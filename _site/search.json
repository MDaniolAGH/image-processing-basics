[
  {
    "objectID": "quarto-workflows/rstudio.html",
    "href": "quarto-workflows/rstudio.html",
    "title": "From RStudio",
    "section": "",
    "text": "The RStudio software (called an IDE, integrated development environment) is an excellent way to edit files and interface with GitHub. Plus, as it is made by the same folks who make Quarto, it has many integrated features for streamlining your workflow with Quarto, including how it previews your edits and provides debugging support for yaml! Quarto's RStudio tutorials has great instructions on getting started with RStudio, including computations and authoring.\nHere is what you’ll need to do to set up and use RStudio with Quarto."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#setup",
    "href": "quarto-workflows/rstudio.html#setup",
    "title": "From RStudio",
    "section": "Setup",
    "text": "Setup\n\nRStudio and GitHub\nFor a workflow with RStudio and GitHub on your local computer, you will need four things:\n\nR\nRStudio\nGit\nGitHub\n\nFollow the UCSB MEDS Installation Guide for detailed instructions on how to create accounts, download, install, and configure on Mac and Windows. This takes about 20 minutes. (For an even more detailed walk-through, see Allison Horst’s ESM 206 Google Doc).\n\n\nClone your repo\nYou’ll start by cloning your repository into RStudio.\nFile &gt; New Project &gt; Version Control &gt; Git &gt; paste your repository name.\nR for Excel Users: Clone your repository using RStudio has detailed instructions and screenshots of these steps.\n\n\nInstall Quarto\nNext, you’ll install Quarto: https://quarto.org/docs/get-started/. After downloading, follow the installation wizard on your computer. When it is complete, you won’t see an application or any new software, but it is now available to RStudio (as well as all other applications on your computer, including the command line).\n\n\nRStudio orientation\nNow let’s take a moment to get oriented. This is an RStudio project, which is indicated in the top-right. The bottom right pane shows all the files in your project; everything we’ve cloned from GitHub. We can open any RStudio project by opening its .Rproj file, or from RStudio File &gt; Open Project ….\n\n\n\nRStudio IDE highlighting the project name and files pane\n\n\n\n\nVisual Editor\nThe RStudio Visual Editor is quite new and has features that improve your writing experience. Working in the Visual Editor feels a bit like working in a Google Doc.\nHere’s an example showing the same file in the original Source Editor with content in markdown format and in the Visual Editor with content that looks more like it will appear in a live site. You can switch freely between these modes.\n\n\n\n\n\n\nRStudio IDE highlighting the Source Editor\n\n\n\n\n\n\n\nRStudio IDE highlighting the Visual Editor\n\n\n\n\n\nAlready have some content formatted in a Google Doc? You can copy-paste it into the Visual Editor and most formatting will be retained.\nThe editing bar provides familiar point and click access to text formatting options like bulleted or numbered lists.\n\n\n\nRStudio IDE highlighting the point and click editing bar\n\n\n\nKeyboard shortcuts\nThe Visual Editor also lets you use many keyboard shortcuts that might be familiar for adding boldface (command-b), italics (command-i), or headers. On a Mac, option-command-2 will make a level 2 header. Try it with option-command-1, or option-command-0 for normal text!\n\n\nInsert an image or figure\nTo insert an image (called a figure in Quarto), click the image icon. This brings up a window in which we can select the image, set its alignment, give it a caption and alt text, hyperlink it, or edit other metadata.\n\n\n\nInsert image or figure using the Visual Editor\n\n\nOnce an image is added, clicking on that image gives us editing options. We can resize it dynamically by clicking in the image and dragging a corner or side to resize. When an image is selected, its dimensions are displayed for editing. Clicking on the gray ellipsis to the right of the dimensions opens the pop-up window to access more metadata edits.\n\n\nInsert a table\nSimilar to adding an image, to insert a table, we click the Table dropdown."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#quarto-render",
    "href": "quarto-workflows/rstudio.html#quarto-render",
    "title": "From RStudio",
    "section": "Quarto render",
    "text": "Quarto render\nIn the Build tab in the top-right pane, click “Render Website”. This will build the .html files and preview your website. It’s equivalent to “knitting” in RMarkdown.\nNote that you can also click “Preview Website”. With “Render Website” in RStudio, Quarto is able to render and preview in one step.\nIf you’d ever like to stop the preview, in the bottom-left, click on the Jobs tab and then the red Stop button.\n\nMake a small change and render it\nClick on index.md. This will open this markdown file in a fourth pane; the editor pane. Make a small change, for example change to today’s date on Line 4. Then, save your file; there is a disc icon at the top of the file.\nThen, render this file: press “Render” which is to the right of the disc icon that saves the file. This will render only this single file, as opposed to rerendering the whole website like when we clicked “Render Website” in the top right pane. Checking Render on Save (between the disc icon and the Render button) is a great strategy for doing this in one step."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#create-a-new-.rmd-page",
    "href": "quarto-workflows/rstudio.html#create-a-new-.rmd-page",
    "title": "From RStudio",
    "section": "Create a new .Rmd page",
    "text": "Create a new .Rmd page\nNew &gt; RMarkdown document &gt; OK\nThe starter RMarkdown document has some R code inside: it displays a summary of the cars dataset that is pre-loaded into R (summary(cars)) and plots the pressure data that is also pre-loaded (plot(pressure)).\nSave this document as r-example.rmd."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#update-_quarto.yml",
    "href": "quarto-workflows/rstudio.html#update-_quarto.yml",
    "title": "From RStudio",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nNow we’ll add r-example.rmd to our _quarto.yml file; this is where we register all files to include in our site. Let’s add it after the section called “Quarto Workflows”.\nOpen _quarto.yml by clicking on it from the file directory.\nScroll down to review the current contents in the sidebar: section under contents:. It’s there we see all the file arrangement that we see in the previewed site.\nAdd - r-example.rmd in its own line, making sure that your indentation aligns with the other pages.\nFrom the Build tab, clicking Preview Website will recreate your website!"
  },
  {
    "objectID": "quarto-workflows/rstudio.html#authoring-tips",
    "href": "quarto-workflows/rstudio.html#authoring-tips",
    "title": "From RStudio",
    "section": "Authoring tips",
    "text": "Authoring tips\nChecking “Render on Save” is really helpful when iterating quickly on a document.\nIf the document is very code-heavy, consider using freeze that will not run the code each time.\nQuarto.org has details about authoring, including specific instructions about authoring in RStudio."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#commit-and-push",
    "href": "quarto-workflows/rstudio.html#commit-and-push",
    "title": "From RStudio",
    "section": "Commit and push!",
    "text": "Commit and push!\nCommitting and pushing will make the changes you see locally live on your website (using the GitHub Action we set up earlier)."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#troubleshooting",
    "href": "quarto-workflows/rstudio.html#troubleshooting",
    "title": "From RStudio",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nIf you have trouble rendering your website after for example changing the extenstion of a file from .md to .qmd, refreshing your RStudio often helps. Do this by clicking the project name at the upper right of the RStudio window (in this case, quarto-website-tutorial), and underneath the “close project” section, click the same name of your project: quarto-website-tutorial. This will relaunch your whole project afresh."
  },
  {
    "objectID": "quarto-workflows/jupyter.html",
    "href": "quarto-workflows/jupyter.html",
    "title": "From Jupyter",
    "section": "",
    "text": "You can interact with Quarto through JupyterLab or JupyterHub. Your Jupyter setup will involve .ipynb notebooks and the command line. Quarto’s JupyterLab tutorials has great instructions on getting started with JupyterLab, including computations and authoring.\nHere we will demonstrate how to work with this Quarto tutorial site in JupyterHub and add a Jupyter Notebook (.ipynb file). This example uses the NASA-Openscapes JupyterHub that already has all python environments as well as Quarto installed."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#setup",
    "href": "quarto-workflows/jupyter.html#setup",
    "title": "From Jupyter",
    "section": "Setup",
    "text": "Setup\n\nJupyterHub\nOur JupyterHub is already setup with python environments as well as Quarto (through nasa-openscapes/corn), so there is no further installation required.\n\n\nClone your repo\nYou’ll start by cloning your repository into JupyterHub. Do this by opening a terminal (File &gt; New &gt; Terminal). In the Terminal, git clone your repository and cd into it:\ngit clone https://github.com/openscapes/quarto-website-tutorial\ncd quarto-website-tutorial\n\n\nInstall Quarto\nNot needed - Quarto is already installed on the NASA-Openscapes JupyterHub! But to install elsewhere you would do so from https://quarto.org/docs/get-started/.\nQuarto is a Command Line Interface (CLI), like git. Once download is complete, follow the installation prompts on your computer like you do for other software. You won’t see an application to click on when it is installed.\nNote for Mac users: If you do not have administrative privileges, please select “Install for me only” during the Destination Selection installation step (you will first click on “Change Install Location” at the Installation Type step).\nYou can check to confirm that Quarto is installed properly from the command line:\nquarto check install\n\n\n\n\n\n\nAdditional checks\n\n\n\n\n\nYou can also run:\n\nquarto check knitr to locate R, verify we have the rmarkdown package, and do a basic render\nquarto check jupyter to locate Python, verify we have Jupyter, and do a basic render\nquarto check to run all of these checks together\n\n\n\n\n\n\n\n\n\n\nHistorical aside: Install Quarto in a docker container\n\n\n\n\n\nIn Summer 2021 some NASA Mentors trying to install quarto locally was not an option, but they were able to install it inside a container using the following Dockerfile:\n#| fold: true\n#| summary: \"Show the Dockerfile\"\n\n##############################\n# This Dockerfile installs quarto and then runs quarto serve against the\n# internal /home/quarto/to_serve.\n#\n# BUILD\n# -----\n# To build this container, run\n#\n#     docker build -t quarto_serve .\n#\n# Add the --no-cache option to force docker to build fresh and get the most\n# recent version of quarto.\n#\n#\n# RUN\n# ---\n# 1. Find the directory you want quarto to serve. Let's call this /PATH/TO/earthdata-cloud-cookbook.\n# 2. Run docker:\n#\n#     docker run --rm -it -p 4848:4848 -v /PATH/TO/earthdata-cloud-cookbook:/home/quarto/to_serve quarto_serve\n#\n# 3. Open your browser and go to http://127.0.0.1:4848/\n#\n##############################\n\nFROM ubuntu:hirsute\n\n######\n# Install some command line tools we'll need\n######\nRUN apt-get update\nRUN apt-get -y install wget\nRUN apt-get -y install gdebi-core\nRUN apt-get -y install git\n\n\n######\n# Install quarto (https://quarto.org/)\n######\n\n# This is a quick and dirty way of getting the newest version number from\n# https://github.com/quarto-dev/quarto-cli/releases/latest. What's happening is\n# we're pulling the version number out of the redirect URL. This will end up\n# with QVER set to something like 0.2.11.\nRUN QVER=`wget --max-redirect 0 https://github.com/quarto-dev/quarto-cli/releases/latest 2&gt;&1 | grep \"Location\" | sed 's/L.*tag\\/v//' | sed 's/ .*//'` \\\n    && wget -O quarto.deb \"https://github.com/quarto-dev/quarto-cli/releases/download/v$QVER/quarto-$QVER-amd64.deb\"\nRUN gdebi -n quarto.deb\n\n# Run this to make sure quarto installed correctly\nRUN quarto check install\n\n\n######\n# Create a non-root user called quarto\n######\nRUN useradd -ms /bin/bash quarto\nUSER quarto\nRUN mkdir /home/quarto/to_serve\nWORKDIR /home/quarto/to_serve\n\n\n######\n# Start quarto serve\n######\n\nCMD quarto serve --no-browse --host 0.0.0.0 --port 4848"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#quarto-preview",
    "href": "quarto-workflows/jupyter.html#quarto-preview",
    "title": "From Jupyter",
    "section": "Quarto preview",
    "text": "Quarto preview\nLet’s start off by previewing our quarto site locally. In Terminal, type quarto preview, which will provide a URL with a preview of our site!\nquarto preview\n# Preparing to preview\n# Watching files for changes\n# Browse at https://openscapes.2i2c.cloud/user/jules32/proxy/4593/\nCopy this URL into another browser window; and arrange them so you can see them both. I make a bit more space in Jupyter by collapsing the left file menu by clicking on the file icon at the top of the left sidebar.\n\n\n\n\n\n\nMake a small change and preview it\nNow we’ll be able to see live changes in the preview as we edit in our .md files. Let’s try it: Change the date in index.md by opening it from the file directory. Change to today’s date, and save. Your preview window will refresh automatically! If it does not, you can also refresh the page manually. The refreshed previewed site will now display your changes!"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#create-a-new-.ipynb-page",
    "href": "quarto-workflows/jupyter.html#create-a-new-.ipynb-page",
    "title": "From Jupyter",
    "section": "Create a new .ipynb page",
    "text": "Create a new .ipynb page\nLet’s add a new page to our site. Instead of an .md file like the others, let’s add a .ipynb file.\nFile &gt; New &gt; Notebook. Accept the default kernel by clicking Select.\n\nFirst chunk: raw yaml\nBy default, this Notebook will give us a first chunk that is code. Let’s change it to raw so that we can write our yaml at the top.\n\n\n\n\n\nIn our Raw code chunk, let’s write the title of this document. We need three dashes --- on separate lines preceding and following the title:, which you can name as you’d like.\n---\ntitle: Python Example\n---\n\n\nSecond chunk: Markdown\nLet’s add a new chunk that is Markdown so we can write some description of what this page will be.\nClick the + symbol at the top of the document, and this will add a new chunk, which by default again is a Code chunk. Change it to a Markdown Chunk following the steps we did above when switching to Raw.\nHere, write a little bit of text in Markdown. Since your title is effectively a level-1 header, avoid using level-1 headers in the rest of your document. Here is some example text I wrote:\n## Introduction\n\nThis example has some Python code that will be a part of our Quarto site.\n\n\nThird chunk: Code\nNow let’s create a new chunk with the default Code setting.\nPaste the following code (or write some of your own to test):\n#| label: fig-polar\n#| fig-cap: \"A line plot on a polar axis\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\nNow, go ahead and execute this code chunk like you normally would, by clicking the cursor in a code block and clicking the sideways “play” triangle to run the selected cells (and advance to the next cell). This code produces a plot.\nNote that the code runs as it normally would; the code options in the comments are just comments.\n\n\nSave your file\nSave your document - I’ll call mine python-example.ipynb in the main repository."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#update-_quarto.yml",
    "href": "quarto-workflows/jupyter.html#update-_quarto.yml",
    "title": "From Jupyter",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nNow we’ll add python-example.ipynb to our _quarto.yml file; this is where we register of all files to include in our site. Let’s add it after the section called “Basic Workflows”.\nOpen _quarto.yml by clicking on it from the file directory.\nScroll down to review the current contents in the sidebar: section. It’s there we see all the file arrangement that we see in the previewed site.\nAdd - python-example.ipynb to line 46, making sure that your indentation aligns with the other pages.\n\n\n\n\n\nYou’ll see that our new page shows up in our Preview, and the code is executed since we did that in the Jupyter Notebook itself. By default, Quarto will not execute code chunks since your computations will likely become more complex and you will want to control when they are executed (or “run”).\nSince Quarto is still previewing our website and the python-example.ipynb, the plot also displays in the notebook after the code is run and the file is saved, as shown below.\n\n\n\n\n\nSo, your normal workflow for creating and running code blocks in your Jupyter Notebook is the same one you’ll use as Quarto displays the preview."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#quarto-render",
    "href": "quarto-workflows/jupyter.html#quarto-render",
    "title": "From Jupyter",
    "section": "Quarto render",
    "text": "Quarto render\nSo far we have used Quarto preview to view our website as we develop it. Quarto render will build the html elements of the website that we can see when we preview. Rendering will format the markdown text and code nicely as a website (or however is indicated in the _quarto.yml).\nBy default, Quarto render does not execute code in a Jupyter notebook. It will never run .ipynb files unless you tell it to.\n\nRender whole notebook\nIf you would like it to specifically execute code in a Jupyter notebook, you can do so in Terminal.\nOur Terminal is still busy previewing our website, so let’s open a new Terminal.\nFile &gt; New &gt; Terminal. Then type:\ncd quarto-website-tutorial\nquarto render python-example.ipynb --execute"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#authoring-tips",
    "href": "quarto-workflows/jupyter.html#authoring-tips",
    "title": "From Jupyter",
    "section": "Authoring tips",
    "text": "Authoring tips\nQuarto.org has details about authoring, including specific instructions about authoring in Jupyter: quarto.org/docs/reference/cells/cells-jupyter."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#commit-and-push",
    "href": "quarto-workflows/jupyter.html#commit-and-push",
    "title": "From Jupyter",
    "section": "Commit and push!",
    "text": "Commit and push!\nCommitting and pushing will make the changes you see locally live on your website (using the GitHub Action we set up earlier)."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#troubleshooting",
    "href": "quarto-workflows/jupyter.html#troubleshooting",
    "title": "From Jupyter",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nMy changes don’t show up in preview\nMake sure you’ve saved your file! There might be a slight delay depending on your JupyterHub/Lab setup.\n\n\nQuarto render hangs / does not complete\nCheck the specific notebook, are there any `—` throughout to denote line breaks rather than yaml? They might be causing the issue; consider deleting those.\nAlso check how long the first raw cell is. Are there level-1 headers (#)? Try removing them."
  },
  {
    "objectID": "explore.html",
    "href": "explore.html",
    "title": "Explore and setup",
    "section": "",
    "text": "With this tutorial, we have a working example website that we will explore together. We’ll learn a few rules and look for patterns to get an understanding of what things to do to help you start customizing and making it your own. And you can continue to use this website as a reference after the tutorial, along with Quarto documentation.\nWe’ll start our exploration online looking at the website architecture and GitHub repository. Then we’ll setup a copy for ourselves so that we can modify from a working example, which is a great way to learn something new. We’ll set it up so that any modifications (commits) will automatically be republished via GitHub Actions. Subsequent chapters will describe how to modify your repo using different tools (browser, RStudio, Jupyter)."
  },
  {
    "objectID": "explore.html#exploring-online",
    "href": "explore.html#exploring-online",
    "title": "Explore and setup",
    "section": "Exploring online",
    "text": "Exploring online\n\nThe website itself\nThis website has 5 things you can see on the left sidebar:\n\nWelcome\nExploring and setup\nQuarto workflows\nLearning more\nTransition from Rmd\n\nMost of these are pages, but you’ll see that “Quarto Workflows” has an arrow; it is a folder with additional pages inside.\n\n\nThe website’s repo\nLet’s go to this website’s GitHub repository (also called a “repo”), https://github.com/openscapes/quarto-website-tutorial. You can also click there from any page in this tutorial website by clicking the GitHub octocat icon underneath the Openscapes logo in the left navbar (click it holding command on Mac, or control on a PC to open it in a different tab in your browser).\nHave a look at the filenames. We can recognize the names of the webpages we’ve seen above, and they have red arrows marking them in the image below. You’ll see the “quarto-workflows” folder and the rest in this site are .qmd files, which are plain text Quarto files that can combine Markdown text with code. index.qmd is the home page. If you click inside “quarto-workflows” you’ll see a mix of filetypes!\n\n\n\nquarto-website-tutorial GitHub repository with files for webpages marked with red arrows\n\n\nThe _site folder has html files with names that should be familiar: they match the .md files we were just exploring. This folder is where Quarto stores files to build the website."
  },
  {
    "objectID": "explore.html#quarto.yml-intro",
    "href": "explore.html#quarto.yml-intro",
    "title": "Explore and setup",
    "section": "_quarto.yml intro",
    "text": "_quarto.yml intro\nThere is also a _quarto.yml file, which is the website’s configuration file. It is essentially metadata for the website that includes the order that the pages/chapters will be in. This is where you update the organization of your website: which page comes before another. If we compare side-by-side, you’ll see that the pages that appear on our website are listed there.\n\n\n\n_quarto.yml and website side-by-side\n\n\nWe’ll learn more about how to interact with _quarto.yml in Quarto Workflows."
  },
  {
    "objectID": "explore.html#fork-to-your-account",
    "href": "explore.html#fork-to-your-account",
    "title": "Explore and setup",
    "section": "Fork to your account",
    "text": "Fork to your account\nLet’s start with an existing Quarto site and copy it into your space to edit. You’ll need a free GitHub account that you create at github.com (follow this advice about choosing your username).\nFirst, choose an existing website to copy. The simplest option is to start with this site: quarto-website-tutorial.\nOther options of potential interest:\n\n2021-Cloud-Hackathon\n2022-SWOT-Ocean-Cloud-Workshop\nOpenscapes Approach-Guide\n\nNext, follow these steps to fork and setup your repo with GitHub Actions from Gavin Fay, using the repo you chose. These instructions will take ~5 minutes.\nNow you’ve got a copy of your repo of choice in your own GitHub account, and you’re set to start making your own edits. Your GitHub repo is set up with a GitHub Action that will use Quarto to rebuild and republish your site anytime you make a commit: committing will trigger the GitHub Action to rebuild and republish the book.\nNote that the GitHub Action for this book does not include R or Python so those will need to be added if your website relies on code. See https://github.com/r-lib/actions for more details and examples.\n\nDownload instead of fork\nForking might not always be the way to go - you can’t fork into the same GitHub user account or organization so if for example you want to make a copy of 2021-Cloud-Hackathon repo within the same NASA-Openscapes GitHub Organization, you’ll need to download instead of fork. In this case, follow these steps to download and copy into a new repository, and set up the GitHub Action separately.\n\nDownload github repo files\nNavigate to https://github.com/openscapes/quarto-website-tutorial (or any other quarto site repo of choice). Click the green “Code” button and select “Download ZIP”. When it downloads on your computer, unzip the files.\n\n\nCreate a new GitHub repo\nNavigate to your GitHub account or organization, and create a new repository, naming it what you’d like. You’ll need a free GitHub account that you create at github.com (follow this advice about choosing your username). When you’re logged in, github.com will show a green button that says “New” which you’ll also see as you navigate to your username’s repository page.\n\n\nAdd original site files\nTo use the GitHub file uploader, click the button next to the green “Code” button that says “Add file”. Add file &gt; Upload files. Then, on your computer, select all the files in unzipped folder (command-A or control-A), and drag them to the GitHub uploader page. Scroll down to write a commit message, which effectively saves your files when you’re working in the browser.\nNote: if you’re comfortable cloning the new repository and copying files into it locally before committing and pushing back to GitHub, that can be preferable to the uploader, which does have limitations with complex repos (although the uploader works fine with this tutorial repo)."
  },
  {
    "objectID": "explore.html#setup-github-action",
    "href": "explore.html#setup-github-action",
    "title": "Explore and setup",
    "section": "Set up GitHub publishing",
    "text": "Set up GitHub publishing\nIf you’ve used the GitHub uploader, you’ll need to set up GitHub publishing separately. We’ll do this in a few steps: we’ll set up a GitHub Action within your repo, and create a gh-pages branch.\nFirst, the GitHub Action. Go back to your main view of your GitHub repository by clicking on the name of your repository in blue at the top-left (the url in your browser window should say https://github.com/username/repo-name).\nNext to the green code button, click Add file &gt; Create new file. Name it exactly this: .github/workflows/quarto-publish.yml . In detail: start by typing the . with github and when you type the / it will give you a new text box to type workflows (plural!), then another /, and finally, quarto-publish.yml.\nNow you’ll have an empty new file. Paste the following in this empty file - you can click on the top-right of this box to copy all the code inside this code box:\non:\n  push:\n    branches: main\n\nname: Render and Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v2 \n        \n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        with:\n          # To install LaTeX to build PDF book \n          tinytex: true \n          # uncomment below and fill to pin a version\n          # version: 0.9.600\n      \n      # add software dependencies here\n\n      - name: Publish to GitHub Pages (and render)\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # this secret is always available for github actions\nCommit this to save your new quarto-publish.yml file. This is your GitHub Action.\nNext, we’ll create a new gh-pages branch. Go back to the main view of your GitHub repository. On the far left from the green “Code” button, click the button that says “main”. In the pull-down menu, type gh-pages - all lowercase, with a hyphen. Click the bold text that says “Create branch: gh-pages from main”.\nNow click on the Settings tab in the top right of your repository. On the left sidebar, click Pages. At the top of Pages under “Source”, select gh-pages root, and press Save. You’ll then see a green highlighted text saying that your site is published at a “github.io” url."
  },
  {
    "objectID": "explore.html#confirm",
    "href": "explore.html#confirm",
    "title": "Explore and setup",
    "section": "Confirm your website is published",
    "text": "Confirm your website is published\nTo confirm that your website is published, go back to your main repository page. You’ll now see an orange dot showing that the GitHub Action is beginning to publish the page.\n\n\n\nOur repo with orange dot indicating in-progress GitHub Action build\n\n\nIf you do not see this orange dot, you might need to make a small commit to trigger the GitHub Actions build. If this is the case, click the pencil on the top-right of the README.md file as circled in the image below, add some small edit (like a space after a period), and scroll down to click commit. Now you should see the orange dot.\n\n\n\n\n\nWhen your orange do becomes a green check, you can go inspect your published site at “https://username.github.io/your-repo). For example: https://openscapes.github.io/quarto-website-tutorial.\n\n\n\nOur repo with green check indicating successful GitHub Action build"
  },
  {
    "objectID": "explore.html#renaming-your-repo",
    "href": "explore.html#renaming-your-repo",
    "title": "Explore and setup",
    "section": "Renaming your repo",
    "text": "Renaming your repo\nIf you’d like to rename your repo, go to Settings and the option to rename is on the top of the main settings page."
  },
  {
    "objectID": "explore.html#onward",
    "href": "explore.html#onward",
    "title": "Explore and setup",
    "section": "Onward!",
    "text": "Onward!\nNow you are ready to start editing and publishing! The next chapter describes how starting off from the browser, using Markdown."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Podstawy Metod Komputerowych w Obliczeniach Inżynierskich",
    "section": "",
    "text": "Strona powstała w zamyśle jako pomoc dydaktyczna dla studentów biorących udział w kursie Podstawy Metod Komputerowych w Obliczeniach Inżynierskich oferowanym na Wydziale EAIiIB AGH."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Podstawy Metod Komputerowych w Obliczeniach Inżynierskich",
    "section": "",
    "text": "Strona powstała w zamyśle jako pomoc dydaktyczna dla studentów biorących udział w kursie Podstawy Metod Komputerowych w Obliczeniach Inżynierskich oferowanym na Wydziale EAIiIB AGH."
  },
  {
    "objectID": "index.html#wymagania-wstępne",
    "href": "index.html#wymagania-wstępne",
    "title": "Podstawy Metod Komputerowych w Obliczeniach Inżynierskich",
    "section": "Wymagania Wstępne",
    "text": "Wymagania Wstępne\nZajęcia prowadzone są w całości z wykorzystaniem notatników Google Colab na indywidualnym koncie studenta. Zachęcamy jednak do korzystania z IDE takich jak:\n\nVisual Studio Code - dla bardziej zaawansowanych - z bardzo dużymi możliwościami konfiguracji,\nSpyder dla bardziej początkujących, z dużą ilością dostępnych bibliotek, łatwiejsze w instalacji (szczególnie na Windowsie)"
  },
  {
    "objectID": "index.html#zakres-tematyczny",
    "href": "index.html#zakres-tematyczny",
    "title": "Podstawy Metod Komputerowych w Obliczeniach Inżynierskich",
    "section": "Zakres Tematyczny",
    "text": "Zakres Tematyczny\nW ciągu semestru poruszymy następujące zagadnienia:\n\nZajęcia wprowadzające, przedstawienie programu laboratorium. Praktycznie wprowadzenie do problemów numerycznych. Przypomnienie podstaw biblioteki NumPy/SciPy/Matplotlib. Wprowadzenie do biblioteki PyTorch.\nRóżniczkowanie numeryczne. Sposoby obliczania gradientu. Podstawowe typu gradientu. Splot. Analiza błędów numerycznych w porównaniu do rozwiązań analitycznych. Implementacja gradientów analitycznych. Przykłady praktyczne.\nCałkowanie numeryczne. Podstawowe algorytmy całkowania numerycznego. Analiza błędu całkowania. Całkowanie numeryczne, a analityczne. Przykłady praktyczne."
  },
  {
    "objectID": "labs/lab1.html",
    "href": "labs/lab1.html",
    "title": "Laboratorium 1",
    "section": "",
    "text": "Wprowadzenie w temat obliczeń numerycznych w języku Python\nPodstawy Pythona - Przypomnienie\nPodstawy użycia bibliotek:\n\nNumpy\nSciPy\nMatPlotLib\n\nTypy Danych w Numpy\nBłędy numeryczne i ich propagacja\nBiblioteka PyTorch\n\n\n\n\nObliczenia numeryczne odgrywają kluczową rolę w wielu dziedzinach nauki i inżynierii. Python, dzięki swoim bibliotekom i cechom języka, stał się popularnym wyborem do przeprowadzania obliczeń numerycznych. Oto kilka powodów, dla których Python jest często wybierany do tego celu:\nCzytelność: Składnia Pythona jest przejrzysta i zwięzła, co pozwala na łatwe pisanie i analizę kodu.\nBiblioteki: Python posiada bogaty zestaw bibliotek do obliczeń numerycznych, takich jak:\n\nNumPy: Biblioteka do obliczeń numerycznych, oferująca wsparcie dla dużych tablic i macierzy wielowymiarowych oraz zestaw funkcji matematycznych do ich operowania.\nSciPy: Oparta na NumPy, jest to biblioteka służąca do bardziej zaawansowanych obliczeń i algorytmów naukowych.\nPandas: Biblioteka do analizy danych, która dostarcza struktury danych i funkcje niezbędne do czyszczenia, agregacji i analizy danych.\n\nInteraktywność: Narzędzia takie jak Jupyter Notebook pozwalają na interaktywne eksplorowanie danych i obliczeń, co jest niezmiernie użyteczne w analizie naukowej.\nIntegracja z innymi językami: Python może być łatwo zintegrowany z kodem napisanym w językach takich jak C, C++ czy Fortran, co pozwala na łączenie szybkości tych języków z elastycznością Pythona.\nWizualizacja Danych: Biblioteki takie jak Matplotlib, Seaborn czy Plotly umożliwiają tworzenie zaawansowanych wizualizacji, które są kluczowe do analizy wyników obliczeń numerycznych.\nWspólnota: Python ma ogromną społeczność, która stale tworzy i udostępnia nowe narzędzia, biblioteki i zasoby do obliczeń numerycznych.\nWszechstronność: Poza obliczeniami numerycznymi, Python jest językiem ogólnego zastosowania, co oznacza, że można go używać również do web developmentu, automatyki, analizy danych, sztucznej inteligencji i wielu innych zastosowań. Dzięki temu badacze i inżynierowie mogą korzystać z jednego języka do wielu różnych zadań.\nOtwarte oprogramowanie: Python jest językiem open source, co oznacza, że jest dostępny za darmo i ma dużą społeczność deweloperów pracujących nad jego rozwojem.\n\n\n\n\n\nPython to wysokopoziomowy język programowania stworzony przez Guido van Rossuma i po raz pierwszy opublikowany w 1991 roku. Charakteryzuje się czytelną składnią, która pozwala programistom wyrażać koncepty w mniejszej ilości kodu niż w językach takich jak C++ czy Java.\nDziałanie Pythona na poziomie szczegółów można opisać w kilku kluczowych krokach. W skrócie, działanie Pythona polega na tym, że kod źródłowy jest interpretowany przez interpreter Pythona w kod bajtowy, który następnie jest wykonywany przez maszynę wirtualną Pythona.\nOto bardziej szczegółowy przegląd tego, jak to działa:\n\nKod źródłowy: Wszystko zaczyna się od kodu źródłowego, który piszesz w pliku .py.\nKompilacja do kodu bajtowego: Gdy uruchamiasz skrypt Pythona, interpreter (zazwyczaj CPython, który jest standardową implementacją Pythona) kompiluje ten kod źródłowy w kod bajtowy. Kod bajtowy to niskopoziomowe, platformowo niezależne przedstawienie twojego kodu źródłowego. Zostaje on zapisany w plikach .pyc w katalogu pycache.\nMaszyna wirtualna Pythona (PVM): Po skompilowaniu kodu, kod bajtowy jest przekazywany do Maszyny Wirtualnej Pythona (PVM). To tu właściwe wykonanie kodu ma miejsce. PVM interpretuje i wykonuje kod bajtowy linia po linii.\nZarządzanie pamięcią: Python automatycznie zarządza pamięcią dzięki mechanizmowi zwanej “garbage collection”. Python posiada wbudowany licznik odniesień, który śledzi liczbę odniesień do każdego obiektu w pamięci. Gdy liczba odniesień do obiektu spada do zera, pamięć zajmowana przez obiekt jest automatycznie zwalniana. Dodatkowo, cykliczne odniesienia (gdzie obiekty odnoszą się nawzajem, ale nie są dostępne z żadnej innej części kodu) są wykrywane przez garbage collector i odpowiednio czyszczone.\nRozszerzenia w języku C: Jednym z mocnych stron Pythona jest jego zdolność do integrowania się z językami niższego poziomu, takimi jak C. Możesz pisać rozszerzenia w C, które są potem dostępne jako moduły w Pythonie. To pozwala na pisania bardziej wydajnych fragmentów kodu w C i korzystania z nich w Pythonie.\nBiblioteki standardowe: Python ma bogate biblioteki standardowe, które oferują funkcje dla wielu powszechnych zadań, od pracy z plikami i sieciami po analizę danych i tworzenie interfejsów graficznych.\nInterfejs API C: Python ma dobrze zdefiniowany API dla języka C, co pozwala na tworzenie rozszerzeń w C oraz na osadzanie interpretera Pythona w aplikacjach napisanych w C.\n\n\n\n\nW języku Python najprostsza deklaracja funkcji wygląda następująco:\ndef my_first_function():\n    pass\nFunkcja ta nie przyjmuje ani nie zwraca niczego.\nFunkcje mogą przyjmowac argumenty:\nArgumenty pozycyjne: Są to najczęściej używane argumenty. Przekazujesz je w kolejności, w jakiej są wymienione w definicji funkcji.\ndef funkcja(a, b, c):\n    print(a, b, c)\n\nfunkcja(1, 2, 3)  # 1 2 3\nArgumenty nazwane (keyword arguments): Przekazujemy wartość, wskazując nazwę argumentu.\nfunkcja(a=1, c=3, b=2)  # 1 2 3\nDomyślne wartości argumentów: Możesz ustawić domyślne wartości dla niektórych (lub wszystkich) argumentów.\ndef funkcja(a, b=2, c=3):\n    print(a, b, c)\n\nfunkcja(1)  # 1 2 3\nfunkcja(1, c=4)  # 1 2 4\n\n\n\n*args i **kwargs to konwencje w Pythonie do obsługi zmiennej liczby argumentów w funkcjach. Dzięki nim możemy przekazywać do funkcji różną liczbę argumentów w sposób bardziej elastyczny.\n\n\n*args pozwala na przekazywanie dowolnej liczby pozycyjnych argumentów do funkcji. W ciele funkcji argumenty te są dostępne jako krotka. Przykład:\ndef suma(*args):\n    return sum(args)\n\nprint(suma(1, 2, 3, 4))  # 10\nprint(suma(10, 20))      # 30\n\n\n\n**kwargs pozwala na przekazywanie dowolnej liczby nazwanych (klucz-wartość) argumentów do funkcji. W ciele funkcji argumenty te są dostępne jako słownik. Przykład:\ndef opis_osoby(**kwargs):\n    for klucz, wartosc in kwargs.items():\n        print(f\"{klucz}: {wartosc}\")\n\nopis_osoby(imie=\"Jan\", nazwisko=\"Kowalski\", wiek=30)\nWynik:\nimie: Jan\nnazwisko: Kowalski\nwiek: 30\nOczywiście, można łączyć *args i **kwargs w jednej funkcji:\ndef funkcja_przykladowa(a, b, *args, **kwargs):\n    print(a, b)\n    print(args)\n    print(kwargs)\n\nfunkcja_przykladowa(1, 2, 3, 4, 5, klucz1=\"wartosc1\", klucz2=\"wartosc2\")\nWynik:\n1 2\n(3, 4, 5)\n{'klucz1': 'wartosc1', 'klucz2': 'wartosc2'}\n\n\n\n\nW Pythonie występują dwa rodzaje pętli: for i while.\n\n\nPętla for jest używana do iterowania po sekwencji (to może być lista, krotka, słownik, zbiór lub łańcuch znaków).\nSkładnia:\nfor zmienna in sekwencja:\n    # instrukcje\nPrzykład: Iteracja po liście:\nfruits = [\"jablko\", \"gruszka\", \"pietruszka\"]\nfor fruit in fruits:\n    print(fruit)\nZa pomocą funkcji range(), pętlę for można również użyć do wykonywania określonej liczby iteracji:\nfor i in range(5):  # będzie wykonywać pętlę od 0 do 4\n    print(i)\n\n\n\nPętla while wykonuje blok kodu tak długo, jak długo warunek pętli jest prawdziwy.\nSkładnia:\nwhile warunek:\n    # instrukcje\nPrzykład:\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\n\n\n\n\nOprócz podstawowych instrukcji pętli, w Pythonie istnieją również instrukcje umożliwiające kontrolę przepływu w pętlach:\n\nbreak: Przerywa działanie pętli i przechodzi do kolejnej instrukcji poza pętlą.\nPrzykład:\nfor i in range(5):\n    if i == 3:\n        break\n    print(i)\ncontinue: Przerywa bieżący cykl pętli i przechodzi do następnego cyklu.\nPrzykład:\nfor i in range(5):\n    if i == 3:\n        continue\n    print(i)\nelse: W Pythonie pętle mogą mieć opcjonalną klauzulę else. Wykonuje się ona, gdy pętla kończy swoje działanie normalnie (nie przez break).\nPrzykład:\nfor i in range(5):\n    print(i)\nelse:\n    print(\"Pętla zakończona\")\n\n\n\n\nGenerator w Pythonie to specjalny rodzaj iteratora, który pozwala na generowanie wartości “na bieżąco” w miarę ich potrzeby, zamiast generować wszystkie wartości naraz i przechowywać je w pamięci. Dzięki temu generatory są bardziej wydajne pod względem alokacji pamięci. Ma to znaczenie zwłaszcza przy pracy z dużymi zbiorami danych.\nGeneratory tworzy się głównie w dwóch sposobach:\n\nZa pomocą funkcji i słowa kluczowego yield.\nZa pomocą wyrażeń generatora (podobnie jak list comprehension, ale w nawiasach okrągłych).\n\nPrzykład:\ndef even_numbers_generator(n):\n    for i in range(n):\n        if i % 2 == 0:\n            yield i\n\ngen = even_numbers_generator(10)\nfor number in gen:\n    print(number)\nOto inny przykład generatora, który zwraca nieskończony ciąg liczb w postaci ciągu geometrycznego o zadanej podstawie:\ndef geometric_sequence(a, r):\n    while True:\n        yield a\n        a *= r\n\n# Przykład użycia\ngen = geometric_sequence(1, 2)  # podstawa 1, iloraz 2\nfor _ in range(5):\n    print(next(gen))\nGeneratory są także często używane do wczytywania danych\n\n\n\n\n\n\nModelowanie sygnału PPG z wykorzystaniem generatora\n\n\n\nRozważmy generator danych dla symulacji sygnału fotopletyzmograficznego (PPG), który jest wykorzystywany do monitorowania tętna i saturacji tlenu w krwi. Sygnał PPG jest rejestrowany za pomocą czujnika optycznego umieszczonego na skórze, który wykrywa zmiany objętości krwi w naczyniach krwionośnych.\nNie zawsze mamy dostęp do takiego sygnału, co więcej - czasami chcemy sami wygenerowac sygnały o konkretnym kształcie, charakterystycznych zniekształceniach, aby przetestowac pewne algorytmy.\nMożemy to zrobic z wykorzystaniem generatora:\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef synthetic_ppg_generator(frequency=100):\n    \"\"\"\n    Generator syntetycznego sygnału PPG.\n    \n    frequency: częstotliwość próbkowania sygnału [Hz]\n    \"\"\"\n    t = 0  # czas [s]\n    dt = 1.0 / frequency\n    while True:\n        # Modelujemy podstawowy kształt fali PPG przy użyciu równania\n        ppg_wave = np.abs(np.sin(t)) + 0.3 * np.sin(4 * np.pi * t) - 0.15 * np.sin(6 * np.pi * t)\n        \n        yield ppg_wave\n        t += dt\n\n# Przykład użycia:\nppg_gen = synthetic_ppg_generator(frequency=100)\n\n# Wygenerowanie 5s sygnału PPG (500 próbek, ponieważ frequency=100Hz)\nppg_signal = [next(ppg_gen) for _ in range(500)]\n\n# Rysujemy sygnał\nplt.plot(ppg_signal)\nplt.title(\"Syntetyczny sygnał PPG\")\nplt.xlabel(\"Próbka\")\nplt.ylabel(\"Amplituda\")\nplt.show()\n\n\n\nWygenerowany sygnał PPG\n\n\n\n\n\n\n\n\n\n\nNumPy to podstawowa biblioteka do obliczeń naukowych w Pythonie, która dostarcza wsparcie dla dużych, wielowymiarowych tablic i macierzy oraz wielu matematycznych funkcji do operacji na tych tablicach. Oto kilka najważniejszych cech biblioteki NumPy w kontekście metod numerycznych:\n\nWektoryzacja:\n\nPozwala na wykonywanie operacji na całych tablicach bez potrzeby stosowania pętli.\nOperacje wektoryzowane są znacznie bardziej wydajne niż ich odpowiedniki bazujące na pętlach, dzięki zastosowaniu optymalizowanych funkcji niskiego poziomu napisanych w językach takich jak C i Fortran.\n\n\n\n\n\n\n\n\nPrzykład wektoryzacji\n\n\n\nZałóżmy, że chcemy dodać elementy dwóch dużych list do siebie. Możemy to zrobić na dwa sposoby:\n\nTradycyjnie:\n\nlist1 = [1, 2, 3, 4, 5]\nlist2 = [5, 4, 3, 2, 1]\nresult = []\n\nfor i in range(len(list1)):\n    result.append(list1[i] + list2[i])\n\nprint(result)\n\nZ wykorzystaniem biblioteki NumPy i wektoryzacji:\n\nimport numpy as np\n\narray1 = np.array([1, 2, 3, 4, 5])\narray2 = np.array([5, 4, 3, 2, 1])\n\nresult_array = array1 + array2\nprint(result_array)\nZobaczmy teraz, co robi NumPy:\nGdy wykonujemy operację result_array = array1 + array2, NumPy wykonuje kilka kroków:\n\nSprawdzanie wymiarów: Najpierw NumPy sprawdzi, czy obie tablice mają taki sam kształt (shape). Jeśli nie mają, zostanie zgłoszony błąd (chyba że możliwe jest “rozgłaszanie” (broadcasting), ale to bardziej zaawansowana funkcjonalność).\nAlokacja pamięci: NumPy alokuje pamięć dla wynikowej tablicy, która będzie miała taki sam kształt jak array1 i array2.\nOperacje element po elemencie: Następnie, dla każdego indeksu w tablicach, NumPy dodaje wartości z array1 i array2, a wynik zapisuje w odpowiednim miejscu w result_array.\n\nW rzeczywistości, proces jest bardziej skomplikowany i zoptymalizowany pod kątem wydajności. Dzięki wektoryzacji i natywnym, optymalizowanym funkcjom niskiego poziomu, operacje takie jak ta są wykonane bardzo szybko.\n\n\n\nEfektywna organizacja pamięci:\n\n\nTablice NumPy są jednorodne i przechowywane w ciągłych blokach pamięci. W przeciwieństwie do list w Pythonie, które są tablicami wskaźników, tablice NumPy zajmują mniej miejsca i umożliwiają szybszy dostęp do danych.\nObsługuje też widoki (views), które pozwalają na dostęp do danych bez ich kopiowania, co jest szczególnie przydatne w dużych zbiorach danych.\n\n\nParalelizacja:\n\n\nChociaż sama NumPy nie obsługuje paralelizacji na poziomie wielu wątków, jej operacje są zoptymalizowane do wykorzystania jednostek SSE/AVX dostępnych w nowoczesnych procesorach, co przyspiesza wiele operacji.\nDodatkowo, biblioteki takie jak Dask czy Numba pozwalają na łatwą paralelizację i kompilację operacji NumPy dla jeszcze większej wydajności.\n\n\nWsparcie dla operacji algebry liniowej, transformacji Fouriera i funkcji statystycznych:\n\n\nDostarcza funkcje do rozwiązywania układów równań, obliczania wartości własnych, dekompozycji oraz innych kluczowych operacji algebry liniowej.\nWbudowane funkcje do operacji na liczbach zespolonych oraz do wykonywania transformacji Fouriera.\n\n\nWsparcie dla różnych typów danych:\n\n\nObsługuje szeroki zakres typów danych, w tym typy liczbowe (całkowite, zmiennoprzecinkowe, zespolone) oraz typy dat i czasów.\n\n\nInteroperacyjność:\n\n\nMoże współdziałać z bibliotekami napisanymi w innych językach, takimi jak C, C++ czy Fortran, co pozwala na wykorzystanie istniejących, optymalizowanych kodów.\nŁatwa integracja z innymi bibliotekami do analizy danych, takimi jak pandas czy SciPy.\n\n\nRozszerzalność:\n\n\nMożliwość tworzenia własnych typów danych i funkcji ufunc, które zachowują się jak wbudowane operacje wektoryzowane.\n\nW kontekście metod numerycznych, NumPy dostarcza solidne narzędzie do szybkiego i wydajnego przetwarzania danych oraz implementacji algorytmów numerycznych w Pythonie.\n\n\n\nDrugą z wykorzystywanych przez nas bibliotek jest biblioteka SciPy - rozbudowana biblioteka służąca do obliczeń naukowych i inżynierskich w języku Python. Biblioteka ta bazuje na NumPy, ale dodaje sporo rzeczy “od siebie”. Przejdźmy przez jej najważniejsze moduły:\n\nModuł do optymalizacji (scipy.optimize): Narzędzia do znajdowania korzeni równań i minimalizacji funkcji.\nModuł do algebry liniowej (scipy.linalg): Funkcje do rozwiązywania równań liniowych, obliczania wartości własnych itp.\nModuł do przetwarzania sygnałów (scipy.signal): Narzędzia do analizy, projektowania i przetwarzania sygnałów.\nModuł do analizy obrazów (scipy.ndimage): Funkcje do przetwarzania i analizy obrazów.\nModuł do statystyki (scipy.stats): Obszerna kolekcja funkcji do statystyki i rozkładów prawdopodobieństwa.\nModuł do całkowania (scipy.integrate): Narzędzia do całkowania funkcji i równań różniczkowych.\n\n\n\n\n\n\n\nPrzykład obliczeń z wykorzystaniem SciPy\n\n\n\nZałóżmy, że chcemy znaleźc minimum jakiejś funkcji. Zobaczmy jak możemy to zrobic z wykorzystaniem biblioteki SciPy:\nfrom scipy.optimize import minimize\n\n# Definiujemy funkcję\ndef f(x):\n    return x**2 + 6*x + 5\n\n# Znajdujemy minimum funkcji zaczynając od punktu x=0\nresult = minimize(f, x0=0)\n\n# Wypisujemy wynik\nprint(f\"Minimum value of f(x) is {result.fun} at x = {result.x}\")\n\n\nPrzeanalizujmy jeszcze jeden, bardzo ważny przykład, który łączy w sobie wykorzystanie biblioteki SciPy oraz pewne specyficzne cechy wykonywania obliczeń numerycznych.\n\n\n\n\n\n\nPrzykład rozwiązywania układu równań\n\n\n\nW szpitalu są dwie grupy pacjentów: osoby z grypą i osoby z zatruciem pokarmowym. Pierwszego dnia przyszło 5 pacjentów z grypą i 3 z zatruciem pokarmowym. Wszyscy razem otrzymali 23 tabletki paracetamolu. Drugiego dnia przyszło 2 osoby z grypą i 3 z zatruciem pokarmowym, a łączna liczba tabletek paracetamolu, które dostali, wynosiła 13. Jaką dawkę paracetamolu otrzymuje pacjent z grypą oraz pacjent z zatruciem pokarmowym?\nZałóżmy, że:\n\nDawka dla pacjenta z grypą to \\(x\\) tabletek.\nDawka dla pacjenta z zatruciem to \\(y\\) tabletek.\n\nNa podstawie powyższych informacji uzyskujemy układ równań:\n\\(5x+3y=23\\) (pierwszy dzień)\n\\(2x+3y=13\\) (drugi dzień)\nRozwiążmy zatem ten układ równań, korzystając z biblioteki SciPy:\nimport numpy as np\nfrom scipy.linalg import solve\n\n# Macierz współczynników\nA = np.array([[5, 3], [2, 3]])\n\n# Wektor wyników\nb = np.array([23, 13])\n\n# Rozwiązujemy układ równań\nx, y = solve(A, b)\n\nprint(f\"Dawka dla pacjenta z grypą: {x:.2f} tabletki\")\nprint(f\"Dawka dla pacjenta z zatruciem pokarmowym: {y:.2f} tabletki\")\n\n\n\n\n\nBiblioteka matplotlib to jedno z najpopularniejszych narzędzi do tworzenia wizualizacji danych w Pythonie. Dzięki niej można tworzyć różnorodne wykresy, od podstawowych liniowych czy słupkowych, po bardziej zaawansowane jak histogramy, wykresy punktowe czy konturowe.\nNajważniejsze cechy biblioteki matplotlib:\n\nWszechstronność: Możliwość tworzenia wielu typów wykresów.\nDostosowywalność: Wielkie możliwości konfiguracji wyglądu wykresów.\nInteraktywność: Możliwość tworzenia interaktywnych wizualizacji.\nIntegracja z innymi bibliotekami: matplotlib integruje się z wieloma innymi bibliotekami Pythona takimi jak pandas czy numpy.\nPodmoduł pyplot: Zapewnia interfejs podobny do MATLAB-a, co jest przydatne dla osób znających to środowisko.\nWsparcie dla różnych formatów: Możliwość zapisu w wielu popularnych formatach graficznych jak PNG, PDF, SVG i innych.\n\n\n\n\n\n\n\nProsty przykład:\n\n\n\nStworzymy wykres przedstawiający funkcje sinus i cosinus na tym samym rysunku z dodatkową konfiguracją:\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Dane\nx = np.linspace(0, 2 * np.pi, 400)\ny1 = np.sin(x)\ny2 = np.cos(x)\n\n# Tworzenie wykresu\nplt.figure(figsize=(10,6))  # ustawienie rozmiaru wykresu\nplt.plot(x, y1, label='sin(x)', color='blue', linewidth=2)  # wykres funkcji sinus\nplt.plot(x, y2, label='cos(x)', color='red', linestyle='--', linewidth=2)  # wykres funkcji cosinus\n\n# Dodanie tytułu i etykiet osi\nplt.title('Funkcje sinus i cosinus')\nplt.xlabel('x')\nplt.ylabel('y')\n\n# Dodanie siatki i legendy\nplt.grid(True, which='both', linestyle='--', linewidth=0.5)\nplt.legend()\n\n# Wyświetlenie wykresu\nplt.tight_layout()  # automatyczne dopasowanie elementów wykresu\nplt.show()\nTen kod utworzy wykres funkcji sinus i cosinus.\n\n\nPrzeanalizujmy bardziej efektowny przykład:\n\n\n\n\n\n\nSymulowany oscyloskop\n\n\n\nZałóżmy, że chcemy przedstawic komuś koncepcję trzech sygnałów oscyloskopowych:\n\nsygnał sinusoidalny\nsygnał prostokątny\nsygnał trójkątny\n\nStworzymy wykres tych sygnałów wraz z opisem, skalą oraz powiększeniem fragmentu jednego z sygnałów.\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Generowanie sygnałów\nt = np.linspace(0, 5 * np.pi, 1000)\nsin_wave = np.sin(t)\nsquare_wave = np.sign(sin_wave)\ntriangle_wave = 2 * np.arcsin(sin_wave) / np.pi\n\n# Tworzenie głównego wykresu\nfig, ax = plt.subplots(figsize=(12, 8))\n\nax.plot(t, sin_wave, label=\"Sinusoidalny\", color=\"blue\")\nax.plot(t, square_wave, label=\"Prostokątny\", color=\"red\", linestyle=\"--\")\nax.plot(t, triangle_wave, label=\"Trójkątny\", color=\"green\", linestyle=\"-.\")\n\n# Ustawienia wykresu\nax.set_title(\"Sygnały oscyloskopowe\")\nax.set_xlabel(\"Czas\")\nax.set_ylabel(\"Amplituda\")\nax.grid(True, linestyle='--', alpha=0.7)\nax.legend()\n\n# Powiększenie fragmentu wykresu\naxins = ax.inset_axes([0.2, 0.2, 0.3, 0.3])  # [x, y, width, height]\naxins.plot(t, sin_wave, color=\"blue\")\naxins.plot(t, square_wave, color=\"red\", linestyle=\"--\")\naxins.plot(t, triangle_wave, color=\"green\", linestyle=\"-.\")\nx1, x2, y1, y2 = 7, 8, -1.5, 1.5  # zakres fragmentu do powiększenia\naxins.set_xlim(x1, x2)\naxins.set_ylim(y1, y2)\naxins.grid(True, linestyle='--', alpha=0.7)\n\n# Zaznaczenie fragmentu do powiększenia na głównym wykresie\nrect = patches.Rectangle((x1, y1), x2-x1, y2-y1, edgecolor='gray', facecolor='none', linestyle=\":\")\nax.add_patch(rect)\nax.indicate_inset_zoom(axins, edgecolor=\"gray\")\n\nplt.tight_layout()\nplt.show()\nTen kod generuje wykres trzech różnych sygnałów oscyloskopowych wraz z legendą, skalą i powiększeniem fragmentu wykresu, pokazującym interesujący obszar tych sygnałów. Zakres powiększenia został zaznaczony na głównym wykresie szarą linią przerywaną.\n\n\n\n\n\nPyTorch to otwartoźródłowa biblioteka do uczenia maszynowego, stworzona głównie przez Facebook’s AI Research lab. PyTorch jest znany ze swojej elastyczności i dynamicznej kompilacji, co sprawia, że jest szczególnie użyteczny w badaniach. Umożliwia budowanie różnego rodzaju modeli głębokiego uczenia oraz oferuje wsparcie dla GPU, co przyspiesza obliczenia.\n\n\n\n\n\n\nPrzykład wykorzystania biblioteki PyTorch\n\n\n\nPrzeanalizujmy przykład wykorzystania PyTorch do rozwiązania problemu matematycznego polegającego na znalezieniu minimum funkcji kwadratowej. W tym celu użyjemy koncepcji różniczkowania i spadku gradientu (dowiecie się o tym na kolejnych zajęciach z naszego przedmiotu, proszę chwilowo się nie martwic), ale bez wchodzenia głęboko w kontekst uczenia maszynowego.\n\n\nZnajdź wartość \\(x\\), która minimalizuje funkcję \\(f(x) = x^2 + 4x + 4\\).\n\n\n\n\nInicjalizuj zmienną \\(x\\) z losową wartością.\nOblicz wartość funkcji \\(f\\) dla aktualnej wartości \\(x\\).\nOblicz gradient funkcji względem \\(x\\) (to informuje nas, w którym kierunku powinniśmy aktualizować \\(x\\) w celu zminimalizowania \\(f\\)).\nAktualizuj \\(x\\) w kierunku przeciwnym do gradientu.\nPowtarzaj kroki 2-4 przez pewną liczbę iteracji lub do osiągnięcia pewnego progu dokładności.\n\n\n\n\nimport torch\n\n# Krok 1: Inicjalizuj zmienną x z losową wartością i wymaganiem obliczania gradientu.\nx = torch.randn(1, requires_grad=True)\n\n# Definicja optymalizatora\nlearning_rate = 0.1\noptimizer = torch.optim.SGD([x], lr=learning_rate)\n\n# Iteracje optymalizacji\nfor iteration in range(100):\n    # Krok 2: Oblicz wartość funkcji f dla aktualnej wartości x.\n    f = x**2 + 4*x + 4\n    \n    # Krok 3: Oblicz gradient funkcji\n    f.backward()\n    \n    # Krok 4: Aktualizuj x w kierunku przeciwnym do gradientu.\n    optimizer.step()\n    \n    # Zeruj gradienty dla następnej iteracji.\n    optimizer.zero_grad()\n\nprint(f'Minimum funkcji f(x) = x^2 + 4x + 4 jest w punkcie x = {x.item()}')\nW tym przykładzie korzystamy z PyTorch do obliczenia gradientów i optymalizacji wartości \\(x\\), aby zminimalizować funkcję \\(f\\). Nie używamy tu żadnych zaawansowanych koncepcji uczenia maszynowego, ale skupiamy się na podstawach różniczkowania i optymalizacji.\nNo dobra, ale dlaczego zatem nie używamy do tego po prostu biblioteki NumPy. Z kilku powodów, niestety niewidocznych gołym okiem na tak prostym przykładzie. Porównując podejście z wykorzystaniem NumPy, do podejścia z wykorzystaniem PyTorch-a, możemy określic pewne różnice (oraz co za tym idzie cechy biblioteki PyTorch)\n\nAutomatyczne różniczkowanie:\n\nPyTorch: PyTorch oferuje automatyczne różniczkowanie dzięki backward(). Pozwala to na obliczenie gradientu funkcji bez konieczności ręcznego określania jego formy.\nNumPy: W NumPy musiałbyś ręcznie wyznaczyć gradient funkcji, co dla naszej funkcji kwadratowej jest proste, ale dla bardziej skomplikowanych funkcji może być trudne.\n\nWsparcie dla GPU:\n\nPyTorch: PyTorch może przeprowadzać obliczenia zarówno na CPU, jak i GPU. Dzięki temu operacje mogą być przyspieszone dla dużych zbiorów danych lub skomplikowanych modeli.\nNumPy: NumPy działa tylko na CPU. Istnieją biblioteki, takie jak CuPy, które oferują podobne do NumPy interfejsy na GPU, ale standardowy NumPy nie oferuje tej funkcjonalności.\n\nAktualizacja zmiennych:\n\nPyTorch: Optymalizatory w PyTorch (np. torch.optim.SGD) automatycznie aktualizują wartość zmiennych w odpowiedzi na obliczone gradienty.\nNumPy: Musiałbyś ręcznie zaktualizować wartość zmiennej na podstawie gradientu, np. x = x - learning_rate * gradient.\n\nIntegracja z głębokim uczeniem:\n\nJeśli w przyszłości chciałbyś rozbudować rozwiązanie, np. dodać warstwy sieci neuronowej, PyTorch oferuje gotowe do użycia narzędzia i struktury, które ułatwiają to zadanie.\nW przypadku NumPy musiałbyś samodzielnie zaimplementować wiele elementów związanych z sieciami neuronowymi.\n\n\nChociaż dla naszego prostego problemu różnice te mogą wydawać się niewielkie, dla bardziej skomplikowanych problemów i większych zbiorów danych zalety PyTorch stają się bardziej widoczne.\nJeśli jednak chodzi o nasz konkretny problem z minimalizacją funkcji kwadratowej, można go łatwo rozwiązać przy użyciu NumPy, obliczając ręcznie gradient i aktualizując wartość \\(x\\) w pętli. PyTorch jest tutaj używany bardziej jako demonstracja jego możliwości niż konieczność.\n\n\n\n\n\n\n\nKluczową strukturą danych w numpy jest ndarray (n-wymiarowa tablica danych), która pozwala na przechowywanie i operacje na dużych zbiorach danych w efektywny sposób.\nKażda tablica ndarray ma atrybut o nazwie dtype, który wskazuje typ danych przechowywanych w tablicy. dtype definiuje:\n\nRodzaj danych (np. liczba całkowita, liczba zmiennoprzecinkowa, boolean, itp.).\nIlość pamięci potrzebną do przechowywania jednego elementu tego typu.\nZakres wartości, jakie można w niej przechowywać.\nPrecyzję (dla liczb zmiennoprzecinkowych).\n\nPrzedstawmy kilka podstawowych typów danych w bibliotece NumPy :\n\nLiczby całkowite: int8, int16, int32, int64 (odpowiednio 8, 16, 32, 64 bity). Dla liczb bez znaku: uint8, uint16, uint32, uint64.\nLiczby zmiennoprzecinkowe: float16, float32, float64. Reprezentują liczby zmiennoprzecinkowe o różnej precyzji.\nLiczby zespolone: complex64, complex128.\nBoolean: bool.\nStringi i unicode: string_, unicode_.\n\nUżyte przez nas typy danych ma bezpośredni wpływ na ilość pamięci przydzielanej dla tablicy:\n\nRozmiar: Ilość pamięci potrzebna do przechowywania jednej tablicy jest równa ilości elementów w tablicy pomnożonej przez rozmiar jednego elementu (zdefiniowanego przez typ danych). Na przykład, tablica 1000 elementów typu int8 będzie zajmować 1000 bajtów pamięci.\nOperacje: Wybór odpowiedniego typu danych może wpłynąć na szybkość i dokładność operacji. Na przykład, operacje na typach z mniejszą precyzją (jak float16) mogą być szybsze, ale mniej dokładne.\nZakres: Mniejsze typy danych mają ograniczony zakres wartości, które mogą przechowywać. Na przykład, int8 może przechowywać wartości od -128 do 127.\n\nDlatego ważne jest, aby wybrać odpowiedni typ danych w zależności od potrzeb. Jeśli potrzebujesz zaoszczędzić pamięć i operacje nie wymagają dużej precyzji, możesz wybrać mniejszy typ danych. Jeśli jednak dokładność jest kluczowa, lepiej jest użyć większego, mimo większego zużycia pamięci.\n\n\n\nRozpocznijmy od dwóch definicji:\n\nSygnał Analogowy: - Sygnał w postaci wielkości fizycznej zmieniającej się w sposób ciągły, a nie skokowo. Jego wartości mogą zostać określone w każdej chwili.\nSygnał Cyfrowy: - Przeciwieństwem sygnału analogowego jest sygnał skwantowany, nazywany również dyskretnym. Kwantyzacja to działanie, które sygnał analogowy (liczbę rzeczywistą, o nieskończonym liczbie wartości w danym przedziale) przekształca w ograniczony zbiór liczb całkowitych, dzięki czemu możliwa jest dalsza obróbka tego sygnału przy pomocy komputera\n\n\n\n\n\n\n\nPrzykład kwantyzacji\n\n\n\nPrzykładem niech będzie sygnał EKG na obrazku poniżej\n\n\n\nEKG\n\n\n\n\nKonwersja sygnału analogowego do cyfrowego zachodzi zawsze z pewną ograniczoną dokładnością. Dokładność ta wynika ze skończonej precyzji reprezentacji liczb w systemach cyfrowych. Nazywamy to błędem kwantyzacji. Wiąże się to bezpośrednio z typami danych. Drugim typem błędu, który nas interesuje to błąd maszynowy.\nBłąd kwantyzacji: Pojawia się, gdy sygnał ciągły lub sygnał o dużej rozdzielczości jest przetwarzany do ograniczonej liczby dyskretnych poziomów. Na przykład, gdy analogowy sygnał dźwiękowy jest digitalizowany, jego wartości amplitudy są zaokrąglane do najbliższego poziomu kwantyzacji. Błąd kwantyzacji odnosi się do różnicy między rzeczywistą wartością sygnału a jego kwantyzowaną wartością.\nBłąd maszynowy: Jest to najmniejsza wartość, która może być reprezentowana w danym systemie numerycznym. Dla standardu liczby zmiennoprzecinkowej IEEE 754 (często używany w komputerach), błąd maszynowy określa minimalną różnicę między “1” a następną wartością, która może być reprezentowana. Błąd maszynowy jest ograniczeniem maszynowym i jest bezpośrednio związany z precyzją, z jaką liczby są reprezentowane w komputerze.\n\nOba typy błędów wynikają z ograniczeń w reprezentowaniu liczb.\nW kontekście przetwarzania sygnałów, błąd kwantyzacji często jest bardziej widoczny, ponieważ wpływa bezpośrednio na jakość rekonstrukcji sygnału. Jednak w obliczeniach numerycznych, błąd maszynowy może kumulować się w wielu operacjach i wpływać na dokładność wyników.\nW praktycznych zastosowaniach DSP (cyfrowe przetwarzanie sygnałów), błąd kwantyzacji jest często większym problemem niż błąd maszynowy, chyba że algorytm wymaga dużej precyzji w obliczeniach matematycznych.\n\nBłąd maszynowy, zwany także epsilonem maszynowym możemy w praktyce wyznaczyc korzystając z definicji, że jest to taka liczba, że:\n\\[1 + \\epsilon \\neq 1 \\tag{1}\\]\nw arytmetyce zmiennoprzecinkowej komputera. Dla typu float64 w bibliotece NumPy (co jest standardowym formatem liczby zmiennoprzecinkowej o podwójnej precyzji), epsilon maszynowy wynosi około \\(2.220446049250313 \\cdot e^−16\\).\n\n\n\n\n\nPacjenci w szpitalu otrzymują różne dawki leku w zależności od ich wagi. Stwórz funkcję, która przyjmuje listę wag pacjentów i zwraca listę z odpowiednimi dawkami leku. Dawka leku jest obliczana według następującej zasady:\n\nDla pacjentów o wadze poniżej 50 kg: 20 mg leku.\nDla pacjentów o wadze od 50 kg do 100 kg: 50 mg leku.\nDla pacjentów o wadze powyżej 100 kg: 100 mg leku.\n\nSygnatura funkcji:\ndef oblicz_dawki(wagi: np.ndarray) -&gt; np.ndarray:\n    pass # tutaj bedzie implementacja\nPrzykładowe działanie:\nDla tablicy wag: np.array([45, 75, 105]), funkcja powinna zwrócić: np.array([20, 50, 100]).\nPrzetestuj działanie funkcji na różnych zbiorach danych.\n\n\n\nW szpitalu prowadzone są badania dotyczące wpływu leku na ciśnienie krwi pacjentów. Dla listy pacjentów, która zawiera zapisane ciśnienie krwi przed i po podaniu leku, oblicz procent pacjentów, u których ciśnienie spadło po podaniu leku.\nMasz daną następującą listę ciśnień krwi:\ncisnienia = [\n    (120, 115),\n    (140, 138),\n    (130, 125),\n    (150, 155),\n    (110, 108)\n]\nKażda krotka zawiera dwie wartości: pierwsza to ciśnienie przed podaniem leku, a druga po podaniu leku.\nUżywając pętli, oblicz procent pacjentów z obniżonym ciśnieniem.\n\n\n\nW dziedzinie medycyny obrazowej często stosuje się przekształcenia obrazów. Jednym z najprostszych z nich jest progowanie (thresholding). Polega ono na porównywaniu wartości danego piksela z wartością progową i wpisywanie do niego wartości 255 jeśli jest większy od wartości progowej lub 0 jeśli jest mniejszy.\nTwoim zadaniem jest napisanie funkcji thresholding, która przyjmuje dwuwymiarową macierz (obraz) oraz wartość progową T i zwraca nową macierz po operacji thresholdingu.\nKażdy element tej macierzy reprezentuje piksel obrazu o wartościach od 0 (czarny) do 255 (biały). Piksele poniżej wartości T powinny być przekształcone na 0, podczas gdy piksele powyżej T powinny być przekształcone na 255.\nSygnatura funkcji:\ndef thresholding(obraz: np.ndarray, T: int) -&gt; np.ndarray:\n    pass #tutaj znajdzie sie implementacja Waszej funkcji\nPrzykładowa macierz:\nobraz = [\n    [120, 130, 140],\n    [150, 160, 170],\n    [180, 190, 200]\n]\nJeśli wartość progowa T wynosi 150, przekształcony obraz będzie wyglądać następująco:\n[\n    [0, 0, 0],\n    [255, 255, 255],\n    [255, 255, 255]\n]\n\n\n\nDane z EEG (elektroencefalografia) pacjenta są zapisane w postaci tablicy numpy reprezentującej napięcie zarejestrowane w kolejnych punktach czasowych. Chcielibyśmy analizować te dane w segmentach o określonej długości czasu (tzw. okna czasowe). Napisz generator, który będzie zwracać fragmenty tej tablicy.\nArgumenty funkcji: 1. Tablica numpy o nazwie eeg_data, reprezentująca dane EEG. 2. Liczba próbek na segment, segment_length.\nGenerator ma zwracać kolejne segmenty danych o długości segment_length. Jeśli w tablicy pozostanie mniej niż segment_length próbek, zwróć te pozostałe próbki.\nSygnatura funkcji:\ndef generator_segmentow_eeg(eeg_data: np.ndarray, segment_length: int):\n    ...\nPrzykład: Załóżmy, że mamy dane EEG w tablicy: np.array([0.5, 0.6, 0.7, 0.55, 0.65, 0.7, 0.8, 0.85]) i chcemy analizować segmenty o długości 3 próbek. - Pierwsze wywołanie next() zwróci np.array([0.5, 0.6, 0.7]). - Drugie wywołanie next() zwróci np.array([0.55, 0.65, 0.7]). - Trzecie wywołanie next() zwróci np.array([0.8, 0.85]). - Kolejne wywołanie next() spowoduje podniesienie wyjątku StopIteration.\nZadanie dodatkowe: Używając biblioteki NumPy wygeneruj tablicę 10.000 próbek sygnału EEG, dla uproszczenia przyjmijmy że będą to wartości losowe z przedziału 0-1, w typie danych float16. Przetestuj działanie swojego generatora dla różnych długości okna czasowego.\n\n\n\nZadanie: Kalkulator z *args i **kwargs\nCelem zadania jest stwotzenie uniwersalnego kalkulatora zdolnego do wykonania różnych operacji matematycznych na dowolnej liczbie argumentów z wykorzystaniem *args i **kwargs.\nInstrukcje:\n\nZaimplementuj funkcję o nazwie universal_calculator.\nFunkcja powinna przyjmować argumenty pozycyjne (*args) reprezentujące wartości liczbowe, na których chcemy wykonać operacje.\nFunkcja powinna również akceptować argumenty nazwane (**kwargs) do kontrolowania operacji:\n\noperation: określa typ operacji (możliwości: \"add\", \"substract\", \"multiply\", \"divide\"). Domyślnie powinna być to operacja dodawania.\npower: podniesienie wyniku do podanej potęgi.\n(Dla chętnych, opcjonalnie) show_steps: jeśli ustawiono na True, funkcja powinna dodatkowo drukować kroki obliczeń.\n\nFunkcja powinna zwracać końcowy wynik operacji.\n\nPrzykład użycia:\nprint(universal_calculator(1, 2, 3, 4))  # Domyślnie dodaje: 10\nprint(universal_calculator(1, 2, 3, operation=\"multiply\"))  # Mnoży: 6\nprint(universal_calculator(10, 2, operation=\"divide\", power=2))  # Dzieli, a następnie podnosi wynik do kwadratu: 25.0\nprint(universal_calculator(1, 2, 3, operation=\"add\", show_steps=True))\n# Drukowanie kroków:\n# 1 + 2 = 3\n# 3 + 3 = 6\n# Wynik: 6\nWskazówki: - Wykorzystaj pętlę for do iteracji przez args podczas wykonywania operacji. - Użyj instrukcji warunkowych do wyboru odpowiedniej operacji matematycznej. - Upewnij się, że kalkulator obsługuje potencjalne błędy, takie jak dzielenie przez zero.\n\n\n\nKorzystając z definicji epsilonu maszynowego napisz funkcję w języku Python, która oblicza epsilon maszynowy danego typu danych w bibliotece NumPy. Pamiętaj o deklaracji typu danych w obliczeniach. Zalecane jest skorzystanie z pętli.\n\n\n\nPoniżej przedstawiony jest kod, który mierzy czas wykonania pewnej operacji. Wykonaj analogiczne działanie z wykorzystaniem biblioteki NumPy, zmierz czas konieczny do jego wykonania, porównaj ten czas z czasem wykonania tradycyjnej metody.\nimport math\nimport time\n\n# Tworzymy listę wartości od 0 do 10^6\nvalues = [i * 0.001 for i in range(1000000)]\n\nstart_time = time.time()\n\nsin_values = []\nfor val in values:\n    sin_values.append(math.sin(val))\n\nend_time = time.time()\nprint(f\"Traditional loop took {end_time - start_time} seconds\")\n\n\n\nTwoim zadaniem jest stworzenie prostego kalkulatora oszczędnościowego, który pomoże użytkownikowi przewidzieć, ile pieniędzy uda mu się zaoszczędzić w ciągu określonego czasu.\nWymagania:\n\nUżytkownik powinien mieć możliwość podania początkowej kwoty oszczędności (może to być 0).\nUżytkownik powinien podać miesięczną kwotę, którą planuje oszczędzać.\nUżytkownik powinien podać roczne oprocentowanie swojego konta oszczędnościowego (np. 3% oznaczać będzie 0.03).\nUżytkownik powinien podać liczbę lat, przez które planuje oszczędzać.\n\nTwoim zadaniem jest:\n\nObliczenie końcowej sumy oszczędności po określonym czasie, uwzględniając oprocentowanie.\nWykorzystanie odpowiednich typów danych w Pythonie do reprezentowania tych wartości (np. float dla kwot i oprocentowania, int dla liczby lat).\n\nFormuła oszczędności z oprocentowaniem składanym miesięcznie:\n\\[A = P \\left(1 + \\frac{r}{n}\\right)^{nt} + PMT \\left[ \\frac{\\left(1 + \\frac{r}{n}\\right)^{nt} - 1}{\\frac{r}{n}} \\right]\\]\nGdzie:\n\nA to końcowa suma oszczędności.\nP to początkowa suma oszczędności.\nr to roczna stopa procentowa (jako ułamek, np. 3% to 0.03).\nn to liczba okresów kapitalizacji w ciągu roku (dla kapitalizacji miesięcznej n=12n=12).\nt to liczba lat oszczędzania.\nPMT to stała miesięczna wpłata."
  },
  {
    "objectID": "labs/lab1.html#zakres-tematyczny",
    "href": "labs/lab1.html#zakres-tematyczny",
    "title": "Laboratorium 1",
    "section": "",
    "text": "Wprowadzenie w temat obliczeń numerycznych w języku Python\nPodstawy Pythona - Przypomnienie\nPodstawy użycia bibliotek:\n\nNumpy\nSciPy\nMatPlotLib\n\nTypy Danych w Numpy\nBłędy numeryczne i ich propagacja\nBiblioteka PyTorch"
  },
  {
    "objectID": "labs/lab1.html#obliczenia-numeryczne-w-języku-python",
    "href": "labs/lab1.html#obliczenia-numeryczne-w-języku-python",
    "title": "Laboratorium 1",
    "section": "",
    "text": "Obliczenia numeryczne odgrywają kluczową rolę w wielu dziedzinach nauki i inżynierii. Python, dzięki swoim bibliotekom i cechom języka, stał się popularnym wyborem do przeprowadzania obliczeń numerycznych. Oto kilka powodów, dla których Python jest często wybierany do tego celu:\nCzytelność: Składnia Pythona jest przejrzysta i zwięzła, co pozwala na łatwe pisanie i analizę kodu.\nBiblioteki: Python posiada bogaty zestaw bibliotek do obliczeń numerycznych, takich jak:\n\nNumPy: Biblioteka do obliczeń numerycznych, oferująca wsparcie dla dużych tablic i macierzy wielowymiarowych oraz zestaw funkcji matematycznych do ich operowania.\nSciPy: Oparta na NumPy, jest to biblioteka służąca do bardziej zaawansowanych obliczeń i algorytmów naukowych.\nPandas: Biblioteka do analizy danych, która dostarcza struktury danych i funkcje niezbędne do czyszczenia, agregacji i analizy danych.\n\nInteraktywność: Narzędzia takie jak Jupyter Notebook pozwalają na interaktywne eksplorowanie danych i obliczeń, co jest niezmiernie użyteczne w analizie naukowej.\nIntegracja z innymi językami: Python może być łatwo zintegrowany z kodem napisanym w językach takich jak C, C++ czy Fortran, co pozwala na łączenie szybkości tych języków z elastycznością Pythona.\nWizualizacja Danych: Biblioteki takie jak Matplotlib, Seaborn czy Plotly umożliwiają tworzenie zaawansowanych wizualizacji, które są kluczowe do analizy wyników obliczeń numerycznych.\nWspólnota: Python ma ogromną społeczność, która stale tworzy i udostępnia nowe narzędzia, biblioteki i zasoby do obliczeń numerycznych.\nWszechstronność: Poza obliczeniami numerycznymi, Python jest językiem ogólnego zastosowania, co oznacza, że można go używać również do web developmentu, automatyki, analizy danych, sztucznej inteligencji i wielu innych zastosowań. Dzięki temu badacze i inżynierowie mogą korzystać z jednego języka do wielu różnych zadań.\nOtwarte oprogramowanie: Python jest językiem open source, co oznacza, że jest dostępny za darmo i ma dużą społeczność deweloperów pracujących nad jego rozwojem."
  },
  {
    "objectID": "labs/lab1.html#podstawy-pythona",
    "href": "labs/lab1.html#podstawy-pythona",
    "title": "Laboratorium 1",
    "section": "",
    "text": "Python to wysokopoziomowy język programowania stworzony przez Guido van Rossuma i po raz pierwszy opublikowany w 1991 roku. Charakteryzuje się czytelną składnią, która pozwala programistom wyrażać koncepty w mniejszej ilości kodu niż w językach takich jak C++ czy Java.\nDziałanie Pythona na poziomie szczegółów można opisać w kilku kluczowych krokach. W skrócie, działanie Pythona polega na tym, że kod źródłowy jest interpretowany przez interpreter Pythona w kod bajtowy, który następnie jest wykonywany przez maszynę wirtualną Pythona.\nOto bardziej szczegółowy przegląd tego, jak to działa:\n\nKod źródłowy: Wszystko zaczyna się od kodu źródłowego, który piszesz w pliku .py.\nKompilacja do kodu bajtowego: Gdy uruchamiasz skrypt Pythona, interpreter (zazwyczaj CPython, który jest standardową implementacją Pythona) kompiluje ten kod źródłowy w kod bajtowy. Kod bajtowy to niskopoziomowe, platformowo niezależne przedstawienie twojego kodu źródłowego. Zostaje on zapisany w plikach .pyc w katalogu pycache.\nMaszyna wirtualna Pythona (PVM): Po skompilowaniu kodu, kod bajtowy jest przekazywany do Maszyny Wirtualnej Pythona (PVM). To tu właściwe wykonanie kodu ma miejsce. PVM interpretuje i wykonuje kod bajtowy linia po linii.\nZarządzanie pamięcią: Python automatycznie zarządza pamięcią dzięki mechanizmowi zwanej “garbage collection”. Python posiada wbudowany licznik odniesień, który śledzi liczbę odniesień do każdego obiektu w pamięci. Gdy liczba odniesień do obiektu spada do zera, pamięć zajmowana przez obiekt jest automatycznie zwalniana. Dodatkowo, cykliczne odniesienia (gdzie obiekty odnoszą się nawzajem, ale nie są dostępne z żadnej innej części kodu) są wykrywane przez garbage collector i odpowiednio czyszczone.\nRozszerzenia w języku C: Jednym z mocnych stron Pythona jest jego zdolność do integrowania się z językami niższego poziomu, takimi jak C. Możesz pisać rozszerzenia w C, które są potem dostępne jako moduły w Pythonie. To pozwala na pisania bardziej wydajnych fragmentów kodu w C i korzystania z nich w Pythonie.\nBiblioteki standardowe: Python ma bogate biblioteki standardowe, które oferują funkcje dla wielu powszechnych zadań, od pracy z plikami i sieciami po analizę danych i tworzenie interfejsów graficznych.\nInterfejs API C: Python ma dobrze zdefiniowany API dla języka C, co pozwala na tworzenie rozszerzeń w C oraz na osadzanie interpretera Pythona w aplikacjach napisanych w C.\n\n\n\n\nW języku Python najprostsza deklaracja funkcji wygląda następująco:\ndef my_first_function():\n    pass\nFunkcja ta nie przyjmuje ani nie zwraca niczego.\nFunkcje mogą przyjmowac argumenty:\nArgumenty pozycyjne: Są to najczęściej używane argumenty. Przekazujesz je w kolejności, w jakiej są wymienione w definicji funkcji.\ndef funkcja(a, b, c):\n    print(a, b, c)\n\nfunkcja(1, 2, 3)  # 1 2 3\nArgumenty nazwane (keyword arguments): Przekazujemy wartość, wskazując nazwę argumentu.\nfunkcja(a=1, c=3, b=2)  # 1 2 3\nDomyślne wartości argumentów: Możesz ustawić domyślne wartości dla niektórych (lub wszystkich) argumentów.\ndef funkcja(a, b=2, c=3):\n    print(a, b, c)\n\nfunkcja(1)  # 1 2 3\nfunkcja(1, c=4)  # 1 2 4\n\n\n\n*args i **kwargs to konwencje w Pythonie do obsługi zmiennej liczby argumentów w funkcjach. Dzięki nim możemy przekazywać do funkcji różną liczbę argumentów w sposób bardziej elastyczny.\n\n\n*args pozwala na przekazywanie dowolnej liczby pozycyjnych argumentów do funkcji. W ciele funkcji argumenty te są dostępne jako krotka. Przykład:\ndef suma(*args):\n    return sum(args)\n\nprint(suma(1, 2, 3, 4))  # 10\nprint(suma(10, 20))      # 30\n\n\n\n**kwargs pozwala na przekazywanie dowolnej liczby nazwanych (klucz-wartość) argumentów do funkcji. W ciele funkcji argumenty te są dostępne jako słownik. Przykład:\ndef opis_osoby(**kwargs):\n    for klucz, wartosc in kwargs.items():\n        print(f\"{klucz}: {wartosc}\")\n\nopis_osoby(imie=\"Jan\", nazwisko=\"Kowalski\", wiek=30)\nWynik:\nimie: Jan\nnazwisko: Kowalski\nwiek: 30\nOczywiście, można łączyć *args i **kwargs w jednej funkcji:\ndef funkcja_przykladowa(a, b, *args, **kwargs):\n    print(a, b)\n    print(args)\n    print(kwargs)\n\nfunkcja_przykladowa(1, 2, 3, 4, 5, klucz1=\"wartosc1\", klucz2=\"wartosc2\")\nWynik:\n1 2\n(3, 4, 5)\n{'klucz1': 'wartosc1', 'klucz2': 'wartosc2'}\n\n\n\n\nW Pythonie występują dwa rodzaje pętli: for i while.\n\n\nPętla for jest używana do iterowania po sekwencji (to może być lista, krotka, słownik, zbiór lub łańcuch znaków).\nSkładnia:\nfor zmienna in sekwencja:\n    # instrukcje\nPrzykład: Iteracja po liście:\nfruits = [\"jablko\", \"gruszka\", \"pietruszka\"]\nfor fruit in fruits:\n    print(fruit)\nZa pomocą funkcji range(), pętlę for można również użyć do wykonywania określonej liczby iteracji:\nfor i in range(5):  # będzie wykonywać pętlę od 0 do 4\n    print(i)\n\n\n\nPętla while wykonuje blok kodu tak długo, jak długo warunek pętli jest prawdziwy.\nSkładnia:\nwhile warunek:\n    # instrukcje\nPrzykład:\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\n\n\n\n\nOprócz podstawowych instrukcji pętli, w Pythonie istnieją również instrukcje umożliwiające kontrolę przepływu w pętlach:\n\nbreak: Przerywa działanie pętli i przechodzi do kolejnej instrukcji poza pętlą.\nPrzykład:\nfor i in range(5):\n    if i == 3:\n        break\n    print(i)\ncontinue: Przerywa bieżący cykl pętli i przechodzi do następnego cyklu.\nPrzykład:\nfor i in range(5):\n    if i == 3:\n        continue\n    print(i)\nelse: W Pythonie pętle mogą mieć opcjonalną klauzulę else. Wykonuje się ona, gdy pętla kończy swoje działanie normalnie (nie przez break).\nPrzykład:\nfor i in range(5):\n    print(i)\nelse:\n    print(\"Pętla zakończona\")\n\n\n\n\nGenerator w Pythonie to specjalny rodzaj iteratora, który pozwala na generowanie wartości “na bieżąco” w miarę ich potrzeby, zamiast generować wszystkie wartości naraz i przechowywać je w pamięci. Dzięki temu generatory są bardziej wydajne pod względem alokacji pamięci. Ma to znaczenie zwłaszcza przy pracy z dużymi zbiorami danych.\nGeneratory tworzy się głównie w dwóch sposobach:\n\nZa pomocą funkcji i słowa kluczowego yield.\nZa pomocą wyrażeń generatora (podobnie jak list comprehension, ale w nawiasach okrągłych).\n\nPrzykład:\ndef even_numbers_generator(n):\n    for i in range(n):\n        if i % 2 == 0:\n            yield i\n\ngen = even_numbers_generator(10)\nfor number in gen:\n    print(number)\nOto inny przykład generatora, który zwraca nieskończony ciąg liczb w postaci ciągu geometrycznego o zadanej podstawie:\ndef geometric_sequence(a, r):\n    while True:\n        yield a\n        a *= r\n\n# Przykład użycia\ngen = geometric_sequence(1, 2)  # podstawa 1, iloraz 2\nfor _ in range(5):\n    print(next(gen))\nGeneratory są także często używane do wczytywania danych\n\n\n\n\n\n\nModelowanie sygnału PPG z wykorzystaniem generatora\n\n\n\nRozważmy generator danych dla symulacji sygnału fotopletyzmograficznego (PPG), który jest wykorzystywany do monitorowania tętna i saturacji tlenu w krwi. Sygnał PPG jest rejestrowany za pomocą czujnika optycznego umieszczonego na skórze, który wykrywa zmiany objętości krwi w naczyniach krwionośnych.\nNie zawsze mamy dostęp do takiego sygnału, co więcej - czasami chcemy sami wygenerowac sygnały o konkretnym kształcie, charakterystycznych zniekształceniach, aby przetestowac pewne algorytmy.\nMożemy to zrobic z wykorzystaniem generatora:\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef synthetic_ppg_generator(frequency=100):\n    \"\"\"\n    Generator syntetycznego sygnału PPG.\n    \n    frequency: częstotliwość próbkowania sygnału [Hz]\n    \"\"\"\n    t = 0  # czas [s]\n    dt = 1.0 / frequency\n    while True:\n        # Modelujemy podstawowy kształt fali PPG przy użyciu równania\n        ppg_wave = np.abs(np.sin(t)) + 0.3 * np.sin(4 * np.pi * t) - 0.15 * np.sin(6 * np.pi * t)\n        \n        yield ppg_wave\n        t += dt\n\n# Przykład użycia:\nppg_gen = synthetic_ppg_generator(frequency=100)\n\n# Wygenerowanie 5s sygnału PPG (500 próbek, ponieważ frequency=100Hz)\nppg_signal = [next(ppg_gen) for _ in range(500)]\n\n# Rysujemy sygnał\nplt.plot(ppg_signal)\nplt.title(\"Syntetyczny sygnał PPG\")\nplt.xlabel(\"Próbka\")\nplt.ylabel(\"Amplituda\")\nplt.show()\n\n\n\nWygenerowany sygnał PPG"
  },
  {
    "objectID": "labs/lab1.html#wybrane-biblioteki-numeryczne-pythona",
    "href": "labs/lab1.html#wybrane-biblioteki-numeryczne-pythona",
    "title": "Laboratorium 1",
    "section": "",
    "text": "NumPy to podstawowa biblioteka do obliczeń naukowych w Pythonie, która dostarcza wsparcie dla dużych, wielowymiarowych tablic i macierzy oraz wielu matematycznych funkcji do operacji na tych tablicach. Oto kilka najważniejszych cech biblioteki NumPy w kontekście metod numerycznych:\n\nWektoryzacja:\n\nPozwala na wykonywanie operacji na całych tablicach bez potrzeby stosowania pętli.\nOperacje wektoryzowane są znacznie bardziej wydajne niż ich odpowiedniki bazujące na pętlach, dzięki zastosowaniu optymalizowanych funkcji niskiego poziomu napisanych w językach takich jak C i Fortran.\n\n\n\n\n\n\n\n\nPrzykład wektoryzacji\n\n\n\nZałóżmy, że chcemy dodać elementy dwóch dużych list do siebie. Możemy to zrobić na dwa sposoby:\n\nTradycyjnie:\n\nlist1 = [1, 2, 3, 4, 5]\nlist2 = [5, 4, 3, 2, 1]\nresult = []\n\nfor i in range(len(list1)):\n    result.append(list1[i] + list2[i])\n\nprint(result)\n\nZ wykorzystaniem biblioteki NumPy i wektoryzacji:\n\nimport numpy as np\n\narray1 = np.array([1, 2, 3, 4, 5])\narray2 = np.array([5, 4, 3, 2, 1])\n\nresult_array = array1 + array2\nprint(result_array)\nZobaczmy teraz, co robi NumPy:\nGdy wykonujemy operację result_array = array1 + array2, NumPy wykonuje kilka kroków:\n\nSprawdzanie wymiarów: Najpierw NumPy sprawdzi, czy obie tablice mają taki sam kształt (shape). Jeśli nie mają, zostanie zgłoszony błąd (chyba że możliwe jest “rozgłaszanie” (broadcasting), ale to bardziej zaawansowana funkcjonalność).\nAlokacja pamięci: NumPy alokuje pamięć dla wynikowej tablicy, która będzie miała taki sam kształt jak array1 i array2.\nOperacje element po elemencie: Następnie, dla każdego indeksu w tablicach, NumPy dodaje wartości z array1 i array2, a wynik zapisuje w odpowiednim miejscu w result_array.\n\nW rzeczywistości, proces jest bardziej skomplikowany i zoptymalizowany pod kątem wydajności. Dzięki wektoryzacji i natywnym, optymalizowanym funkcjom niskiego poziomu, operacje takie jak ta są wykonane bardzo szybko.\n\n\n\nEfektywna organizacja pamięci:\n\n\nTablice NumPy są jednorodne i przechowywane w ciągłych blokach pamięci. W przeciwieństwie do list w Pythonie, które są tablicami wskaźników, tablice NumPy zajmują mniej miejsca i umożliwiają szybszy dostęp do danych.\nObsługuje też widoki (views), które pozwalają na dostęp do danych bez ich kopiowania, co jest szczególnie przydatne w dużych zbiorach danych.\n\n\nParalelizacja:\n\n\nChociaż sama NumPy nie obsługuje paralelizacji na poziomie wielu wątków, jej operacje są zoptymalizowane do wykorzystania jednostek SSE/AVX dostępnych w nowoczesnych procesorach, co przyspiesza wiele operacji.\nDodatkowo, biblioteki takie jak Dask czy Numba pozwalają na łatwą paralelizację i kompilację operacji NumPy dla jeszcze większej wydajności.\n\n\nWsparcie dla operacji algebry liniowej, transformacji Fouriera i funkcji statystycznych:\n\n\nDostarcza funkcje do rozwiązywania układów równań, obliczania wartości własnych, dekompozycji oraz innych kluczowych operacji algebry liniowej.\nWbudowane funkcje do operacji na liczbach zespolonych oraz do wykonywania transformacji Fouriera.\n\n\nWsparcie dla różnych typów danych:\n\n\nObsługuje szeroki zakres typów danych, w tym typy liczbowe (całkowite, zmiennoprzecinkowe, zespolone) oraz typy dat i czasów.\n\n\nInteroperacyjność:\n\n\nMoże współdziałać z bibliotekami napisanymi w innych językach, takimi jak C, C++ czy Fortran, co pozwala na wykorzystanie istniejących, optymalizowanych kodów.\nŁatwa integracja z innymi bibliotekami do analizy danych, takimi jak pandas czy SciPy.\n\n\nRozszerzalność:\n\n\nMożliwość tworzenia własnych typów danych i funkcji ufunc, które zachowują się jak wbudowane operacje wektoryzowane.\n\nW kontekście metod numerycznych, NumPy dostarcza solidne narzędzie do szybkiego i wydajnego przetwarzania danych oraz implementacji algorytmów numerycznych w Pythonie.\n\n\n\nDrugą z wykorzystywanych przez nas bibliotek jest biblioteka SciPy - rozbudowana biblioteka służąca do obliczeń naukowych i inżynierskich w języku Python. Biblioteka ta bazuje na NumPy, ale dodaje sporo rzeczy “od siebie”. Przejdźmy przez jej najważniejsze moduły:\n\nModuł do optymalizacji (scipy.optimize): Narzędzia do znajdowania korzeni równań i minimalizacji funkcji.\nModuł do algebry liniowej (scipy.linalg): Funkcje do rozwiązywania równań liniowych, obliczania wartości własnych itp.\nModuł do przetwarzania sygnałów (scipy.signal): Narzędzia do analizy, projektowania i przetwarzania sygnałów.\nModuł do analizy obrazów (scipy.ndimage): Funkcje do przetwarzania i analizy obrazów.\nModuł do statystyki (scipy.stats): Obszerna kolekcja funkcji do statystyki i rozkładów prawdopodobieństwa.\nModuł do całkowania (scipy.integrate): Narzędzia do całkowania funkcji i równań różniczkowych.\n\n\n\n\n\n\n\nPrzykład obliczeń z wykorzystaniem SciPy\n\n\n\nZałóżmy, że chcemy znaleźc minimum jakiejś funkcji. Zobaczmy jak możemy to zrobic z wykorzystaniem biblioteki SciPy:\nfrom scipy.optimize import minimize\n\n# Definiujemy funkcję\ndef f(x):\n    return x**2 + 6*x + 5\n\n# Znajdujemy minimum funkcji zaczynając od punktu x=0\nresult = minimize(f, x0=0)\n\n# Wypisujemy wynik\nprint(f\"Minimum value of f(x) is {result.fun} at x = {result.x}\")\n\n\nPrzeanalizujmy jeszcze jeden, bardzo ważny przykład, który łączy w sobie wykorzystanie biblioteki SciPy oraz pewne specyficzne cechy wykonywania obliczeń numerycznych.\n\n\n\n\n\n\nPrzykład rozwiązywania układu równań\n\n\n\nW szpitalu są dwie grupy pacjentów: osoby z grypą i osoby z zatruciem pokarmowym. Pierwszego dnia przyszło 5 pacjentów z grypą i 3 z zatruciem pokarmowym. Wszyscy razem otrzymali 23 tabletki paracetamolu. Drugiego dnia przyszło 2 osoby z grypą i 3 z zatruciem pokarmowym, a łączna liczba tabletek paracetamolu, które dostali, wynosiła 13. Jaką dawkę paracetamolu otrzymuje pacjent z grypą oraz pacjent z zatruciem pokarmowym?\nZałóżmy, że:\n\nDawka dla pacjenta z grypą to \\(x\\) tabletek.\nDawka dla pacjenta z zatruciem to \\(y\\) tabletek.\n\nNa podstawie powyższych informacji uzyskujemy układ równań:\n\\(5x+3y=23\\) (pierwszy dzień)\n\\(2x+3y=13\\) (drugi dzień)\nRozwiążmy zatem ten układ równań, korzystając z biblioteki SciPy:\nimport numpy as np\nfrom scipy.linalg import solve\n\n# Macierz współczynników\nA = np.array([[5, 3], [2, 3]])\n\n# Wektor wyników\nb = np.array([23, 13])\n\n# Rozwiązujemy układ równań\nx, y = solve(A, b)\n\nprint(f\"Dawka dla pacjenta z grypą: {x:.2f} tabletki\")\nprint(f\"Dawka dla pacjenta z zatruciem pokarmowym: {y:.2f} tabletki\")\n\n\n\n\n\nBiblioteka matplotlib to jedno z najpopularniejszych narzędzi do tworzenia wizualizacji danych w Pythonie. Dzięki niej można tworzyć różnorodne wykresy, od podstawowych liniowych czy słupkowych, po bardziej zaawansowane jak histogramy, wykresy punktowe czy konturowe.\nNajważniejsze cechy biblioteki matplotlib:\n\nWszechstronność: Możliwość tworzenia wielu typów wykresów.\nDostosowywalność: Wielkie możliwości konfiguracji wyglądu wykresów.\nInteraktywność: Możliwość tworzenia interaktywnych wizualizacji.\nIntegracja z innymi bibliotekami: matplotlib integruje się z wieloma innymi bibliotekami Pythona takimi jak pandas czy numpy.\nPodmoduł pyplot: Zapewnia interfejs podobny do MATLAB-a, co jest przydatne dla osób znających to środowisko.\nWsparcie dla różnych formatów: Możliwość zapisu w wielu popularnych formatach graficznych jak PNG, PDF, SVG i innych.\n\n\n\n\n\n\n\nProsty przykład:\n\n\n\nStworzymy wykres przedstawiający funkcje sinus i cosinus na tym samym rysunku z dodatkową konfiguracją:\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Dane\nx = np.linspace(0, 2 * np.pi, 400)\ny1 = np.sin(x)\ny2 = np.cos(x)\n\n# Tworzenie wykresu\nplt.figure(figsize=(10,6))  # ustawienie rozmiaru wykresu\nplt.plot(x, y1, label='sin(x)', color='blue', linewidth=2)  # wykres funkcji sinus\nplt.plot(x, y2, label='cos(x)', color='red', linestyle='--', linewidth=2)  # wykres funkcji cosinus\n\n# Dodanie tytułu i etykiet osi\nplt.title('Funkcje sinus i cosinus')\nplt.xlabel('x')\nplt.ylabel('y')\n\n# Dodanie siatki i legendy\nplt.grid(True, which='both', linestyle='--', linewidth=0.5)\nplt.legend()\n\n# Wyświetlenie wykresu\nplt.tight_layout()  # automatyczne dopasowanie elementów wykresu\nplt.show()\nTen kod utworzy wykres funkcji sinus i cosinus.\n\n\nPrzeanalizujmy bardziej efektowny przykład:\n\n\n\n\n\n\nSymulowany oscyloskop\n\n\n\nZałóżmy, że chcemy przedstawic komuś koncepcję trzech sygnałów oscyloskopowych:\n\nsygnał sinusoidalny\nsygnał prostokątny\nsygnał trójkątny\n\nStworzymy wykres tych sygnałów wraz z opisem, skalą oraz powiększeniem fragmentu jednego z sygnałów.\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Generowanie sygnałów\nt = np.linspace(0, 5 * np.pi, 1000)\nsin_wave = np.sin(t)\nsquare_wave = np.sign(sin_wave)\ntriangle_wave = 2 * np.arcsin(sin_wave) / np.pi\n\n# Tworzenie głównego wykresu\nfig, ax = plt.subplots(figsize=(12, 8))\n\nax.plot(t, sin_wave, label=\"Sinusoidalny\", color=\"blue\")\nax.plot(t, square_wave, label=\"Prostokątny\", color=\"red\", linestyle=\"--\")\nax.plot(t, triangle_wave, label=\"Trójkątny\", color=\"green\", linestyle=\"-.\")\n\n# Ustawienia wykresu\nax.set_title(\"Sygnały oscyloskopowe\")\nax.set_xlabel(\"Czas\")\nax.set_ylabel(\"Amplituda\")\nax.grid(True, linestyle='--', alpha=0.7)\nax.legend()\n\n# Powiększenie fragmentu wykresu\naxins = ax.inset_axes([0.2, 0.2, 0.3, 0.3])  # [x, y, width, height]\naxins.plot(t, sin_wave, color=\"blue\")\naxins.plot(t, square_wave, color=\"red\", linestyle=\"--\")\naxins.plot(t, triangle_wave, color=\"green\", linestyle=\"-.\")\nx1, x2, y1, y2 = 7, 8, -1.5, 1.5  # zakres fragmentu do powiększenia\naxins.set_xlim(x1, x2)\naxins.set_ylim(y1, y2)\naxins.grid(True, linestyle='--', alpha=0.7)\n\n# Zaznaczenie fragmentu do powiększenia na głównym wykresie\nrect = patches.Rectangle((x1, y1), x2-x1, y2-y1, edgecolor='gray', facecolor='none', linestyle=\":\")\nax.add_patch(rect)\nax.indicate_inset_zoom(axins, edgecolor=\"gray\")\n\nplt.tight_layout()\nplt.show()\nTen kod generuje wykres trzech różnych sygnałów oscyloskopowych wraz z legendą, skalą i powiększeniem fragmentu wykresu, pokazującym interesujący obszar tych sygnałów. Zakres powiększenia został zaznaczony na głównym wykresie szarą linią przerywaną.\n\n\n\n\n\nPyTorch to otwartoźródłowa biblioteka do uczenia maszynowego, stworzona głównie przez Facebook’s AI Research lab. PyTorch jest znany ze swojej elastyczności i dynamicznej kompilacji, co sprawia, że jest szczególnie użyteczny w badaniach. Umożliwia budowanie różnego rodzaju modeli głębokiego uczenia oraz oferuje wsparcie dla GPU, co przyspiesza obliczenia.\n\n\n\n\n\n\nPrzykład wykorzystania biblioteki PyTorch\n\n\n\nPrzeanalizujmy przykład wykorzystania PyTorch do rozwiązania problemu matematycznego polegającego na znalezieniu minimum funkcji kwadratowej. W tym celu użyjemy koncepcji różniczkowania i spadku gradientu (dowiecie się o tym na kolejnych zajęciach z naszego przedmiotu, proszę chwilowo się nie martwic), ale bez wchodzenia głęboko w kontekst uczenia maszynowego.\n\n\nZnajdź wartość \\(x\\), która minimalizuje funkcję \\(f(x) = x^2 + 4x + 4\\).\n\n\n\n\nInicjalizuj zmienną \\(x\\) z losową wartością.\nOblicz wartość funkcji \\(f\\) dla aktualnej wartości \\(x\\).\nOblicz gradient funkcji względem \\(x\\) (to informuje nas, w którym kierunku powinniśmy aktualizować \\(x\\) w celu zminimalizowania \\(f\\)).\nAktualizuj \\(x\\) w kierunku przeciwnym do gradientu.\nPowtarzaj kroki 2-4 przez pewną liczbę iteracji lub do osiągnięcia pewnego progu dokładności.\n\n\n\n\nimport torch\n\n# Krok 1: Inicjalizuj zmienną x z losową wartością i wymaganiem obliczania gradientu.\nx = torch.randn(1, requires_grad=True)\n\n# Definicja optymalizatora\nlearning_rate = 0.1\noptimizer = torch.optim.SGD([x], lr=learning_rate)\n\n# Iteracje optymalizacji\nfor iteration in range(100):\n    # Krok 2: Oblicz wartość funkcji f dla aktualnej wartości x.\n    f = x**2 + 4*x + 4\n    \n    # Krok 3: Oblicz gradient funkcji\n    f.backward()\n    \n    # Krok 4: Aktualizuj x w kierunku przeciwnym do gradientu.\n    optimizer.step()\n    \n    # Zeruj gradienty dla następnej iteracji.\n    optimizer.zero_grad()\n\nprint(f'Minimum funkcji f(x) = x^2 + 4x + 4 jest w punkcie x = {x.item()}')\nW tym przykładzie korzystamy z PyTorch do obliczenia gradientów i optymalizacji wartości \\(x\\), aby zminimalizować funkcję \\(f\\). Nie używamy tu żadnych zaawansowanych koncepcji uczenia maszynowego, ale skupiamy się na podstawach różniczkowania i optymalizacji.\nNo dobra, ale dlaczego zatem nie używamy do tego po prostu biblioteki NumPy. Z kilku powodów, niestety niewidocznych gołym okiem na tak prostym przykładzie. Porównując podejście z wykorzystaniem NumPy, do podejścia z wykorzystaniem PyTorch-a, możemy określic pewne różnice (oraz co za tym idzie cechy biblioteki PyTorch)\n\nAutomatyczne różniczkowanie:\n\nPyTorch: PyTorch oferuje automatyczne różniczkowanie dzięki backward(). Pozwala to na obliczenie gradientu funkcji bez konieczności ręcznego określania jego formy.\nNumPy: W NumPy musiałbyś ręcznie wyznaczyć gradient funkcji, co dla naszej funkcji kwadratowej jest proste, ale dla bardziej skomplikowanych funkcji może być trudne.\n\nWsparcie dla GPU:\n\nPyTorch: PyTorch może przeprowadzać obliczenia zarówno na CPU, jak i GPU. Dzięki temu operacje mogą być przyspieszone dla dużych zbiorów danych lub skomplikowanych modeli.\nNumPy: NumPy działa tylko na CPU. Istnieją biblioteki, takie jak CuPy, które oferują podobne do NumPy interfejsy na GPU, ale standardowy NumPy nie oferuje tej funkcjonalności.\n\nAktualizacja zmiennych:\n\nPyTorch: Optymalizatory w PyTorch (np. torch.optim.SGD) automatycznie aktualizują wartość zmiennych w odpowiedzi na obliczone gradienty.\nNumPy: Musiałbyś ręcznie zaktualizować wartość zmiennej na podstawie gradientu, np. x = x - learning_rate * gradient.\n\nIntegracja z głębokim uczeniem:\n\nJeśli w przyszłości chciałbyś rozbudować rozwiązanie, np. dodać warstwy sieci neuronowej, PyTorch oferuje gotowe do użycia narzędzia i struktury, które ułatwiają to zadanie.\nW przypadku NumPy musiałbyś samodzielnie zaimplementować wiele elementów związanych z sieciami neuronowymi.\n\n\nChociaż dla naszego prostego problemu różnice te mogą wydawać się niewielkie, dla bardziej skomplikowanych problemów i większych zbiorów danych zalety PyTorch stają się bardziej widoczne.\nJeśli jednak chodzi o nasz konkretny problem z minimalizacją funkcji kwadratowej, można go łatwo rozwiązać przy użyciu NumPy, obliczając ręcznie gradient i aktualizując wartość \\(x\\) w pętli. PyTorch jest tutaj używany bardziej jako demonstracja jego możliwości niż konieczność."
  },
  {
    "objectID": "labs/lab1.html#typy-danych",
    "href": "labs/lab1.html#typy-danych",
    "title": "Laboratorium 1",
    "section": "",
    "text": "Kluczową strukturą danych w numpy jest ndarray (n-wymiarowa tablica danych), która pozwala na przechowywanie i operacje na dużych zbiorach danych w efektywny sposób.\nKażda tablica ndarray ma atrybut o nazwie dtype, który wskazuje typ danych przechowywanych w tablicy. dtype definiuje:\n\nRodzaj danych (np. liczba całkowita, liczba zmiennoprzecinkowa, boolean, itp.).\nIlość pamięci potrzebną do przechowywania jednego elementu tego typu.\nZakres wartości, jakie można w niej przechowywać.\nPrecyzję (dla liczb zmiennoprzecinkowych).\n\nPrzedstawmy kilka podstawowych typów danych w bibliotece NumPy :\n\nLiczby całkowite: int8, int16, int32, int64 (odpowiednio 8, 16, 32, 64 bity). Dla liczb bez znaku: uint8, uint16, uint32, uint64.\nLiczby zmiennoprzecinkowe: float16, float32, float64. Reprezentują liczby zmiennoprzecinkowe o różnej precyzji.\nLiczby zespolone: complex64, complex128.\nBoolean: bool.\nStringi i unicode: string_, unicode_.\n\nUżyte przez nas typy danych ma bezpośredni wpływ na ilość pamięci przydzielanej dla tablicy:\n\nRozmiar: Ilość pamięci potrzebna do przechowywania jednej tablicy jest równa ilości elementów w tablicy pomnożonej przez rozmiar jednego elementu (zdefiniowanego przez typ danych). Na przykład, tablica 1000 elementów typu int8 będzie zajmować 1000 bajtów pamięci.\nOperacje: Wybór odpowiedniego typu danych może wpłynąć na szybkość i dokładność operacji. Na przykład, operacje na typach z mniejszą precyzją (jak float16) mogą być szybsze, ale mniej dokładne.\nZakres: Mniejsze typy danych mają ograniczony zakres wartości, które mogą przechowywać. Na przykład, int8 może przechowywać wartości od -128 do 127.\n\nDlatego ważne jest, aby wybrać odpowiedni typ danych w zależności od potrzeb. Jeśli potrzebujesz zaoszczędzić pamięć i operacje nie wymagają dużej precyzji, możesz wybrać mniejszy typ danych. Jeśli jednak dokładność jest kluczowa, lepiej jest użyć większego, mimo większego zużycia pamięci."
  },
  {
    "objectID": "labs/lab1.html#błędy-numeryczne-i-ich-propagacja",
    "href": "labs/lab1.html#błędy-numeryczne-i-ich-propagacja",
    "title": "Laboratorium 1",
    "section": "",
    "text": "Rozpocznijmy od dwóch definicji:\n\nSygnał Analogowy: - Sygnał w postaci wielkości fizycznej zmieniającej się w sposób ciągły, a nie skokowo. Jego wartości mogą zostać określone w każdej chwili.\nSygnał Cyfrowy: - Przeciwieństwem sygnału analogowego jest sygnał skwantowany, nazywany również dyskretnym. Kwantyzacja to działanie, które sygnał analogowy (liczbę rzeczywistą, o nieskończonym liczbie wartości w danym przedziale) przekształca w ograniczony zbiór liczb całkowitych, dzięki czemu możliwa jest dalsza obróbka tego sygnału przy pomocy komputera\n\n\n\n\n\n\n\nPrzykład kwantyzacji\n\n\n\nPrzykładem niech będzie sygnał EKG na obrazku poniżej\n\n\n\nEKG\n\n\n\n\nKonwersja sygnału analogowego do cyfrowego zachodzi zawsze z pewną ograniczoną dokładnością. Dokładność ta wynika ze skończonej precyzji reprezentacji liczb w systemach cyfrowych. Nazywamy to błędem kwantyzacji. Wiąże się to bezpośrednio z typami danych. Drugim typem błędu, który nas interesuje to błąd maszynowy.\nBłąd kwantyzacji: Pojawia się, gdy sygnał ciągły lub sygnał o dużej rozdzielczości jest przetwarzany do ograniczonej liczby dyskretnych poziomów. Na przykład, gdy analogowy sygnał dźwiękowy jest digitalizowany, jego wartości amplitudy są zaokrąglane do najbliższego poziomu kwantyzacji. Błąd kwantyzacji odnosi się do różnicy między rzeczywistą wartością sygnału a jego kwantyzowaną wartością.\nBłąd maszynowy: Jest to najmniejsza wartość, która może być reprezentowana w danym systemie numerycznym. Dla standardu liczby zmiennoprzecinkowej IEEE 754 (często używany w komputerach), błąd maszynowy określa minimalną różnicę między “1” a następną wartością, która może być reprezentowana. Błąd maszynowy jest ograniczeniem maszynowym i jest bezpośrednio związany z precyzją, z jaką liczby są reprezentowane w komputerze.\n\nOba typy błędów wynikają z ograniczeń w reprezentowaniu liczb.\nW kontekście przetwarzania sygnałów, błąd kwantyzacji często jest bardziej widoczny, ponieważ wpływa bezpośrednio na jakość rekonstrukcji sygnału. Jednak w obliczeniach numerycznych, błąd maszynowy może kumulować się w wielu operacjach i wpływać na dokładność wyników.\nW praktycznych zastosowaniach DSP (cyfrowe przetwarzanie sygnałów), błąd kwantyzacji jest często większym problemem niż błąd maszynowy, chyba że algorytm wymaga dużej precyzji w obliczeniach matematycznych.\n\nBłąd maszynowy, zwany także epsilonem maszynowym możemy w praktyce wyznaczyc korzystając z definicji, że jest to taka liczba, że:\n\\[1 + \\epsilon \\neq 1 \\tag{1}\\]\nw arytmetyce zmiennoprzecinkowej komputera. Dla typu float64 w bibliotece NumPy (co jest standardowym formatem liczby zmiennoprzecinkowej o podwójnej precyzji), epsilon maszynowy wynosi około \\(2.220446049250313 \\cdot e^−16\\)."
  },
  {
    "objectID": "labs/lab1.html#zadania",
    "href": "labs/lab1.html#zadania",
    "title": "Laboratorium 1",
    "section": "",
    "text": "Pacjenci w szpitalu otrzymują różne dawki leku w zależności od ich wagi. Stwórz funkcję, która przyjmuje listę wag pacjentów i zwraca listę z odpowiednimi dawkami leku. Dawka leku jest obliczana według następującej zasady:\n\nDla pacjentów o wadze poniżej 50 kg: 20 mg leku.\nDla pacjentów o wadze od 50 kg do 100 kg: 50 mg leku.\nDla pacjentów o wadze powyżej 100 kg: 100 mg leku.\n\nSygnatura funkcji:\ndef oblicz_dawki(wagi: np.ndarray) -&gt; np.ndarray:\n    pass # tutaj bedzie implementacja\nPrzykładowe działanie:\nDla tablicy wag: np.array([45, 75, 105]), funkcja powinna zwrócić: np.array([20, 50, 100]).\nPrzetestuj działanie funkcji na różnych zbiorach danych.\n\n\n\nW szpitalu prowadzone są badania dotyczące wpływu leku na ciśnienie krwi pacjentów. Dla listy pacjentów, która zawiera zapisane ciśnienie krwi przed i po podaniu leku, oblicz procent pacjentów, u których ciśnienie spadło po podaniu leku.\nMasz daną następującą listę ciśnień krwi:\ncisnienia = [\n    (120, 115),\n    (140, 138),\n    (130, 125),\n    (150, 155),\n    (110, 108)\n]\nKażda krotka zawiera dwie wartości: pierwsza to ciśnienie przed podaniem leku, a druga po podaniu leku.\nUżywając pętli, oblicz procent pacjentów z obniżonym ciśnieniem.\n\n\n\nW dziedzinie medycyny obrazowej często stosuje się przekształcenia obrazów. Jednym z najprostszych z nich jest progowanie (thresholding). Polega ono na porównywaniu wartości danego piksela z wartością progową i wpisywanie do niego wartości 255 jeśli jest większy od wartości progowej lub 0 jeśli jest mniejszy.\nTwoim zadaniem jest napisanie funkcji thresholding, która przyjmuje dwuwymiarową macierz (obraz) oraz wartość progową T i zwraca nową macierz po operacji thresholdingu.\nKażdy element tej macierzy reprezentuje piksel obrazu o wartościach od 0 (czarny) do 255 (biały). Piksele poniżej wartości T powinny być przekształcone na 0, podczas gdy piksele powyżej T powinny być przekształcone na 255.\nSygnatura funkcji:\ndef thresholding(obraz: np.ndarray, T: int) -&gt; np.ndarray:\n    pass #tutaj znajdzie sie implementacja Waszej funkcji\nPrzykładowa macierz:\nobraz = [\n    [120, 130, 140],\n    [150, 160, 170],\n    [180, 190, 200]\n]\nJeśli wartość progowa T wynosi 150, przekształcony obraz będzie wyglądać następująco:\n[\n    [0, 0, 0],\n    [255, 255, 255],\n    [255, 255, 255]\n]\n\n\n\nDane z EEG (elektroencefalografia) pacjenta są zapisane w postaci tablicy numpy reprezentującej napięcie zarejestrowane w kolejnych punktach czasowych. Chcielibyśmy analizować te dane w segmentach o określonej długości czasu (tzw. okna czasowe). Napisz generator, który będzie zwracać fragmenty tej tablicy.\nArgumenty funkcji: 1. Tablica numpy o nazwie eeg_data, reprezentująca dane EEG. 2. Liczba próbek na segment, segment_length.\nGenerator ma zwracać kolejne segmenty danych o długości segment_length. Jeśli w tablicy pozostanie mniej niż segment_length próbek, zwróć te pozostałe próbki.\nSygnatura funkcji:\ndef generator_segmentow_eeg(eeg_data: np.ndarray, segment_length: int):\n    ...\nPrzykład: Załóżmy, że mamy dane EEG w tablicy: np.array([0.5, 0.6, 0.7, 0.55, 0.65, 0.7, 0.8, 0.85]) i chcemy analizować segmenty o długości 3 próbek. - Pierwsze wywołanie next() zwróci np.array([0.5, 0.6, 0.7]). - Drugie wywołanie next() zwróci np.array([0.55, 0.65, 0.7]). - Trzecie wywołanie next() zwróci np.array([0.8, 0.85]). - Kolejne wywołanie next() spowoduje podniesienie wyjątku StopIteration.\nZadanie dodatkowe: Używając biblioteki NumPy wygeneruj tablicę 10.000 próbek sygnału EEG, dla uproszczenia przyjmijmy że będą to wartości losowe z przedziału 0-1, w typie danych float16. Przetestuj działanie swojego generatora dla różnych długości okna czasowego.\n\n\n\nZadanie: Kalkulator z *args i **kwargs\nCelem zadania jest stwotzenie uniwersalnego kalkulatora zdolnego do wykonania różnych operacji matematycznych na dowolnej liczbie argumentów z wykorzystaniem *args i **kwargs.\nInstrukcje:\n\nZaimplementuj funkcję o nazwie universal_calculator.\nFunkcja powinna przyjmować argumenty pozycyjne (*args) reprezentujące wartości liczbowe, na których chcemy wykonać operacje.\nFunkcja powinna również akceptować argumenty nazwane (**kwargs) do kontrolowania operacji:\n\noperation: określa typ operacji (możliwości: \"add\", \"substract\", \"multiply\", \"divide\"). Domyślnie powinna być to operacja dodawania.\npower: podniesienie wyniku do podanej potęgi.\n(Dla chętnych, opcjonalnie) show_steps: jeśli ustawiono na True, funkcja powinna dodatkowo drukować kroki obliczeń.\n\nFunkcja powinna zwracać końcowy wynik operacji.\n\nPrzykład użycia:\nprint(universal_calculator(1, 2, 3, 4))  # Domyślnie dodaje: 10\nprint(universal_calculator(1, 2, 3, operation=\"multiply\"))  # Mnoży: 6\nprint(universal_calculator(10, 2, operation=\"divide\", power=2))  # Dzieli, a następnie podnosi wynik do kwadratu: 25.0\nprint(universal_calculator(1, 2, 3, operation=\"add\", show_steps=True))\n# Drukowanie kroków:\n# 1 + 2 = 3\n# 3 + 3 = 6\n# Wynik: 6\nWskazówki: - Wykorzystaj pętlę for do iteracji przez args podczas wykonywania operacji. - Użyj instrukcji warunkowych do wyboru odpowiedniej operacji matematycznej. - Upewnij się, że kalkulator obsługuje potencjalne błędy, takie jak dzielenie przez zero.\n\n\n\nKorzystając z definicji epsilonu maszynowego napisz funkcję w języku Python, która oblicza epsilon maszynowy danego typu danych w bibliotece NumPy. Pamiętaj o deklaracji typu danych w obliczeniach. Zalecane jest skorzystanie z pętli.\n\n\n\nPoniżej przedstawiony jest kod, który mierzy czas wykonania pewnej operacji. Wykonaj analogiczne działanie z wykorzystaniem biblioteki NumPy, zmierz czas konieczny do jego wykonania, porównaj ten czas z czasem wykonania tradycyjnej metody.\nimport math\nimport time\n\n# Tworzymy listę wartości od 0 do 10^6\nvalues = [i * 0.001 for i in range(1000000)]\n\nstart_time = time.time()\n\nsin_values = []\nfor val in values:\n    sin_values.append(math.sin(val))\n\nend_time = time.time()\nprint(f\"Traditional loop took {end_time - start_time} seconds\")\n\n\n\nTwoim zadaniem jest stworzenie prostego kalkulatora oszczędnościowego, który pomoże użytkownikowi przewidzieć, ile pieniędzy uda mu się zaoszczędzić w ciągu określonego czasu.\nWymagania:\n\nUżytkownik powinien mieć możliwość podania początkowej kwoty oszczędności (może to być 0).\nUżytkownik powinien podać miesięczną kwotę, którą planuje oszczędzać.\nUżytkownik powinien podać roczne oprocentowanie swojego konta oszczędnościowego (np. 3% oznaczać będzie 0.03).\nUżytkownik powinien podać liczbę lat, przez które planuje oszczędzać.\n\nTwoim zadaniem jest:\n\nObliczenie końcowej sumy oszczędności po określonym czasie, uwzględniając oprocentowanie.\nWykorzystanie odpowiednich typów danych w Pythonie do reprezentowania tych wartości (np. float dla kwot i oprocentowania, int dla liczby lat).\n\nFormuła oszczędności z oprocentowaniem składanym miesięcznie:\n\\[A = P \\left(1 + \\frac{r}{n}\\right)^{nt} + PMT \\left[ \\frac{\\left(1 + \\frac{r}{n}\\right)^{nt} - 1}{\\frac{r}{n}} \\right]\\]\nGdzie:\n\nA to końcowa suma oszczędności.\nP to początkowa suma oszczędności.\nr to roczna stopa procentowa (jako ułamek, np. 3% to 0.03).\nn to liczba okresów kapitalizacji w ciągu roku (dla kapitalizacji miesięcznej n=12n=12).\nt to liczba lat oszczędzania.\nPMT to stała miesięczna wpłata."
  },
  {
    "objectID": "transition-from-rmarkdown.html",
    "href": "transition-from-rmarkdown.html",
    "title": "Transition from RMarkdown",
    "section": "",
    "text": "You may already have workflows in RMarkdown and are interested in transitioning to Quarto. There’s no hurry to migrate to Quarto. Keep using Rmarkdown and when you’re ready the migration will be fine.\nHere are some notes as we migrate RMarkdown sites and books.\nTODO: translating R code chunks"
  },
  {
    "objectID": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "href": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Bookdown to Quarto",
    "text": "Bookdown to Quarto\nConverting a Bookdown book to Quarto is slightly more involved than converting a website. A book has chapters whose order must be defined, and likely has citations and cross-refs. Still, conversion is not that hard.\nWe got some practice converting from Bookdown to Quarto by helping Gavin Fay convert his lab’s fantastic onboarding documentation, the Faylab Lab Manual. Here’s the GitHub view before and after.\nOur best first reference material for this was Nick Tierney’s Notes on Changing from Rmarkdown/Bookdown to Quarto. Nick shares some scripts in that post to automate some changes. In our case, the book was small enough that we made all changes manually. Quarto documentation was indispensable.\n\nExperimenting in a low-risk environment\nWe forked a copy of the Faylab Lab manual to the Openscapes organization, and worked in a branch so we could make changes relatively risk-free. We could always fork a new copy of the original if we “broke” something. (Caution: the default when making a pull request from a fork is to push changes to the original upstream repo, not your fork and it does this without warning if you have write-access to that repo.) With local previews it’s easy to test / play with settings to see what they do. We tended to make a change, Preview, then compare the look and functionality of the book to the original. It was helpful to comment out some elements of the configuration file _output.yml after their counterparts had been added to the Quarto configuration file _quarto.yml, or to confirm they were no longer needed, before making the drastic move of deleting them.\n\n\nThe conversion\nHere are the main steps to convert the Faylab Lab manual from Bookdown to Quarto.\nCreate new empty file called _quarto.yml and add book metadata there. The screenshots below\nSet project type as book.\nMove metadata out of index.qmd and into _quarto.yml. Title, author, and publication date were in index.qmd with date set using date: \"Last updated:r Sys.Date()\". Now these are in _quarto.yml with date set using date: last-modified. Note that having R code would require you to adjust code chunk options in the Quarto style (#|). This tripped us up a bit; see GitHub Actions.\nMove chapters listing out of _bookdown.yml and into _quarto.yml.\nAdd page footer to _quarto.yml.\nHere’s what ours looked like when we finished the steps above (_quarto.yml).\n\n\n\n\n\n\n_quarto.yml contents\n\n\n\n\n\n\n\nFaylab Lab Manual\n\n\n\n\n\nChange insertion of images from html style to Quarto style. (Note Quarto calls them “figures”, not “images”.) The following snippet will insert the GitHub octocat logo in a page:\n![](https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png){fig-align=\"left\" width=\"35px\"}\nChange all filename extensions .Rmd -&gt; .qmd (you could Preview after this change and see that the book looks the same). Note that Quarto works with .Rmd files just as well as it does .qmd, so this change is not urgent. In fact, if you have a lot of R code in your .Rmds (unlike the Faylab Lab Manual), there will be additional tinkering needed to make the code chunks happy.\n\n\nCitations\nThe Faylab Lab Manual cited two papers, presenting us with an opportunity to see how easy it is to add references to a Quarto book. Briefly, in the Visual Editor, Insert &gt; Citation &gt; DOI. Pasting the DOI or its full URL, we can insert the citation. This automatically creates a references.bib file and adds the full citations at the bottom of the chapter page (watch demo). In July 2022, we had to manually add a ## References heading, but this may not be necessary in future Quarto updates.\n\n\n\n\n\n\nInsert citation via its DOI using RStudio Visual Editor\n\n\n\n\n\n\n\n\n\n\nPublishing notes\nIf the book’s output is strictly html, there’s no need to specify output-dir in _quarto.yml. The output directory default is _book/, which is what we’d like. If we wanted other types of output like like PDF or EPUB, etc. those single file outputs are also written to the output-dir (Quarto docs).\nIf you currently have a docs/ folder, delete it.\nUpdate .gitignore to ignore _book/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_book/\nOnce all is settled, delete _output.yml.\nOnce the Openscapes fork was fully reviewed, we made a pull request from that to the main branch of the book’s repo. Once that was merged, we set up GitHub Actions to render the book. (TODO: instructions for GitHub Actions)\n\n\nGitHub Actions\nThis book was mostly prose and screenshots without any R code. This made the conversion from RMarkdown to Quarto likely more straightforward than if you also needed to adjust code chunk options in the quarto style (#|). Our initial GitHub Action to render the converted Faylab Lab Manual failed because we had a piece of R code - even though the code was commented out! This was resolved when we deleted the line."
  },
  {
    "objectID": "transition-from-rmarkdown.html#distill-to-quarto",
    "href": "transition-from-rmarkdown.html#distill-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Distill to quarto",
    "text": "Distill to quarto\nWe transitioned our events site from distill to quarto in May 2022 (github view before and after). We followed excellent notes and examples from Nick Tierney and Danielle Navarro.\nAfter we had changed all the files, the Build tab in the RStudio IDE still showed “Build website” rather then “Render Website” and “Preview Website”, and would error when we pushed them (because that button was expecting a distill site, not a quarto site). To fix this, we updated the .Rproj file. Clicking on the .Rproj file in the RStudio IDE will open a dialog box where you can click things you want (you can also open these in a text editor or from the GitHub website to see the actual text). To fix this situation with the Build tab: Project Options &gt; Build Tools &gt; Project Build Tools &gt; None.\nLooking at files /posts/_metadata.yml and _quarto.yml helps see where things are defined. For example, to make event post citations appear, we added citation: true to /posts/_metadata.yml and in _quarto.yml under the website key we set site-url: https://openscapes.github.io/events. We deleted footer.html used with distill because footer is now defined in quarto.yml.\n\nPublishing notes\n\nBackground: Our distill site had been set up to output to a docs folder, and had GitHub Settings &gt; Pages set to look there rather gh-pages branch. (Julie note: this was a new-to-me capability when we set up the events distill site in Spring 2021 so I had forgotten that was an option). We’ve inititally kept this same set-up for now with our events page in _quarto.yml: output-dir: docs. However, this is sub-optimal; better to not have to commit and push these files but to instead have a GitHub Action generate them upon a commit. So the following is what we did -\n\nDon’t specify output-dir in _quarto.yml. The output directory default is _site/, which is what we’d like.\nIf you currently have a docs/ folder (like we did as we were experimenting), delete it.\nUpdate .gitignore to ignore _site/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_site/\nPush these changes, merge into main.\nOn GitHub.com, in your repo, set up GitHub publishing\nFollow instructions from the explore and setup chapter."
  },
  {
    "objectID": "transition-from-rmarkdown.html#troubleshooting",
    "href": "transition-from-rmarkdown.html#troubleshooting",
    "title": "Transition from RMarkdown",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nGitHub Action fails, says you need RMarkdown but you don’t have R code!\nAnd you changed all .Rmds to .qmds!\nYou likely have a few setup code chunks from RMarkdown, that look like this:\n{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\nYou can find them by opening each of your files and having a look, or use GitHub’s search for the keyword knitr"
  },
  {
    "objectID": "learning-more.html",
    "href": "learning-more.html",
    "title": "Learning more",
    "section": "",
    "text": "An excellent overview: Reproducible authoring with Quarto - Mine Çetinkaya-Rundel, Feb 2022 - slides, youtube\nA Quarto tip a day in June 2022, from Mine Çetinkaya-Rundel.\n\n\n\nOpenscapes Champions Lessons Series\nOpenscapes Approach Guide\n\nNASA Earthdata Cloud Cookbook\n\nSee many more examples at the quarto gallery!\n\n\n\nAre you making onboarding documentation? Check out The Fay Lab Manual (now in Quarto!) for inspiration on structure - you could also start there and make it your own."
  },
  {
    "objectID": "learning-more.html#learn-more",
    "href": "learning-more.html#learn-more",
    "title": "Learning more",
    "section": "",
    "text": "An excellent overview: Reproducible authoring with Quarto - Mine Çetinkaya-Rundel, Feb 2022 - slides, youtube\nA Quarto tip a day in June 2022, from Mine Çetinkaya-Rundel.\n\n\n\nOpenscapes Champions Lessons Series\nOpenscapes Approach Guide\n\nNASA Earthdata Cloud Cookbook\n\nSee many more examples at the quarto gallery!\n\n\n\nAre you making onboarding documentation? Check out The Fay Lab Manual (now in Quarto!) for inspiration on structure - you could also start there and make it your own."
  },
  {
    "objectID": "quarto-workflows/browser.html",
    "href": "quarto-workflows/browser.html",
    "title": "From the Browser",
    "section": "",
    "text": "A workflow from the browser if good for getting started (since you do not need to install additional software) and for making small contributions, but is definitely limited. Once you feel comfortable here, you can move to a different setup.\nHere’s an example of editing content on an existing page."
  },
  {
    "objectID": "quarto-workflows/browser.html#edit-content-on-an-existing-page",
    "href": "quarto-workflows/browser.html#edit-content-on-an-existing-page",
    "title": "From the Browser",
    "section": "Edit content on an existing page",
    "text": "Edit content on an existing page\nLet’s change the date on the home page of this website.\nIn your repository, navigate to index.md. Then, click the pencil icon in the top right to edit directly.\n\n\n\n\n\nWe are now in the “Edit file” tab of the editor, where we can make modifications. Let’s change the date to today’s date. Click the “Preview” tab to see your changes. You can even check the “Show diff” box on the right side to see the changes you’ve made.\n\n\n\n\n\nWhile you’re here, see if there are additional changes to the text you’d like to make. Maybe changing the title or author at the top, or for the main text on the home page of the website.\nOur index.md file is written in Markdown, which enables you to make simple text formatting. As you go back and forth from “Edit file” to “Preview”, notice the patterns of how the Markdown text looks when it is as source (“Edit file”) and when it is formatted (“Preview”). For example, in Markdown, you can make text as a header with # symbols, bold or italic with * symbols, and hyperlinks with [](). Notice that spacing is important: for example, there are carriage returns (when you hit the “return” key) before any bullet points. You can learn the short list of Markdown rules here: https://quarto.org/docs/authoring/markdown-basics."
  },
  {
    "objectID": "quarto-workflows/browser.html#commit-and-publish",
    "href": "quarto-workflows/browser.html#commit-and-publish",
    "title": "From the Browser",
    "section": "Commit and publish",
    "text": "Commit and publish\nCommit your changes by scrolling to the bottom of the page and writing a commit message - a note to yourself and others about what changes you made. Write your commit message and then click the green “Commit changes” button.\n\n\n\n\n\nNow, click back to the main page of your GitHub repository. You should see the orange dot confirming your website is published. You’ll have to wait for the GitHub Action to tell quarto to build your site for you to see the update, but it will be there!"
  },
  {
    "objectID": "quarto-workflows/browser.html#limitations",
    "href": "quarto-workflows/browser.html#limitations",
    "title": "From the Browser",
    "section": "Limitations",
    "text": "Limitations\nWhile awesome that we can edit using GitHub directly from the browser, there are obvious limitations. One is that to see your edits show up in your book, you have to publish using the GitHub Action. This is slow. Another limitation is that we can only work on one file at a time and commit them each separately, which also is slow. Using additional software can make things much better, as we explore in subsequent chapters."
  },
  {
    "objectID": "quarto-workflows/index.html",
    "href": "quarto-workflows/index.html",
    "title": "Quarto Workflows",
    "section": "",
    "text": "How do you work in Quarto? You can use whichever tool you’re comfortable with (RStudio, Jupyter, GitHub, VS Code, etc). Developing your quarto site will have the same basic workflow, no matter which tool you use. It is very iterative, and each is explored more below.\n\nAuthoring: write text, code, images, etc in a file. Supported files include .md, .Rmd, .qmd, .ipynb…\nUpdate _quarto.yml as needed (for example, if you’ve created a new file you’d like included in your site)\nRender individual files and/or the whole website\nRepeat, repeat, repeat\nCommit and push your website to GitHub, your updates will publish automatically!\nRepeat all of the above to make the website as you’d like!\n\nNote: if editing from your internet browser we won’t render in Step 3. That step will not be separate, but combined with Step 5, which will only require a commit, not a push."
  },
  {
    "objectID": "quarto-workflows/index.html#basic-workflow",
    "href": "quarto-workflows/index.html#basic-workflow",
    "title": "Quarto Workflows",
    "section": "",
    "text": "How do you work in Quarto? You can use whichever tool you’re comfortable with (RStudio, Jupyter, GitHub, VS Code, etc). Developing your quarto site will have the same basic workflow, no matter which tool you use. It is very iterative, and each is explored more below.\n\nAuthoring: write text, code, images, etc in a file. Supported files include .md, .Rmd, .qmd, .ipynb…\nUpdate _quarto.yml as needed (for example, if you’ve created a new file you’d like included in your site)\nRender individual files and/or the whole website\nRepeat, repeat, repeat\nCommit and push your website to GitHub, your updates will publish automatically!\nRepeat all of the above to make the website as you’d like!\n\nNote: if editing from your internet browser we won’t render in Step 3. That step will not be separate, but combined with Step 5, which will only require a commit, not a push."
  },
  {
    "objectID": "quarto-workflows/index.html#authoring",
    "href": "quarto-workflows/index.html#authoring",
    "title": "Quarto Workflows",
    "section": "Authoring",
    "text": "Authoring\nAs an author, you have a lot of options of how your text will be formatted, arranged, and interlinked. You will be writing in Markdown, which is a lightweight text formatting language. The Quarto documentation about authoring introduces markdown-basics that will get you started. Also see Mine Çetinkaya-Rundel’s A Quarto tip a day.\nEach page of our site has a similar first few lines - this YAML, like we saw in our _quarto.yml and it is indicated by two sets of 3 dashes --- :\n---\ntitle: My title\n---\nYou’re able to add more features to individual pages by including it in the YAML, which for the most part here only includes a title. See Quarto excecution options for more information of what you can include in the YAML."
  },
  {
    "objectID": "quarto-workflows/index.html#update-_quarto.yml",
    "href": "quarto-workflows/index.html#update-_quarto.yml",
    "title": "Quarto Workflows",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nLet’s have a closer look at the _quarto.yml file.\nThis type of file (.yml or .yaml) is written in YAML (“Yet Another Markup Language”). You’ll be able to shift the arrangement of webpages by reordering/adding/deleting them in the _quarto.yml file following the patterns you see in this example.\n\n\n\n_quarto.yml and website side-by-side\n\n\nNotice that there are multiple ways in the _quarto.yml for you to include a file in your website. For example, in the above image, the “First Observations” we see in the left sidebar of the published website (right image) is represented in _quarto.yml (left image) over two lines, with line 36 indicating the file reference and line 37 indicating the text to show up in the left sidebar. However, “From RStudio” is only represented in one line of _quarto.yml, on line 43. This represents two strategies for including a file in your website. By default, the title of a specified file will show up in the website’s sidebar, which is what is happening with the “From RStudio” example. If you would like more control over what is written in the sidebar vs the title of your files, then the approach we took with “First Observations” is what you’ll want to do: you’ll see that only “First Observations” shows up in the sidebar as we specified in _quarto.yml, but the page’s title says “First Observations & Setup” (which in our preference was too long for the sidebar).\n\n\n\n\n\n\nNote\n\n\n\nAs you modify _quarto.yml, the most important thing to know is that spacing matters. Pay attention to whether text is indented by one, two, four, or other spaces, and make sure you follow it; if your site is not looking as expected it is likely a silent error in your YAML. Some text editors like RStudio provide debugging support for YAML and are highly recommended to save you time and heartache."
  },
  {
    "objectID": "quarto-workflows/index.html#install-quarto",
    "href": "quarto-workflows/index.html#install-quarto",
    "title": "Quarto Workflows",
    "section": "Install Quarto",
    "text": "Install Quarto\nhttps://quarto.org/docs/get-started/ describes how to install Quarto, which will depend on your operating system. We’ll walk through installation for each tool in the next chapters."
  },
  {
    "objectID": "labs/lab2.html",
    "href": "labs/lab2.html",
    "title": "Laboratorium 2",
    "section": "",
    "text": "Różniczkowanie numeryczne,\nSposoby obliczania gradientu,\nPodstawowe typy gradientu,\nSplot,\nAnaliza błędów numerycznych w porównaniu do rozwiązań analitycznych,\nImplementacja gradientów analitycznych,\nPrzykłady praktyczne,\nZadania do samodzielnego rozwiązania.\n\n\n\n\nDo różniczkowania można podejść zarówno numerycznie, jak i analitycznie, a każde z nich ma swój własny zestaw zalet i ograniczeń.\n\nDefinicja:\n\nRóżniczkowanie analityczne Polega na wykorzystaniu reguł różniczkowania (takich jak reguła potęg, reguła iloczynu, reguła łańcucha itp.) do znalezienia pochodnej funkcji. Na przykład pochodna \\(f(x) = x^2\\) to \\(f'(x) = 2x\\).\nRóżniczkowanie numeryczne Różniczkowanie numeryczne to metoda przybliżonego obliczania pochodnych funkcji za pomocą technik numerycznych. Zamiast korzystać z klasycznych reguł różniczkowania, stosuje się różnice skończone oparte na wartościach funkcji w określonych punktach.\n\nDokładność:\n\nRóżniczkowanie analityczne Dostarcza dokładnego wyrażenia dla pochodnej, zakładając, że nie popełniono błędów w procesie obliczenia pochodnej analitycznie.\nRóżniczkowanie numeryczne Dostarcza tylko przybliżenie pochodnej. Dokładność przybliżenia jest zależna od długości kroku \\(h\\). Zbyt duża wartość h może wprowadzić błędy obcięcia podczas gdy zbyt mała wartość może wprowadzić błędy zaokrąglenia.\n\nZastosowanie:\n\nRóżniczkowanie analityczne Ograniczone do funkcji, które można różniczkować za pomocą znanych reguł i technik (np. pochodną funkcji sinus jest funkcja cosinus). Niektóre złożone funkcje mogą być trudne lub niemożliwe do zróżniczkowania analitycznie.\nRóżniczkowanie numeryczne Można je stosować do prawie każdej funkcji, pod warunkiem że funkcja jest dobrze zachowująca się (tj. ciągła i gładka) w interesującym regionie. Sprawia to, że jest użyteczne dla funkcji, dla których trudno uzyskać analityczną pochodną (np. sygnał EKG)\n\nNarzędzia:\n\nRóżniczkowanie analityczne Wykonywane za pomocą manipulacji algebraicznych, symbolicznych narzędzi obliczeniowych takich jak Mathematica lub Maple, lub systemów algebry komputerowej (CAS) w kalkulatorach.\nRóżniczkowanie numeryczne Implementowane za pomocą języków programowania, oprogramowania takiego jak MATLAB czy Python (z bibliotekami takimi jak NumPy lub SciPy), lub konkretnych narzędzi do obliczeń numerycznych.\n\n\n\n\n\nOgólnie sposoby obliczania gradientu można podzielić na metody analityczne i numeryczne.\n\n\n\nPolega na bezpośrednim zastosowaniu reguł różniczkowania matematycznego do obliczenia gradientu\nIdealna w przypadkach gdy funkcja jest jasno określona oraz różniczkowalna w całej dziedzinie\nDla funkcji wektora skalarnego \\(f(\\mathbf{x})\\) gdzie \\(\\mathbf{x}\\) jest wektorem w przestrzeni \\(\\mathbb{R}^n\\), \\(\\nabla f(\\mathbf{x}) = \\left[ \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right]\\)\n\n\n\n\n\nPrzybliża gradient poprzez obliczenie funkcji w dwóch pobliskich punktach i obliczenie różnicy.\nPrzydatne, gdy gradient analityczny jest trudny do uzyskania lub podczas weryfikacji poprawności gradientu analitycznego.\nPowszechnie stosowane metody to metoda różnic w przód, w tył i metoda różnic centralnych.\n\n\n\n\n\\(\\frac{\\partial f(\\mathbf{x})}{\\partial x} \\approx \\frac{f(\\mathbf{x} + h ) - f(\\mathbf{x})}{h}\\)\n\n\n\n\n\n\\(\\frac{\\partial f(\\mathbf{x})}{\\partial x} \\approx \\frac{f(\\mathbf{x}) - f(\\mathbf{x} - h)}{h}\\)\n\n\n\n\n\n\\(\\frac{\\partial f(\\mathbf{x})}{\\partial x} \\approx \\frac{f(\\mathbf{x} + h) - f(\\mathbf{x} - h)}{2h}\\)\n\n\n\n\nZałóżmy że mamy sygnał \\(\\textbf{s}\\) o następujących wartościach:\n\\[ s = [0, 0.04, 0.19, 0.44, 0.79, 1.23, 1.77, 2.41, 3.16, 4] \\]\nOtrzymano go próbkując sygnał napięciowy z częstotliwością \\(f = 1 \\text{Hz}\\). Co sekundę zapisywano kolejne wartości sygnału do tablixy \\(s\\). Interesuje nas przeprowadzenie operacji różniczkowania na tym sygnale metodą “do przodu”.\nWiemy, że metoda do przodu definiowana jest jako: \\[dx = \\frac{f(x+h) - f(x)}{h}\\]\nNasz sygnał jest sygnałem numerycznym z wartościami zdefiniowanymi w konkretnych jego punktach, dla indeksów \\(0, 1, 2, 3... n\\) naszej tablicy \\(s\\). W tym przypadku długość naszego kroku \\(h\\) będzie musiała być wielokrotnością liczby całkowitej \\(1\\). Załóżmy więc, że będzie to po prostu 1.\nPrzy takim założeniu nasza formuła na metodę “do przodu” przybierze postać: \\[dx = \\frac{f(x+1) - f(x)}{1}\\] gdzie:\n\n\\(dx\\) - wartość różniczki w danym punkcie\n\\(x\\) - indeks tablicy \\(s\\)\nPrzykład takiego obliczania pochodnej sygnału dyskretnego z naszej tablicy \\(s\\) zilustrowano na rysunku poniżej.\n\n\n\n\ndef forward_difference(f, x, h=1e-5):\n    \"\"\"\n    Approximate the derivative of f at x using the forward difference method.\n\n    Parameters:\n    - f: The function to differentiate.\n    - x: The point at which to evaluate the derivative.\n    - h: A small step size for differentiation, default value is 1e-5.\n\n    Returns:\n    - The approximated derivative of f at x.\n    \"\"\"\n    return (f(x + h) - f(x)) / h\n\n\n\ndef forward_difference(signal):\n    \"\"\"\n    Approximate the derivative of a discrete signal using the forward difference method.\n\n    Parameters:\n    - signal: Numpy array containing discrete signal values.\n\n    Returns:\n    - Numpy array containing the approximated derivative values.\n    \"\"\"\n    derivative = np.zeros_like(signal)\n    \n    # Dla każdego punktu w sygnale proszę obliczyć różnicę do przodu\n    # Pytanie: Co zrobić z ostatnią próbką sygnału?\n    for i in range(len(signal) - 1):\n        derivative[i] = signal[i + 1] - signal[i]\n    \n    return derivative\n\n\n\n\n\n\n\n\n\n\nW matematyce splot jest operacją matematyczną na dwóch funkcjach (\\(f\\) i \\(g\\)), która tworzy trzecią funkcję (\\(f*g\\)), która wyraża sposób, w jaki kształt jednej jest modyfikowany przez drugą.\nOperacja splotu dyskretnego często opisywana jest przez równanie: \\[h[n] = (f * g)[n] = \\sum_{m=-\\infty}^{\\infty} f[m] g[n - m]\\]\nPoszczególne składniki tego równania przedstawiają się następująco:\n\n\\(h[n]\\) - Jest to sekwencja wyjściowa (wynikowa) po operacji splotu. Dla każdej wartości \\(n\\), \\(h[n]\\) reprezentuje wartość splotu dla tego konkretnego punktu  \n\n\\((f * g)[n]\\) - To jest alternatywna notacja dla \\(h[n]\\) i wskazuje na operację splotu między \\(f\\) a \\(g\\) w punkcie \\(n\\), \n\n\\(\\sum_{m=-\\infty}^{\\infty}\\) - Oznacza sumowanie (czyli dodawanie wartości) dla wszystkich wartości mm od minus nieskończoności do plus nieskończoności. W praktyce, w komputerowych implementacjach splotu, zakres ten jest zwykle ograniczony do długości sekwencji wejściowych.\n\n\\(f[m]\\) - Jest to wartość sekwencji \\(f\\) w punkcie \\(m\\). \\(f\\) jest jednym z sygnałów wejściowych (często nazywanym sygnałem wejściowym).\n\n\\(g[n - m]\\) - Jest to wartość sekwencji \\(g\\) w punkcie \\(n−m\\). \\(g\\) jest drugim sygnałem wejściowym (często nazywanym kernelem). \\(n−m\\) oznacza “przesunięcie” sekwencji \\(g\\) względem \\(f\\), co pozwala na “skanowanie” i mnożenie tych dwóch sygnałów . To jest bardzo ważne, gdyż zachodzą tu dwie rzeczy: - Przesunięcie - Dla każdego \\(m\\) sygnał \\(g\\) jest przesuwany względem \\(f\\). Przesunięcie oznacza, że wartości sygnału \\(g\\) są mnożone przez odpowiadające im wartości w sygnale \\(f\\) w miarę jak zmienia się \\(m\\). - Odbicie - W kontekście splotu, odbicie jednego z sygnałów (często kernela) jest kluczowym krokiem. Proces ten polega na odwróceniu kolejności próbek sygnału względem osi czasu lub indeksu. Odbicie jest konieczne, aby poprawnie ocenić, jak kernel wpłynie na każdy fragment sygnału wejściowego w trakcie operacji splotu.\n\n\n\n\n\n\nPrzykład Intuicyjny\n\n\n\nFabuła:\nOrganizujemy pokaz fajerwerków. Chcemy aby w każdej sekundzie wystrzeliwanych było \\(n\\) fajerwerków. Każdy fajerwerk spala się według funkcji spalania \\(s\\). Chcemy obliczyć ile jednostek gazów spalania znajduje się w danej sekundzie pokazu fajerwerków w atmosferze.\nObliczenia:\n\nMamy sygnał odpalania fajerwerków: \\[f(t) = [1, 2, 2, 1]\\]\nSygnał ten, mówi nam że: - W pierwszej sekundzie odpalamy 1 fajerwerk - W drugiej sekundzie odpalamy 2 fajerwerki - W trzeciej sekundzie odpalamy 2 fajerwerki - W czwartej sekundzie odpalamy 1 fajerwerk\n\nKażdy fajerwerk spala się zgodnie z funkcją: \\[s(t) = [2, 1, 0]\\]\nOznacza to, że:\n\nW pierwszej sekundzie po odpaleniu fajerwerk emituje 2 jednostki gazu,\nW drugiej sekundzie po odpaleniu emituje 1 jednostkę gazu\nW trzeciej sekundzie nie emituje gazu (bo zgasł)\n\nAby obliczyć całkowitą ilość emitowanego gazu w funkcji czasu, wykonujemy splot sygnału odpalania fajerwerków z funkcją spalania:\n\\[h(t) = f(t) * s(t)\\]\nWynik splotu będzie wyglądał następująco:\n\n\\((1 × 2) = 2\\)\n\\((1 × 1)+(2 × 2)= 1 + 4 = 5\\)\n\\((1×0)+(2×1)+(2×2)=0+2+4=6\\)\n\\((2×0)+(2×1)+(1×2)=0+2+2=4\\)\n\\((2×0)+(1×1)=1\\)\n\\((1×0)=0\\)\n\n\nWięc sygnał \\(h(t)\\), który przedstawia ilość emitowanego gazu w funkcji czasu, wynosi:\n\\[h(t) = [2,5,6,4,1,0]\\]\nTen wynik mówi nam że:\n\nw pierwszej sekundzie emitujemy 2 jednostki gazu,\nw drugiej sekundzie 5 jednostek,\nw trzeciej sekundzie 6 jednostek,\nw czwartej sekundzie 4 jednostki,\nw piątej sekundzie 1 jednostkę,\na w szóstej sekundzie 0 jednostek.\n\n\n\n\n\n\nPrzeanalizujmy wzory na\n\n\n\n\n\n\n\n\nMetoda\nPierwsza pochodna (\\(f'(x)\\))\nDruga pochodna (\\(f''(x)\\))\n\n\n\n\nDo przodu\n\\(\\frac{f(x+h) - f(x)}{h}\\)\n\\(\\frac{f(x+2h) - 2f(x+h) + f(x)}{h^2}\\)\n\n\nRóżnic centralnych\n\\(\\frac{f(x+h) - f(x-h)}{2h}\\)\n\\(\\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}\\)\n\n\nDo tyłu\n\\(\\frac{f(x) - f(x-h)}{h}\\)\n\\(\\frac{f(x) - 2f(x-h) + f(x-2h)}{h^2}\\)\n\n\n\n\nPatrząc na tabelę, zauważmy że:\n\nW kolejnych pochodnych zawsze używamy jedynie próbek z różniczkowanego sygnału oraz kroku \\(h\\)\nW każdym równaniu występują pewne znane komponenty: \\(f(x)\\), \\(f(x+h)\\), \\(f(x+2h)\\), \\(f(x-h)\\), \\(f(x - 2h)\\).\n\nMożemy zatem naszą tabelę zapisać w inny sposób, rozbijając ją na elementy z konkretnymi współczynnikami, na przykład:\n\nMetoda różnic ‘do przodu’, pierwsza pochodna: \\(\\frac{1 × f(x+h) -1 × f(x)}{h}\\). Czyli możemy przyjąć, że kernel takiej operacji to: \\([1, -1]\\) a wynik możemy po prostu podzielić przez \\(h\\).\n\nInnymi słowy, obliczenie pierwszej pochodnej sygnału \\(s\\) może być przeprowadzone z wykorzystaniem splotu z kernelem \\(g = [-1, 1]\\)odpowiadającym operacji pierwszej pochodnej.\nPrzykład numeryczny:\nimport numpy as np\n\n# Zdefiniujmy jakiś sygnał dyskretny\ns = np.array([1, 3, 5, 7, 11, 13, 17, 19])\n\n# Zdefiniujmy kernel dla obliczenia pierwszej pochodnej metodą \"do przodu\"\nh = 1.0\nkernel = np.array([-1/h, 1/h])\n\n# Obliczamy pierwszą pochodną używając splotu\n# Używamy opcji 'valid' aby uniknąć artefaktów krańcowych (boundary effect)\n# Przejrzyj dokumentację funkcji np.convolve aby dowiedzieć się jak działa\nds = np.convolve(s, kernel, mode='valid')\n\nprint(ds)\n\n\n\n\nDefinicja błędu: Błąd numeryczny to różnica między wartością otrzymaną z metody numerycznej a dokładną wartością analityczną.\nŹródła błędów:\n\nBłąd zaokrąglenia: Powstaje w wyniku reprezentacji liczb w komputerze z ograniczoną precyzją.\nBłąd przybliżenia: Powstaje w wyniku stosowania metod przybliżonych do obliczeń, np. stosując metody różnicowe do przybliżania pochodnych.\n\n\n\n\n\n\n\nPrzykład Analizy Błędów\n\n\n\nFunkcja: \\(f(x) = x^2\\)\nDla \\(x = 2\\): \\[f(2) = 2^2 = 4\\] \\[f(2 + h) = (2 + 0.01)^2 = 4.0401\\]\nPochodna Numeryczna używając metody różnic skończonych do przodu: \\[f'(x) \\approx \\frac{f(x+h) - f(x)}{h}\\] \\[f'(2) \\approx \\frac{f(2+0.01) - f(2)}{0.01}\\] \\[f'(2) \\approx \\frac{4.0401 - 4}{0.01} = 4.01\\]\nPochodna Analityczna: \\[f'(x) = 2x\\] \\[f'(2) = 2(2) = 4\\]\nBłąd Numeryczny: \\[\\text{Błąd} = \\text{Wartość Numeryczna} - \\text{Wartość Analityczna}\\] \\[\\text{Błąd} = 4.01 - 4 = 0.01\\]\nAnaliza Błędu Numerycznego: - Błąd wynosi 0.01 dla kroku \\(h = 0.01\\) przy \\(x = 2\\). - Błąd ten pochodzi z przybliżenia i będzie się różnić w zależności od wielkości kroku \\(h\\). Dla mniejszego \\(h\\) błąd mógłby być mniejszy, ale po pewnym czasie błędy zaokrąglenia mogą zacząć dominować co spowoduje powtórne zwiększenie się błędu numerycznego. - Możemy przeprowadzić dodatkowe obliczenia dla różnych wartości \\(h\\), aby zrozumieć, jak błąd zmienia się w zależności od wielkości kroku.\nW praktyce warto przeprowadzić analizę błędów dla różnych wartości \\(h\\) i różnych punktów \\(x\\), aby zrozumieć zachowanie metody numerycznej w różnych warunkach.\nCzy możemy przeprowadzić obliczenia analityczne komputerowo?\nCzęściowo tak. Możemy w tym celu wykorzystać bibliotekę Pythona SymPy:\nimport sympy as sp\n\n# Zdefiniowanie symbolu\nx = sp.Symbol('x')\n\n# Funkcja\nf = x**2\n\n# Pochodna funkcji\nf_prime = sp.diff(f, x)\n\nprint(f\"Pochodna funkcji {f} to: {f_prime}\")\nSymPy to biblioteka Pythona o otwartym kodzie źródłowym dla matematyki symbolicznej. Jej celem jest stanie się w pełni funkcjonalnym systemem algebry komputerowej (CAS - Computer Algebra System), przy jednoczesnym utrzymaniu kodu tak prostym, jak to możliwe, aby był zrozumiały i łatwy do rozszerzenia. Obliczenia symboliczne, często określane jako algebra symboliczna lub algebra komputerowa, to gałąź obliczeń matematycznych i informatyki, która koncentruje się na manipulowaniu wyrażeniami matematycznymi w formie symbolicznej, a nie na uzyskiwaniu przybliżeń numerycznych.\n\n\n\n\n\nObliczmy gradient analitycznie za pomocą biblioteki obliczeń symbolicznych w Pythonie, sympy.\nJako przykład użyjmy prostej funkcji dwóch zmiennych: \\[f(x, y) = x^2 + 3xy + y^2\\]\nGradient funkcji \\(f\\) jest wektorem jego pochodnych cząstkowych względem każdej ze zmiennych (w naszym przykładzie względem \\(x\\) oraz \\(y\\)): \\[\\nabla f = \\left[ \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y} \\right]\\]\nPrzeanalizujmy jak przeprowadzić takie obliczenia symbolicznie, z wykorzystaniem biblioteki sympy:\nimport sympy as sp\n\n# Definiujemy zmienne\nx, y = sp.symbols('x y')\n\n# Definiujemy funkcje\nf = x**2 + 3*x*y + y**2\n\n# Obliczamy gradient\ngrad_f = [sp.diff(f, var) for var in (x, y)]\n\nprint(\"Gradient:\", grad_f)\nPowinniśmy otrzymać następujący wynik:\nGradient: [2*x + 3*y, 3*x + 2*y]\nPodsumowując, gradientem naszej funkcji \\(f(x, y)\\) jest \\([2x + 3y, 3x + 2y]\\).\nFunkcja sympy.diff() zapewnia analityczną (dokładną) pochodną, w przeciwieństwie do aproksymacji numerycznej.\nZwizualizujmy ten przykład:\n\n\n\n\n\n\n\nKod użyty do wygenerowania wizualizacji\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sympy as sp\n\n# Definiujemy zmienne i funkcje\nx, y = sp.symbols('x y')\nf = x**2 + 3*x*y + y**2\ngrad_f = [sp.diff(f, var) for var in (x, y)]\n\n# Lambdyfikacja wyrażeń symbolicznych (proces konieczny do wyznaczenia ich wartości dla konkretnych danych numerycznych)\nf_callable = sp.lambdify((x, y), f, 'numpy')\nf_gradient = sp.lambdify((x, y), grad_f, 'numpy')\n\n# Tworzenie siatki punktów na których rozepniemy nasze dane (bardzo ważna czynność!)\nX, Y = np.meshgrid(np.linspace(-10, 10, 20), np.linspace(-10, 10, 20))\n\n# Obliczenie wartości funkcji na konkretnych punktach siatki\nZ = f_callable(X, Y)\nU, V = f_gradient(X, Y)\n\n# Normalizacja danych (dla lepszej wizualizacji)\nN = np.sqrt(U**2 + V**2)\nU /= N\nV /= N\n\n# Plot\nplt.figure(figsize=(10, 8))\n\n# Wyrysowanie funkcji używając metody contour oraz mapy kolorów 'viridis'\ncontour = plt.contourf(X, Y, Z, 20, cmap='viridis')\nplt.colorbar(contour, label='f(x, y) value')\n\n# Narysowanie strzałek reprezentujących wartości gradientu\nplt.quiver(X, Y, U, V, angles='xy', scale_units='xy', scale=1, color='r', width=0.005)\n\nplt.title('f(x, y) and its Gradient')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid()\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.show()\n\n\n\n\n\n\n\n\nGradienty mogą być użyte jako najprostsza metoda wykrywania krawędzi, zwłaszcza na obrazach binarnych.\n\n\n\n\n\n\n\nKod użyty do wygenerowania przykładu z kołem\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nwidth, height = 200, 200\n\n# Krok 1: Używamy meshgrid do utworzenia siatki współrzędnych\nx, y = np.meshgrid(np.arange(width), np.arange(height))\n\ncenterx, centery = width // 2, height // 2\nradius = 50\n\nmask = (x - centerx)**2 + (y - centery)**2 &lt;= radius**2\ncircle_img = np.zeros((width, height))\ncircle_img[mask] = 1\n\n# Krok 2: Obliczamy gradient\ngy, gx = np.gradient(circle_img)\n\n# Krok 3: Wizualizacja\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\naxes[0].imshow(circle_img, cmap='gray')\naxes[0].set_title(\"Oryginalne Koło\")\n\naxes[1].imshow(gx, cmap='gray')\naxes[1].set_title(\"Gradient względem X\")\n\naxes[2].imshow(gy, cmap='gray')\naxes[2].set_title(\"Gradient względem Y\")\n\nfor ax in axes:\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nJednym z algorytmów wykrywających zespół QRS na sygnale EKG jest algorytm Pan-Tompkins. Składa się on z następujących kroków:\n\nFiltracja pasmowo przepustowa usuwająca zakłócenia sieciowe z sygnału\nRóżniczkowanie - służy to podkreśleniu cech morfologicznych sygnału\nKwadrat - podnosimy sygnał do kwadratu celem wzmocnienia cech morfologicznych\nIntegracja (moving average) - operacja ta jest używana do uzyskania finalnego kształtu fali QRS. Sygnał jest przetwarzany za pomocą okna czasowego (np. 30 ms), co skutkuje wygładzeniem sygnału.\nProgowanie - na podstawie przetworzonego sygnału określany jest próg, który służy do wykrywania kompleksów QRS. Wielkość progu jest dynamicznie dostosowywana w trakcie analizy.\n\n\n\n\nAlgorytm Pan-Tompkins krok po kroku\n\n\n\n\n\n\n\n\nKod użyty do wygenerowania wizualizacji Pan-Tompkins\n\n\n\n\n\nimport numpy as np # biblioteka numpy do obliczeń numerycznych\nimport neurokit2 as nk # NeuroKit2 - zawiera generator syntetycznego EKG\nimport matplotlib.pyplot as plt # Matplotlib - Rysowanie wykresów\n\ndef bandpass_filter(signal):\n    # Placeholder na filtr pasmowo przepustowy - TODO\n    return signal\n\n# Różniczkowanie\ndef differentiate(signal):\n    return np.diff(signal)\n\n# Kwadrat\ndef square(signal):\n    return signal ** 2\n\n# Całkowanie\ndef integrate(signal, window_size):\n    return np.convolve(signal, np.ones(window_size)/window_size, mode='same')\n\n# Progowanie\ndef find_qrs(signal, threshold):\n    qrs_locs = np.where(signal &gt; threshold)[0]\n    return qrs_locs\n\n# Pan Tompkins zawarty w jednej funkcji\ndef pan_tompkins_qrs_detection(ecg_signal):\n    ecg_signal = bandpass_filter(ecg_signal)\n    differentiated = differentiate(ecg_signal)\n    squared = square(differentiated)\n    integrated = integrate(squared, window_size=30)  # Adjust based on sampling rate\n    threshold = np.mean(integrated)\n    qrs_locs = find_qrs(integrated, threshold)\n    return qrs_locs\n\n# Postprocessing R-peaków\ndef refine_r_peaks(qrs_locs, ecg_signal, proximity):\n    r_peaks = []\n    grouped_peaks = []\n    for loc in qrs_locs:\n        if not grouped_peaks or abs(loc - grouped_peaks[-1]) &lt;= proximity:\n            grouped_peaks.append(loc)\n        else:\n            # Pick the highest point within this group\n            r_peak = max(grouped_peaks, key=lambda x: ecg_signal[x])\n            r_peaks.append(r_peak)\n            grouped_peaks = [loc]\n    # Handle the last group\n    if grouped_peaks:\n        r_peak = max(grouped_peaks, key=lambda x: ecg_signal[x])\n        r_peaks.append(r_peak)\n    return r_peaks\n\n# Wygenerowanie sygnału syntetycznego EKG\necg_signal = nk.ecg_simulate(duration=10, sampling_rate=1000, heart_rate=70)\n\n# Detekcja z użyciem Pan-Tompkins\nqrs_locs = pan_tompkins_qrs_detection(ecg_signal)\n\n# Postprocessing\nr_peaks = refine_r_peaks(qrs_locs, ecg_signal, proximity=40) \n\nplt.figure(figsize=(14, 5))\nplt.plot(ecg_signal, label='EKG')\nplt.plot(r_peaks, ecg_signal[r_peaks], \"ro\", label='R-peaki')\nplt.title(\"Syntetyczny sygnał EKG oraz wykryte zespoły QRS z użyciem algorytmu Pan-Tompkins\")\nplt.xlabel(\"Próbki\")\nplt.ylabel(\"Amplituda\")\nplt.legend()\nplt.savefig(\"lab2_pan_tompkins_ecg.png\", dpi=200, format=\"png\")\nplt.show()\n\n\n\n\n\n\n\n\n\nZaimplementuj funkcję, (za pomocą pętli for, bez użycia gotowych funkcji) do obliczania pochodnej funkcji jednej zmiennej metodą “centralną”, “do przodu” i “do tyłu”. Jakie są zalety poszczególnych rozwiązań? Jakie są wady? Kiedy warto użyć jednej wersji zamiast drugiej? Skorzystaj z definicji funkcji:\ndef our_derivatie(x, step=1, mode=\"central\"):\n   # x - sygnał wejściowy, dyskretny\n   # step - krok\n   # mode - tryb działania, możliwe opcje: \"central\", \"forward\", \"backward\"\n   pass\n\n\n\nZaimplementuj funkcję do obliczania splotu 1D (iteracyjnie, bez transformacji Fouriera, bez użycia gotowych funkcji). Porównaj działanie zaimplementowanej funkcji z funkcją biblioteczną (SciPy) oraz czas wykonywania obliczeń. Która funkcja jest szybsza? O ile? Dlaczego? Czy wyniki są identyczne? Porównaj działanie funkcji bibliotecznej liczącej splot z definicji oraz z transformacji Fouriera. (Sprawdź dla różnych wielkości tablic wejściowych).\ndef our_convolution(x1, x2, mode=\"pad\"):\n   # x1 - sygnał 1\n   # x2 - sygnał 2\n   # mode - tryb działania na granicy sygnału, #pad - padding, #reflect - reflection\n   pass\n\n\n\nZaimplementuj funkcję (za pomocą pętli for, bez użycia gotowych funkcji) do obliczenia pochodnej funkcji jednej zmiennej “centralnie”, która umożliwia wybór rzędu pochodnej (1,2,3,4) oraz trybu (splot lub sekwencyjnie). Porównaj wynik z wartościami analitycznymi na przykładowym wielomianie wyższego stopnia. Przeanalizuj błędy numeryczne (m.in. porównaj obliczenia za pomocą splotu z sekwencyjnym obliczaniem pierwszej pochodnej). Porównaj czas wykonania obliczeń. Skąd się biorą różnice? Które rozwiązanie jest szybsze? Które jest bardziej stabilne? Które rozwiązanie jest obarczone mniejszym błędem?\n\n\n\n\n\n\nObliczanie pochodnej sekwencyjnie\n\n\n\nSekwencyjna metoda obliczania pochodnej polega na obliczeniu pochodnej danego sygnału (pierwszej), a następnie pochodną drugiego rzędu dostajemy obliczając pochodną pierwszego rzędu pochodnej pierwszego rzędu itd…\n\n\ndef our_derivative(x, step=1, order=1, mode=\"conv\"):\n   # order - rząd pochodnej, 1,2,3,4\n   # conv/sequential - tryb działania (konwolucyjnie / sekwencyjnie)\n   pass\n\n\n\nZaimplementuj funkcję (za pomocą pętli for, bez użycia gotowych funkcji do obliczania pochodnych/gradientów) do obliczenia gradientu centralnego funkcji dwóch zmiennych. Na wejściu funkcji będzie tablica 2D (na przykład obraz). Na wyjściu funkcji powinna być tablica gradientów po x oraz y.\n\n\n\nZaimplementuj funkcję (za pomocą pętli for, bez użycia gotowych funkcji do obliczania pochodnych/gradientów) do obliczenia gradientu centralnego funkcji dowolnej liczby zmiennych (wejście w postaci tablicy N-wymiarowej). Porównaj działanie (błędy numeryczne, szybkość obliczeń) do wbudowanej funkcji gradient w bibliotece numpy.\ndef our_gradient(x, step=1):\n   pass"
  },
  {
    "objectID": "labs/lab2.html#zakres-tematyczny",
    "href": "labs/lab2.html#zakres-tematyczny",
    "title": "Laboratorium 2",
    "section": "",
    "text": "Różniczkowanie numeryczne,\nSposoby obliczania gradientu,\nPodstawowe typy gradientu,\nSplot,\nAnaliza błędów numerycznych w porównaniu do rozwiązań analitycznych,\nImplementacja gradientów analitycznych,\nPrzykłady praktyczne,\nZadania do samodzielnego rozwiązania."
  },
  {
    "objectID": "labs/lab2.html#różniczkowanie---analityczne-oraz-numeryczne",
    "href": "labs/lab2.html#różniczkowanie---analityczne-oraz-numeryczne",
    "title": "Laboratorium 2",
    "section": "",
    "text": "Do różniczkowania można podejść zarówno numerycznie, jak i analitycznie, a każde z nich ma swój własny zestaw zalet i ograniczeń.\n\nDefinicja:\n\nRóżniczkowanie analityczne Polega na wykorzystaniu reguł różniczkowania (takich jak reguła potęg, reguła iloczynu, reguła łańcucha itp.) do znalezienia pochodnej funkcji. Na przykład pochodna \\(f(x) = x^2\\) to \\(f'(x) = 2x\\).\nRóżniczkowanie numeryczne Różniczkowanie numeryczne to metoda przybliżonego obliczania pochodnych funkcji za pomocą technik numerycznych. Zamiast korzystać z klasycznych reguł różniczkowania, stosuje się różnice skończone oparte na wartościach funkcji w określonych punktach.\n\nDokładność:\n\nRóżniczkowanie analityczne Dostarcza dokładnego wyrażenia dla pochodnej, zakładając, że nie popełniono błędów w procesie obliczenia pochodnej analitycznie.\nRóżniczkowanie numeryczne Dostarcza tylko przybliżenie pochodnej. Dokładność przybliżenia jest zależna od długości kroku \\(h\\). Zbyt duża wartość h może wprowadzić błędy obcięcia podczas gdy zbyt mała wartość może wprowadzić błędy zaokrąglenia.\n\nZastosowanie:\n\nRóżniczkowanie analityczne Ograniczone do funkcji, które można różniczkować za pomocą znanych reguł i technik (np. pochodną funkcji sinus jest funkcja cosinus). Niektóre złożone funkcje mogą być trudne lub niemożliwe do zróżniczkowania analitycznie.\nRóżniczkowanie numeryczne Można je stosować do prawie każdej funkcji, pod warunkiem że funkcja jest dobrze zachowująca się (tj. ciągła i gładka) w interesującym regionie. Sprawia to, że jest użyteczne dla funkcji, dla których trudno uzyskać analityczną pochodną (np. sygnał EKG)\n\nNarzędzia:\n\nRóżniczkowanie analityczne Wykonywane za pomocą manipulacji algebraicznych, symbolicznych narzędzi obliczeniowych takich jak Mathematica lub Maple, lub systemów algebry komputerowej (CAS) w kalkulatorach.\nRóżniczkowanie numeryczne Implementowane za pomocą języków programowania, oprogramowania takiego jak MATLAB czy Python (z bibliotekami takimi jak NumPy lub SciPy), lub konkretnych narzędzi do obliczeń numerycznych."
  },
  {
    "objectID": "labs/lab2.html#sposoby-obliczania-gradientu",
    "href": "labs/lab2.html#sposoby-obliczania-gradientu",
    "title": "Laboratorium 2",
    "section": "",
    "text": "Ogólnie sposoby obliczania gradientu można podzielić na metody analityczne i numeryczne.\n\n\n\nPolega na bezpośrednim zastosowaniu reguł różniczkowania matematycznego do obliczenia gradientu\nIdealna w przypadkach gdy funkcja jest jasno określona oraz różniczkowalna w całej dziedzinie\nDla funkcji wektora skalarnego \\(f(\\mathbf{x})\\) gdzie \\(\\mathbf{x}\\) jest wektorem w przestrzeni \\(\\mathbb{R}^n\\), \\(\\nabla f(\\mathbf{x}) = \\left[ \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right]\\)\n\n\n\n\n\nPrzybliża gradient poprzez obliczenie funkcji w dwóch pobliskich punktach i obliczenie różnicy.\nPrzydatne, gdy gradient analityczny jest trudny do uzyskania lub podczas weryfikacji poprawności gradientu analitycznego.\nPowszechnie stosowane metody to metoda różnic w przód, w tył i metoda różnic centralnych.\n\n\n\n\n\\(\\frac{\\partial f(\\mathbf{x})}{\\partial x} \\approx \\frac{f(\\mathbf{x} + h ) - f(\\mathbf{x})}{h}\\)\n\n\n\n\n\n\\(\\frac{\\partial f(\\mathbf{x})}{\\partial x} \\approx \\frac{f(\\mathbf{x}) - f(\\mathbf{x} - h)}{h}\\)\n\n\n\n\n\n\\(\\frac{\\partial f(\\mathbf{x})}{\\partial x} \\approx \\frac{f(\\mathbf{x} + h) - f(\\mathbf{x} - h)}{2h}\\)\n\n\n\n\nZałóżmy że mamy sygnał \\(\\textbf{s}\\) o następujących wartościach:\n\\[ s = [0, 0.04, 0.19, 0.44, 0.79, 1.23, 1.77, 2.41, 3.16, 4] \\]\nOtrzymano go próbkując sygnał napięciowy z częstotliwością \\(f = 1 \\text{Hz}\\). Co sekundę zapisywano kolejne wartości sygnału do tablixy \\(s\\). Interesuje nas przeprowadzenie operacji różniczkowania na tym sygnale metodą “do przodu”.\nWiemy, że metoda do przodu definiowana jest jako: \\[dx = \\frac{f(x+h) - f(x)}{h}\\]\nNasz sygnał jest sygnałem numerycznym z wartościami zdefiniowanymi w konkretnych jego punktach, dla indeksów \\(0, 1, 2, 3... n\\) naszej tablicy \\(s\\). W tym przypadku długość naszego kroku \\(h\\) będzie musiała być wielokrotnością liczby całkowitej \\(1\\). Załóżmy więc, że będzie to po prostu 1.\nPrzy takim założeniu nasza formuła na metodę “do przodu” przybierze postać: \\[dx = \\frac{f(x+1) - f(x)}{1}\\] gdzie:\n\n\\(dx\\) - wartość różniczki w danym punkcie\n\\(x\\) - indeks tablicy \\(s\\)\nPrzykład takiego obliczania pochodnej sygnału dyskretnego z naszej tablicy \\(s\\) zilustrowano na rysunku poniżej.\n\n\n\n\ndef forward_difference(f, x, h=1e-5):\n    \"\"\"\n    Approximate the derivative of f at x using the forward difference method.\n\n    Parameters:\n    - f: The function to differentiate.\n    - x: The point at which to evaluate the derivative.\n    - h: A small step size for differentiation, default value is 1e-5.\n\n    Returns:\n    - The approximated derivative of f at x.\n    \"\"\"\n    return (f(x + h) - f(x)) / h\n\n\n\ndef forward_difference(signal):\n    \"\"\"\n    Approximate the derivative of a discrete signal using the forward difference method.\n\n    Parameters:\n    - signal: Numpy array containing discrete signal values.\n\n    Returns:\n    - Numpy array containing the approximated derivative values.\n    \"\"\"\n    derivative = np.zeros_like(signal)\n    \n    # Dla każdego punktu w sygnale proszę obliczyć różnicę do przodu\n    # Pytanie: Co zrobić z ostatnią próbką sygnału?\n    for i in range(len(signal) - 1):\n        derivative[i] = signal[i + 1] - signal[i]\n    \n    return derivative"
  },
  {
    "objectID": "labs/lab2.html#splot",
    "href": "labs/lab2.html#splot",
    "title": "Laboratorium 2",
    "section": "",
    "text": "W matematyce splot jest operacją matematyczną na dwóch funkcjach (\\(f\\) i \\(g\\)), która tworzy trzecią funkcję (\\(f*g\\)), która wyraża sposób, w jaki kształt jednej jest modyfikowany przez drugą.\nOperacja splotu dyskretnego często opisywana jest przez równanie: \\[h[n] = (f * g)[n] = \\sum_{m=-\\infty}^{\\infty} f[m] g[n - m]\\]\nPoszczególne składniki tego równania przedstawiają się następująco:\n\n\\(h[n]\\) - Jest to sekwencja wyjściowa (wynikowa) po operacji splotu. Dla każdej wartości \\(n\\), \\(h[n]\\) reprezentuje wartość splotu dla tego konkretnego punktu  \n\n\\((f * g)[n]\\) - To jest alternatywna notacja dla \\(h[n]\\) i wskazuje na operację splotu między \\(f\\) a \\(g\\) w punkcie \\(n\\), \n\n\\(\\sum_{m=-\\infty}^{\\infty}\\) - Oznacza sumowanie (czyli dodawanie wartości) dla wszystkich wartości mm od minus nieskończoności do plus nieskończoności. W praktyce, w komputerowych implementacjach splotu, zakres ten jest zwykle ograniczony do długości sekwencji wejściowych.\n\n\\(f[m]\\) - Jest to wartość sekwencji \\(f\\) w punkcie \\(m\\). \\(f\\) jest jednym z sygnałów wejściowych (często nazywanym sygnałem wejściowym).\n\n\\(g[n - m]\\) - Jest to wartość sekwencji \\(g\\) w punkcie \\(n−m\\). \\(g\\) jest drugim sygnałem wejściowym (często nazywanym kernelem). \\(n−m\\) oznacza “przesunięcie” sekwencji \\(g\\) względem \\(f\\), co pozwala na “skanowanie” i mnożenie tych dwóch sygnałów . To jest bardzo ważne, gdyż zachodzą tu dwie rzeczy: - Przesunięcie - Dla każdego \\(m\\) sygnał \\(g\\) jest przesuwany względem \\(f\\). Przesunięcie oznacza, że wartości sygnału \\(g\\) są mnożone przez odpowiadające im wartości w sygnale \\(f\\) w miarę jak zmienia się \\(m\\). - Odbicie - W kontekście splotu, odbicie jednego z sygnałów (często kernela) jest kluczowym krokiem. Proces ten polega na odwróceniu kolejności próbek sygnału względem osi czasu lub indeksu. Odbicie jest konieczne, aby poprawnie ocenić, jak kernel wpłynie na każdy fragment sygnału wejściowego w trakcie operacji splotu.\n\n\n\n\n\n\nPrzykład Intuicyjny\n\n\n\nFabuła:\nOrganizujemy pokaz fajerwerków. Chcemy aby w każdej sekundzie wystrzeliwanych było \\(n\\) fajerwerków. Każdy fajerwerk spala się według funkcji spalania \\(s\\). Chcemy obliczyć ile jednostek gazów spalania znajduje się w danej sekundzie pokazu fajerwerków w atmosferze.\nObliczenia:\n\nMamy sygnał odpalania fajerwerków: \\[f(t) = [1, 2, 2, 1]\\]\nSygnał ten, mówi nam że: - W pierwszej sekundzie odpalamy 1 fajerwerk - W drugiej sekundzie odpalamy 2 fajerwerki - W trzeciej sekundzie odpalamy 2 fajerwerki - W czwartej sekundzie odpalamy 1 fajerwerk\n\nKażdy fajerwerk spala się zgodnie z funkcją: \\[s(t) = [2, 1, 0]\\]\nOznacza to, że:\n\nW pierwszej sekundzie po odpaleniu fajerwerk emituje 2 jednostki gazu,\nW drugiej sekundzie po odpaleniu emituje 1 jednostkę gazu\nW trzeciej sekundzie nie emituje gazu (bo zgasł)\n\nAby obliczyć całkowitą ilość emitowanego gazu w funkcji czasu, wykonujemy splot sygnału odpalania fajerwerków z funkcją spalania:\n\\[h(t) = f(t) * s(t)\\]\nWynik splotu będzie wyglądał następująco:\n\n\\((1 × 2) = 2\\)\n\\((1 × 1)+(2 × 2)= 1 + 4 = 5\\)\n\\((1×0)+(2×1)+(2×2)=0+2+4=6\\)\n\\((2×0)+(2×1)+(1×2)=0+2+2=4\\)\n\\((2×0)+(1×1)=1\\)\n\\((1×0)=0\\)\n\n\nWięc sygnał \\(h(t)\\), który przedstawia ilość emitowanego gazu w funkcji czasu, wynosi:\n\\[h(t) = [2,5,6,4,1,0]\\]\nTen wynik mówi nam że:\n\nw pierwszej sekundzie emitujemy 2 jednostki gazu,\nw drugiej sekundzie 5 jednostek,\nw trzeciej sekundzie 6 jednostek,\nw czwartej sekundzie 4 jednostki,\nw piątej sekundzie 1 jednostkę,\na w szóstej sekundzie 0 jednostek.\n\n\n\n\n\n\nPrzeanalizujmy wzory na\n\n\n\n\n\n\n\n\nMetoda\nPierwsza pochodna (\\(f'(x)\\))\nDruga pochodna (\\(f''(x)\\))\n\n\n\n\nDo przodu\n\\(\\frac{f(x+h) - f(x)}{h}\\)\n\\(\\frac{f(x+2h) - 2f(x+h) + f(x)}{h^2}\\)\n\n\nRóżnic centralnych\n\\(\\frac{f(x+h) - f(x-h)}{2h}\\)\n\\(\\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}\\)\n\n\nDo tyłu\n\\(\\frac{f(x) - f(x-h)}{h}\\)\n\\(\\frac{f(x) - 2f(x-h) + f(x-2h)}{h^2}\\)\n\n\n\n\nPatrząc na tabelę, zauważmy że:\n\nW kolejnych pochodnych zawsze używamy jedynie próbek z różniczkowanego sygnału oraz kroku \\(h\\)\nW każdym równaniu występują pewne znane komponenty: \\(f(x)\\), \\(f(x+h)\\), \\(f(x+2h)\\), \\(f(x-h)\\), \\(f(x - 2h)\\).\n\nMożemy zatem naszą tabelę zapisać w inny sposób, rozbijając ją na elementy z konkretnymi współczynnikami, na przykład:\n\nMetoda różnic ‘do przodu’, pierwsza pochodna: \\(\\frac{1 × f(x+h) -1 × f(x)}{h}\\). Czyli możemy przyjąć, że kernel takiej operacji to: \\([1, -1]\\) a wynik możemy po prostu podzielić przez \\(h\\).\n\nInnymi słowy, obliczenie pierwszej pochodnej sygnału \\(s\\) może być przeprowadzone z wykorzystaniem splotu z kernelem \\(g = [-1, 1]\\)odpowiadającym operacji pierwszej pochodnej.\nPrzykład numeryczny:\nimport numpy as np\n\n# Zdefiniujmy jakiś sygnał dyskretny\ns = np.array([1, 3, 5, 7, 11, 13, 17, 19])\n\n# Zdefiniujmy kernel dla obliczenia pierwszej pochodnej metodą \"do przodu\"\nh = 1.0\nkernel = np.array([-1/h, 1/h])\n\n# Obliczamy pierwszą pochodną używając splotu\n# Używamy opcji 'valid' aby uniknąć artefaktów krańcowych (boundary effect)\n# Przejrzyj dokumentację funkcji np.convolve aby dowiedzieć się jak działa\nds = np.convolve(s, kernel, mode='valid')\n\nprint(ds)"
  },
  {
    "objectID": "labs/lab2.html#analiza-błędów-numerycznych-w-porównaniu-do-rozwiązań-analitycznych",
    "href": "labs/lab2.html#analiza-błędów-numerycznych-w-porównaniu-do-rozwiązań-analitycznych",
    "title": "Laboratorium 2",
    "section": "",
    "text": "Definicja błędu: Błąd numeryczny to różnica między wartością otrzymaną z metody numerycznej a dokładną wartością analityczną.\nŹródła błędów:\n\nBłąd zaokrąglenia: Powstaje w wyniku reprezentacji liczb w komputerze z ograniczoną precyzją.\nBłąd przybliżenia: Powstaje w wyniku stosowania metod przybliżonych do obliczeń, np. stosując metody różnicowe do przybliżania pochodnych.\n\n\n\n\n\n\n\nPrzykład Analizy Błędów\n\n\n\nFunkcja: \\(f(x) = x^2\\)\nDla \\(x = 2\\): \\[f(2) = 2^2 = 4\\] \\[f(2 + h) = (2 + 0.01)^2 = 4.0401\\]\nPochodna Numeryczna używając metody różnic skończonych do przodu: \\[f'(x) \\approx \\frac{f(x+h) - f(x)}{h}\\] \\[f'(2) \\approx \\frac{f(2+0.01) - f(2)}{0.01}\\] \\[f'(2) \\approx \\frac{4.0401 - 4}{0.01} = 4.01\\]\nPochodna Analityczna: \\[f'(x) = 2x\\] \\[f'(2) = 2(2) = 4\\]\nBłąd Numeryczny: \\[\\text{Błąd} = \\text{Wartość Numeryczna} - \\text{Wartość Analityczna}\\] \\[\\text{Błąd} = 4.01 - 4 = 0.01\\]\nAnaliza Błędu Numerycznego: - Błąd wynosi 0.01 dla kroku \\(h = 0.01\\) przy \\(x = 2\\). - Błąd ten pochodzi z przybliżenia i będzie się różnić w zależności od wielkości kroku \\(h\\). Dla mniejszego \\(h\\) błąd mógłby być mniejszy, ale po pewnym czasie błędy zaokrąglenia mogą zacząć dominować co spowoduje powtórne zwiększenie się błędu numerycznego. - Możemy przeprowadzić dodatkowe obliczenia dla różnych wartości \\(h\\), aby zrozumieć, jak błąd zmienia się w zależności od wielkości kroku.\nW praktyce warto przeprowadzić analizę błędów dla różnych wartości \\(h\\) i różnych punktów \\(x\\), aby zrozumieć zachowanie metody numerycznej w różnych warunkach.\nCzy możemy przeprowadzić obliczenia analityczne komputerowo?\nCzęściowo tak. Możemy w tym celu wykorzystać bibliotekę Pythona SymPy:\nimport sympy as sp\n\n# Zdefiniowanie symbolu\nx = sp.Symbol('x')\n\n# Funkcja\nf = x**2\n\n# Pochodna funkcji\nf_prime = sp.diff(f, x)\n\nprint(f\"Pochodna funkcji {f} to: {f_prime}\")\nSymPy to biblioteka Pythona o otwartym kodzie źródłowym dla matematyki symbolicznej. Jej celem jest stanie się w pełni funkcjonalnym systemem algebry komputerowej (CAS - Computer Algebra System), przy jednoczesnym utrzymaniu kodu tak prostym, jak to możliwe, aby był zrozumiały i łatwy do rozszerzenia. Obliczenia symboliczne, często określane jako algebra symboliczna lub algebra komputerowa, to gałąź obliczeń matematycznych i informatyki, która koncentruje się na manipulowaniu wyrażeniami matematycznymi w formie symbolicznej, a nie na uzyskiwaniu przybliżeń numerycznych."
  },
  {
    "objectID": "labs/lab2.html#zadania-domowe",
    "href": "labs/lab2.html#zadania-domowe",
    "title": "Laboratorium 2",
    "section": "",
    "text": "Zaimplementuj funkcję, (za pomocą pętli for, bez użycia gotowych funkcji) do obliczania pochodnej funkcji jednej zmiennej metodą “centralną”, “do przodu” i “do tyłu”. Jakie są zalety poszczególnych rozwiązań? Jakie są wady? Kiedy warto użyć jednej wersji zamiast drugiej? Skorzystaj z definicji funkcji:\ndef our_derivatie(x, step=1, mode=\"central\"):\n   # x - sygnał wejściowy, dyskretny\n   # step - krok\n   # mode - tryb działania, możliwe opcje: \"central\", \"forward\", \"backward\"\n   pass\n\n\n\nZaimplementuj funkcję do obliczania splotu 1D (iteracyjnie, bez transformacji Fouriera, bez użycia gotowych funkcji). Porównaj działanie zaimplementowanej funkcji z funkcją biblioteczną (SciPy) oraz czas wykonywania obliczeń. Która funkcja jest szybsza? O ile? Dlaczego? Czy wyniki są identyczne? Porównaj działanie funkcji bibliotecznej liczącej splot z definicji oraz z transformacji Fouriera. (Sprawdź dla różnych wielkości tablic wejściowych).\ndef our_convolution(x1, x2, mode=\"pad\"):\n   # x1 - sygnał 1\n   # x2 - sygnał 2\n   # mode - tryb działania na granicy sygnału, #pad - padding, #reflect - reflection\n   pass\n\n\n\nZaimplementuj funkcję (za pomocą pętli for, bez użycia gotowych funkcji) do obliczenia pochodnej funkcji jednej zmiennej “centralnie”, która umożliwia wybór rzędu pochodnej (1,2,3,4) oraz trybu (splot lub sekwencyjnie). Porównaj wynik z wartościami analitycznymi na przykładowym wielomianie wyższego stopnia. Przeanalizuj błędy numeryczne (m.in. porównaj obliczenia za pomocą splotu z sekwencyjnym obliczaniem pierwszej pochodnej). Porównaj czas wykonania obliczeń. Skąd się biorą różnice? Które rozwiązanie jest szybsze? Które jest bardziej stabilne? Które rozwiązanie jest obarczone mniejszym błędem?\n\n\n\n\n\n\nObliczanie pochodnej sekwencyjnie\n\n\n\nSekwencyjna metoda obliczania pochodnej polega na obliczeniu pochodnej danego sygnału (pierwszej), a następnie pochodną drugiego rzędu dostajemy obliczając pochodną pierwszego rzędu pochodnej pierwszego rzędu itd…\n\n\ndef our_derivative(x, step=1, order=1, mode=\"conv\"):\n   # order - rząd pochodnej, 1,2,3,4\n   # conv/sequential - tryb działania (konwolucyjnie / sekwencyjnie)\n   pass\n\n\n\nZaimplementuj funkcję (za pomocą pętli for, bez użycia gotowych funkcji do obliczania pochodnych/gradientów) do obliczenia gradientu centralnego funkcji dwóch zmiennych. Na wejściu funkcji będzie tablica 2D (na przykład obraz). Na wyjściu funkcji powinna być tablica gradientów po x oraz y.\n\n\n\nZaimplementuj funkcję (za pomocą pętli for, bez użycia gotowych funkcji do obliczania pochodnych/gradientów) do obliczenia gradientu centralnego funkcji dowolnej liczby zmiennych (wejście w postaci tablicy N-wymiarowej). Porównaj działanie (błędy numeryczne, szybkość obliczeń) do wbudowanej funkcji gradient w bibliotece numpy.\ndef our_gradient(x, step=1):\n   pass"
  },
  {
    "objectID": "labs/lab2.html#implementacja-gradientów-analitycznych",
    "href": "labs/lab2.html#implementacja-gradientów-analitycznych",
    "title": "Laboratorium 2",
    "section": "",
    "text": "Obliczmy gradient analitycznie za pomocą biblioteki obliczeń symbolicznych w Pythonie, sympy.\nJako przykład użyjmy prostej funkcji dwóch zmiennych: \\[f(x, y) = x^2 + 3xy + y^2\\]\nGradient funkcji \\(f\\) jest wektorem jego pochodnych cząstkowych względem każdej ze zmiennych (w naszym przykładzie względem \\(x\\) oraz \\(y\\)): \\[\\nabla f = \\left[ \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y} \\right]\\]\nPrzeanalizujmy jak przeprowadzić takie obliczenia symbolicznie, z wykorzystaniem biblioteki sympy:\nimport sympy as sp\n\n# Definiujemy zmienne\nx, y = sp.symbols('x y')\n\n# Definiujemy funkcje\nf = x**2 + 3*x*y + y**2\n\n# Obliczamy gradient\ngrad_f = [sp.diff(f, var) for var in (x, y)]\n\nprint(\"Gradient:\", grad_f)\nPowinniśmy otrzymać następujący wynik:\nGradient: [2*x + 3*y, 3*x + 2*y]\nPodsumowując, gradientem naszej funkcji \\(f(x, y)\\) jest \\([2x + 3y, 3x + 2y]\\).\nFunkcja sympy.diff() zapewnia analityczną (dokładną) pochodną, w przeciwieństwie do aproksymacji numerycznej.\nZwizualizujmy ten przykład:\n\n\n\n\n\n\n\nKod użyty do wygenerowania wizualizacji\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sympy as sp\n\n# Definiujemy zmienne i funkcje\nx, y = sp.symbols('x y')\nf = x**2 + 3*x*y + y**2\ngrad_f = [sp.diff(f, var) for var in (x, y)]\n\n# Lambdyfikacja wyrażeń symbolicznych (proces konieczny do wyznaczenia ich wartości dla konkretnych danych numerycznych)\nf_callable = sp.lambdify((x, y), f, 'numpy')\nf_gradient = sp.lambdify((x, y), grad_f, 'numpy')\n\n# Tworzenie siatki punktów na których rozepniemy nasze dane (bardzo ważna czynność!)\nX, Y = np.meshgrid(np.linspace(-10, 10, 20), np.linspace(-10, 10, 20))\n\n# Obliczenie wartości funkcji na konkretnych punktach siatki\nZ = f_callable(X, Y)\nU, V = f_gradient(X, Y)\n\n# Normalizacja danych (dla lepszej wizualizacji)\nN = np.sqrt(U**2 + V**2)\nU /= N\nV /= N\n\n# Plot\nplt.figure(figsize=(10, 8))\n\n# Wyrysowanie funkcji używając metody contour oraz mapy kolorów 'viridis'\ncontour = plt.contourf(X, Y, Z, 20, cmap='viridis')\nplt.colorbar(contour, label='f(x, y) value')\n\n# Narysowanie strzałek reprezentujących wartości gradientu\nplt.quiver(X, Y, U, V, angles='xy', scale_units='xy', scale=1, color='r', width=0.005)\n\nplt.title('f(x, y) and its Gradient')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid()\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.show()"
  },
  {
    "objectID": "labs/lab2.html#przykłady-praktyczne",
    "href": "labs/lab2.html#przykłady-praktyczne",
    "title": "Laboratorium 2",
    "section": "",
    "text": "Gradienty mogą być użyte jako najprostsza metoda wykrywania krawędzi, zwłaszcza na obrazach binarnych.\n\n\n\n\n\n\n\nKod użyty do wygenerowania przykładu z kołem\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nwidth, height = 200, 200\n\n# Krok 1: Używamy meshgrid do utworzenia siatki współrzędnych\nx, y = np.meshgrid(np.arange(width), np.arange(height))\n\ncenterx, centery = width // 2, height // 2\nradius = 50\n\nmask = (x - centerx)**2 + (y - centery)**2 &lt;= radius**2\ncircle_img = np.zeros((width, height))\ncircle_img[mask] = 1\n\n# Krok 2: Obliczamy gradient\ngy, gx = np.gradient(circle_img)\n\n# Krok 3: Wizualizacja\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\naxes[0].imshow(circle_img, cmap='gray')\naxes[0].set_title(\"Oryginalne Koło\")\n\naxes[1].imshow(gx, cmap='gray')\naxes[1].set_title(\"Gradient względem X\")\n\naxes[2].imshow(gy, cmap='gray')\naxes[2].set_title(\"Gradient względem Y\")\n\nfor ax in axes:\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nJednym z algorytmów wykrywających zespół QRS na sygnale EKG jest algorytm Pan-Tompkins. Składa się on z następujących kroków:\n\nFiltracja pasmowo przepustowa usuwająca zakłócenia sieciowe z sygnału\nRóżniczkowanie - służy to podkreśleniu cech morfologicznych sygnału\nKwadrat - podnosimy sygnał do kwadratu celem wzmocnienia cech morfologicznych\nIntegracja (moving average) - operacja ta jest używana do uzyskania finalnego kształtu fali QRS. Sygnał jest przetwarzany za pomocą okna czasowego (np. 30 ms), co skutkuje wygładzeniem sygnału.\nProgowanie - na podstawie przetworzonego sygnału określany jest próg, który służy do wykrywania kompleksów QRS. Wielkość progu jest dynamicznie dostosowywana w trakcie analizy.\n\n\n\n\nAlgorytm Pan-Tompkins krok po kroku\n\n\n\n\n\n\n\n\nKod użyty do wygenerowania wizualizacji Pan-Tompkins\n\n\n\n\n\nimport numpy as np # biblioteka numpy do obliczeń numerycznych\nimport neurokit2 as nk # NeuroKit2 - zawiera generator syntetycznego EKG\nimport matplotlib.pyplot as plt # Matplotlib - Rysowanie wykresów\n\ndef bandpass_filter(signal):\n    # Placeholder na filtr pasmowo przepustowy - TODO\n    return signal\n\n# Różniczkowanie\ndef differentiate(signal):\n    return np.diff(signal)\n\n# Kwadrat\ndef square(signal):\n    return signal ** 2\n\n# Całkowanie\ndef integrate(signal, window_size):\n    return np.convolve(signal, np.ones(window_size)/window_size, mode='same')\n\n# Progowanie\ndef find_qrs(signal, threshold):\n    qrs_locs = np.where(signal &gt; threshold)[0]\n    return qrs_locs\n\n# Pan Tompkins zawarty w jednej funkcji\ndef pan_tompkins_qrs_detection(ecg_signal):\n    ecg_signal = bandpass_filter(ecg_signal)\n    differentiated = differentiate(ecg_signal)\n    squared = square(differentiated)\n    integrated = integrate(squared, window_size=30)  # Adjust based on sampling rate\n    threshold = np.mean(integrated)\n    qrs_locs = find_qrs(integrated, threshold)\n    return qrs_locs\n\n# Postprocessing R-peaków\ndef refine_r_peaks(qrs_locs, ecg_signal, proximity):\n    r_peaks = []\n    grouped_peaks = []\n    for loc in qrs_locs:\n        if not grouped_peaks or abs(loc - grouped_peaks[-1]) &lt;= proximity:\n            grouped_peaks.append(loc)\n        else:\n            # Pick the highest point within this group\n            r_peak = max(grouped_peaks, key=lambda x: ecg_signal[x])\n            r_peaks.append(r_peak)\n            grouped_peaks = [loc]\n    # Handle the last group\n    if grouped_peaks:\n        r_peak = max(grouped_peaks, key=lambda x: ecg_signal[x])\n        r_peaks.append(r_peak)\n    return r_peaks\n\n# Wygenerowanie sygnału syntetycznego EKG\necg_signal = nk.ecg_simulate(duration=10, sampling_rate=1000, heart_rate=70)\n\n# Detekcja z użyciem Pan-Tompkins\nqrs_locs = pan_tompkins_qrs_detection(ecg_signal)\n\n# Postprocessing\nr_peaks = refine_r_peaks(qrs_locs, ecg_signal, proximity=40) \n\nplt.figure(figsize=(14, 5))\nplt.plot(ecg_signal, label='EKG')\nplt.plot(r_peaks, ecg_signal[r_peaks], \"ro\", label='R-peaki')\nplt.title(\"Syntetyczny sygnał EKG oraz wykryte zespoły QRS z użyciem algorytmu Pan-Tompkins\")\nplt.xlabel(\"Próbki\")\nplt.ylabel(\"Amplituda\")\nplt.legend()\nplt.savefig(\"lab2_pan_tompkins_ecg.png\", dpi=200, format=\"png\")\nplt.show()"
  },
  {
    "objectID": "labs/lab3.html",
    "href": "labs/lab3.html",
    "title": "Laboratorium 3",
    "section": "",
    "text": "Całkowanie numeryczne\nPodstawowe algorytmy całkowania numerycznego\nAnaliza błędu całkowania\nCałkowanie numeryczne, a analityczne\nPrzykłady praktyczne\nZadania do samodzielnego rozwiązania\n\n\n\n\nCałkowanie numeryczne jest techniką matematyczną służącą do przybliżonego wyznaczania wartości całek oznaczonych. W wielu przypadkach funkcje, które chcemy całkować, mogą być zbyt skomplikowane, aby znaleźć ich analityczne rozwiązania, lub mogą być dostępne tylko w postaci dyskretnych zestawów danych. W takich sytuacjach techniki całkowania numerycznego stają się niezbędne.\n\n\nMetoda prostokątów to jedna z najprostszych technik całkowania numerycznego. Jej idea polega na podziale obszaru pod krzywą funkcji na wiele małych prostokątów i następnie zsumowaniu pól tych prostokątów, aby uzyskać przybliżone pole pod krzywą.\nW metodzie punktu środkowego wartość funkcji w środkowym punkcie każdego prostokąta jest używana do określenia wysokości tego prostokąta.\n\n\n\nZakładamy, że chcemy obliczyć całkę funkcji \\(f(x)\\) w przedziale \\([a, b]\\).\nDzielimy przedział \\([a, b]\\) na \\(n\\) równych podprzedziałów o długości \\(\\Delta x\\), gdzie: \\[\\Delta x = \\frac{b - a}{n}\\]\nWartość funkcji w punkcie środkowym \\(x_i^*\\) każdego podprzedziału jest używana do obliczenia wysokości prostokąta. Gdzie \\(x_i^* = a + \\left(i - \\frac{1}{2}\\right) \\Delta x\\) dla \\(i = 1, 2, \\dots, n\\).\nPole każdego prostokąta jest dane przez \\(f(x_i^*) \\Delta x\\).\nCałkowite przybliżone pole pod krzywą to suma pól wszystkich prostokątów: \\[A \\approx \\sum_{i=1}^{n} f(x_i^*) \\Delta x\\]\n\n\n\n\n\\[\\int_a^b f(x) \\, dx \\approx \\sum_{i=1}^{n} f\\left(a + \\left(i - \\frac{1}{2}\\right) \\Delta x\\right) \\Delta x\\]\nUproszczone przybliżenie wartości całki funkcji \\(f(x)\\) na przedziale \\([a, b]\\), zakładając że bierzemy punkt w lewym górnym rogu prostokątu a nie w środku, gdzie dzielimy przedział na \\(n\\) równych części o szerokości \\(\\Delta x\\): \\(\\Delta x = \\frac{b - a}{n}\\)\nPrzybliżenie regułą prostokątów jest: \\[\\int_a^b f(x) dx \\approx \\sum_{i=0}^{n-1} f(a + i\\Delta x) \\Delta x\\]\nW tym przypadku przyjmujemy wartość funkcji na lewym krańcu każdego podprzedziału (czyli lewych prostokątów) i mnożymy przez szerokość \\(e\\Delta x\\) dla każdego prostokąta.\nMetoda prostokątów jest stosunkowo prosta w implementacji i może być użyteczna w przypadkach, gdy funkcja jest stosunkowo gładka lub gdy dysponujemy dużą liczbą punktów do całkowania. Jednakże może nie być tak dokładna jak bardziej zaawansowane metody, takie jak metoda trapezów czy metoda Simpsona, zwłaszcza dla funkcji o skomplikowanym kształcie.\n\n\n\n\nMetoda trapezów to pierwsza z metod Newtona-Cotesa. Formuły Newtona-Cotesa są najpopularniejszymi schematami całkowania numerycznego. Opierają się one na strategii zastąpienia skomplikowanej funkcji lub danych tabelarycznych funkcją aproksymującą, która jest łatwa do całkowania:\n\\[I = \\int_a^bf(x)dx \\approxeq \\int_a^bf_n(x)dx\\]\ngdzie \\(f_n(x)\\) jest wielomianem przyjmującym postać:\n\\[f_n(x) = a_0 + a_1x + ... + a_{n-1}x^{n-1}+a_nx^n\\]\na \\(n\\) jest rzędem wielomianu.\n\nMetoda trapezów to najprostsza zamknięta formuła Newtona-Cotesa, w której funkcja jest przybliżana linią prostą (wielomianem pierwszego stopnia) na każdym podprzedziale.\n\\[I \\approxeq h\\frac{f(x_0) + f(x_1)}{2} + h\\frac{f(x_1) + f(x_2)}{2} + h\\frac{f(x_{n-1}) + f(x_n)}{2}\\]\nCzyli uogólniając: \\[I \\approxeq \\frac{h}{2} [f(x_0) + 2\\sum_{i=1}^{n-1}f(x_i) + f(x_n)]\\]\n\n\n\n\n\n\n\nKod użyty do wygenerowania tego rysunku\n\n\n\n\n\n# Definiujemy funkcję\ndef f(x):\n    return np.sin(x) + (1/3)*np.sin(3*x)\n\n# Zakres całkowania od 0 do pi\na, b = 0, 1*np.pi\n\n# Liczba trapezów\nn = 5\n\n# Definiujemy szerokość trapezu\ndx = (b - a) / n\n\n# Punkty x do obliczeń i wizualizacji\nx = np.linspace(a, b, n+1)\ny = f(x)\n\n# Kolory z palety Material Design (ładnie wyglądają)\nfill_color = '#BBDEFB'  # light blue\nedge_color = '#1A237E'  # dark blue\nline_color = '#1976D2'  # blue\n\n# Rysujemy funkcję\nx_dense = np.linspace(a, b, 400)\nplt.plot(x_dense, f(x_dense), color=line_color, label='f(x)')\n\n# Rysujemy trapezy oraz ich obrysy\nfor i in range(n):\n    plt.fill_between([x[i], x[i+1]], [y[i], y[i+1]], color=fill_color, edgecolor=edge_color)\n    plt.plot([x[i], x[i]], [0, y[i]], color=edge_color)  # obrysy wertykalne\n    \n    # Dodajemy podpisy dla kolejnych kroków\n    mid_point = (x[i] + x[i+1]) / 2\n    plt.text(mid_point, 0.2, f'h{i+1}', ha='center', fontsize=10)\nplt.plot([x[-1], x[-1]], [0, y[-1]], color=edge_color)  # ostatni obrys wertykalny\n\nplt.text(a + 0.2, -0.4, f'h = {dx:.4f}', fontsize=12)\n\nplt.legend()\nplt.grid(True)\nplt.ylim([-0.5, 2])\nplt.show()\n\n\n\nPseudokod dla metody trapezów:\nFunction TrapezoidalRuleDiscrete(y, n):\n   h = (b - a) / (n - 1)\n   integral = 0.5 * (y[0] + y[n-1])\n\n   For i from 1 to n-2:\n      integral = integral + y[i]\n\n   integral = integral * h\n   Return integral\n\n\n\n\n\n\nEksperyment 1\n\n\n\nPrzeprowadź eksperyment i spróbuj obliczyć całki dla różnych funkcji numerycznych metodą trapezów z różną długością kroku. Funkcje możesz wygenerować przy pomocy następującego kodu:\nstart = -np.pi\nend = np.pi \nstep = 0.000001\nsamples = int((end - start) / step)\n\nx = np.linspace(start, end, samples)\nf = np.cos(x) + x**2\nPrzeprowadź analizę błędu całkowania.\nCo dzieje się z błędem wraz ze zmianą długości kroku.\nW jaki sposób się zmienia?\nPorównaj to z wartością całki obliczoną analitycznie.\nPorównaj czas wykonywania całkowania dla sygnałów o różnej długości i dla różnych typów danych.\n\n\n\n\n\nDrugą z omawianych metod całkowania numerycznego jest metoda Simpsona. Polega ona na użyciu wielomianu drugiego stopnia do przybliżenia funkcji w danym przedziale.\n\\[I = \\int_a^bf(x)dx \\approxeq \\int_a^bf_s(x)dx\\]\nPole powierzhni pod wykresem funkcji \\(f_s\\) reprezentującej przybliżenie funkcji \\(\\int_a^b(fx)dx\\) jest dane wzorem\n\\[I \\approxeq \\frac{h}{3} [f_s(x_0) + 4\\sum_{i = 1,3,5...}^{n-1}{f_s(x_i)} + 2\\sum_{j = 2,4,6...}^{n-2}f_s(x_j) + f_s(x_n)\\]\nWzór ten można wyprowadzić z przybliżenia Lagrange’s wielomianu stopnia drugiego (wykład).\nBłąd w metodzie Simpsona 1/3 względem\n\n\n\n\n\n\nOgraniczenia metody Simpsona 1/3\n\n\n\nMetoda Simpsona 1/3 wymaga aby ilość przedziałów była parzysta. W sytuacji kiedy liczba przedziałów jest nieparzysta na pierwszych lub ostatnich trzech z nich możemy przeprowadzić całkowanie metodą Simpsona 3/8.\n\n\n\n\n\n\n\n\n\nKod użyty do wygenerowania tego rysunku\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the function\ndef f(x):\n    return np.sin(x) + (1/3)*np.sin(3*x)\n\n# Range for integration\na, b = 0, 2*np.pi\n\n# Number of intervals (must be even for Simpson's 1/3 rule)\nn = 10\nassert n % 2 == 0, \"Number of intervals must be even for Simpson's 1/3 rule\"\n\n# Width of an interval\ndx = (b - a) / n\n\n# Points x for calculation and visualization\nx = np.linspace(a, b, n+1)\ny = f(x)\n\n# Compute the approximation using Simpson's 1/3 rule\nintegral_approx = dx/3 * (y[0] + y[-1] + 4*np.sum(y[1:-1:2]) + 2*np.sum(y[2:-2:2]))\n\n# Colors from Material Design palette\nfill_color = '#BBDEFB'\nedge_color = '#1A237E'\nline_color = '#1976D2'\npoint_color = '#D32F2F'  # red color for points\n\n# Plot the function\nx_dense = np.linspace(a, b, 400)\nplt.plot(x_dense, f(x_dense), color=line_color, label='f(x)')\n\n# Draw parabolic sections and mark the points\nfor i in range(0, n, 2):\n    xx = np.linspace(x[i], x[i+2], 100)\n    yy = (\n        f(x[i])*(xx - x[i+1])*(xx - x[i+2])/((x[i] - x[i+1])*(x[i] - x[i+2]))\n        + f(x[i+1])*(xx - x[i])*(xx - x[i+2])/((x[i+1] - x[i])*(x[i+1] - x[i+2]))\n        + f(x[i+2])*(xx - x[i])*(xx - x[i+1])/((x[i+2] - x[i])*(x[i+2] - x[i+1]))\n    )\n    plt.fill_between(xx, yy, color=fill_color, edgecolor=edge_color)\n    \n    # Add steps annotations\n    plt.text((x[i] + x[i+2]) / 2, 1.4, f'step {i//2+1}', ha='center', fontsize=10)\n    \n    # Marking points: start, middle, and end\n    plt.scatter([x[i], x[i+1], x[i+2]], [y[i], y[i+1], y[i+2]], color=point_color, zorder=5)\n    \n    # Adjusted labels to avoid overlap\n    offset = 0.15\n    plt.text(x[i], y[i] - offset if y[i] &gt; 0 else y[i] + offset, f'Start', ha='center', fontsize=8, va='center')\n    plt.text(x[i+1], y[i+1] - offset, f'Mid', ha='center', fontsize=8, va='center')\n    plt.text(x[i+2], y[i+2] + offset if y[i+2] &gt; 0 else y[i+2] - offset, f'End', ha='center', fontsize=8, va='center')\nplt.text(a + 0.2, -0.3, f'h = {dx:.4f}', fontsize=12)\n\nplt.legend()\nplt.grid(True)\nplt.ylim([-1.5, 2])\nplt.show()\n\n\n\n\n\n\n\n\n\nEksperyment 2\n\n\n\nPrzeprowadź analogiczny eksperyment do eksperymentu 1 ale z wykorzystaniem metody Simpsona. Możesz skorzystać z funkcji dostępnej w pakiecie scipy o nazwie scipy.integrate.simpson\n\n\n\n\n\nW przypadku metody Simpsona 3/8 jej sposób działania jest podobny do metody Simpsona 1/3, jednak zamiast wielomianu stopnia drugiego, wykorzystamy wielomian stopnia trzeciego.\n\\[I = \\int_a^bf(x)dx \\approxeq \\int_a^bf_3(x)dx\\]\na to po odpowiednich przekształceniach wynikających z przybliżenia Lagrange’a wielomianu prowadzi do wzoru:\n\\[I \\approxeq \\frac{3h}{8}[f(x_0) + 3f(x_1) + 3f(x_2) + f(x_3)]\\]\nRegułę Simpsona 3/8 można stosować w połączeniu z metodą Simpsona 1/3 gdy mamy do czynienia z nieparzystą liczbą przedziałów.\n\n\n\nSuma kumulacyjna, inaczej nazywana sumą skumulowaną lub kumulatą, to suma wartości danego zestawu danych w kolejnych punktach, zamiast pojedynczych wartości. Daje to ciąg liczb, w którym każda kolejna wartość to suma wszystkich poprzednich wartości w zestawie plus bieżąca wartość.\n\\[y[i] = \\sum_{k=1}^{i}k[i]\\] \\[x = [x_1, x_2, x_3, x_4...x_n]\\]\n\\[y = [x_1, x_1 + x_2, x_1+x_2+x_3...]\\]\nPrzykład:\nZałóżmy, że mamy następujący zestaw danych:\n\\[A = \\{ 1, 2, 3, 4 \\}\\]\nSuma kumulacyjna tego zestawu będzie wyglądała następująco:\n\\[\\{ 1, 1+2, 1+2+3, 1+2+3+4 \\} = \\{ 1, 3, 6, 10 \\}\\]\nOstateczny ciąg sumy kumulacyjnej to {1, 3, 6, 10}.\nW wielu zastosowaniach, takich jak analiza finansowa, statystyka czy obróbka sygnałów, suma kumulacyjna jest używana do obliczenia sumy wartości w określonym zakresie lub do analizy wzrostu wartości w czasie.\n\n\n\n\nObszar pod zespołem QRS (często nazywany obszarem QRS) w elektrokardiogramie (EKG) może dostarczyć cennych informacji diagnostycznych na temat aktywności elektrycznej serca i stanu mięśnia sercowego.\nQRS Area Is a Strong Determinant of Outcome in Cardiac Resynchronization Therapy\n\n\n\n\n\n\n\nKod użyty do wygenerowania tego przykładu\n\n\n\n\n\nimport neurokit2 as nk\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate a synthetic ECG signal (5 seconds)\necg_signal = nk.ecg_simulate(duration=5, sampling_rate=1000, heart_rate=70)\n\n# Detect R-peaks\n_, rpeaks = nk.ecg_peaks(ecg_signal, sampling_rate=1000)\n\n# Delineate the ECG signal to extract waves\n_, waves_peak = nk.ecg_delineate(ecg_signal, rpeaks, sampling_rate=1000, method=\"peak\")\n\n# Plot the ECG signal\nplt.figure(figsize=(15, 5))\nplt.plot(ecg_signal, label='ECG Signal')\n\nqrs_areas = []\n\n# Get a colormap for varying QRS colors\ncolor_map = plt.cm.get_cmap('viridis', len(waves_peak['ECG_Q_Peaks']))\n\n# Highlight the QRS complex using the Q-peaks and S-peaks as boundaries\nfor idx, (q_peak, s_peak) in enumerate(zip(waves_peak['ECG_Q_Peaks'], waves_peak['ECG_S_Peaks'])):\n    if not np.isnan(q_peak) and not np.isnan(s_peak):\n        \n        # Determine the local baseline as the mean value before Q and after S\n        local_baseline = np.mean([ecg_signal[int(q_peak) - 5:int(q_peak)], ecg_signal[int(s_peak):int(s_peak) + 5]])\n        \n        # Calculate the QRS area related to the local baseline using the trapezoidal rule\n        qrs_area = np.trapz(ecg_signal[int(q_peak):int(s_peak)] - local_baseline)\n        qrs_areas.append(qrs_area)\n        \n        # Highlight the QRS complex on the plot with different colors\n        plt.fill_between(range(int(q_peak), int(s_peak)), ecg_signal[int(q_peak):int(s_peak)], local_baseline, color=color_map(idx), alpha=0.7, label=f'QRS Area {idx + 1} = {qrs_area:.2f}')\n\n# Display the legend and title\nhandles, labels = plt.gca().get_legend_handles_labels()\nby_label = dict(zip(labels, handles))\nplt.legend(by_label.values(), by_label.keys(), loc=\"upper left\")\n\nplt.title(\"ECG Signal with Highlighted QRS Area\")\nplt.show()\n\n# Print the QRS areas\nfor idx, area in enumerate(qrs_areas, 1):\n    print(f\"QRS complex {idx}: Area = {area:.2f}\")\n\n\n\n\n\n\n\n\nZaimplementuj funkcję (za pomocą pętli for, bez użycia gotowych funkcji) implementującą metodę trapezów, metodę Simpsona 1/3 i metodę Simpsona 3/8. Porównaj działanie do funkcji dostępnych w bibliotece SciPy (zarówno pod kątem czasu obliczeń jak i uzyskanych wyników). Porównaj dokładność wyznaczonych sum z wartością oczekiwaną, dla wybranych, znanych całek oznaczonych.\ndef our_integrate(y, dx, method=”trapezoidal”): \n   #methods: trapezoidal, simpson_13, simpson_38 pass\n\n\n\nZaimplementuj własny generator do sumy kumulacyjnej (za pomocą pętli for) i korzystając z niej zaimplementuj rekurencyjnie całkowanie z Zadania 1. Dokonaj wizualizacji przykładowych funkcji i ich całek. Jakie zalety ma implementacja rekurencyjna całkowania? Jakie wady? Porównaj szybkość działania implementacji rekurencyjnej całkowania metodą trapezów/Simpsona z wbudowaną funkcją do całkowania kwadraturą Gaussa z biblioteki SciPy.\ndef our_integrate_recur(y, dx, mode=\"trapezoidal\"): \n#trapezoidal, simpson_13, simpson_38\npass # should use yield\n\n\n\nZaimplementuj własną funkcję do całkowania funkcji dwóch zmiennych metodą trapezów. Porównaj uzyskane wyniki z metodą opartą o kwadratury Gaussa dla dwóch zmiennych pod względem dokładności i szybkości wykonywania. W jakich przypadkach zaimplementowana metoda może być bardziej użyteczna od metod opartych o kwadratury Gaussa?\ndef our_integrate_2d(z, x_step, y_step): pass"
  },
  {
    "objectID": "labs/lab3.html#zakres-tematyczny",
    "href": "labs/lab3.html#zakres-tematyczny",
    "title": "Laboratorium 3",
    "section": "",
    "text": "Całkowanie numeryczne\nPodstawowe algorytmy całkowania numerycznego\nAnaliza błędu całkowania\nCałkowanie numeryczne, a analityczne\nPrzykłady praktyczne\nZadania do samodzielnego rozwiązania"
  },
  {
    "objectID": "labs/lab3.html#całkowanie-numeryczne",
    "href": "labs/lab3.html#całkowanie-numeryczne",
    "title": "Laboratorium 3",
    "section": "",
    "text": "Całkowanie numeryczne jest techniką matematyczną służącą do przybliżonego wyznaczania wartości całek oznaczonych. W wielu przypadkach funkcje, które chcemy całkować, mogą być zbyt skomplikowane, aby znaleźć ich analityczne rozwiązania, lub mogą być dostępne tylko w postaci dyskretnych zestawów danych. W takich sytuacjach techniki całkowania numerycznego stają się niezbędne.\n\n\nMetoda prostokątów to jedna z najprostszych technik całkowania numerycznego. Jej idea polega na podziale obszaru pod krzywą funkcji na wiele małych prostokątów i następnie zsumowaniu pól tych prostokątów, aby uzyskać przybliżone pole pod krzywą.\nW metodzie punktu środkowego wartość funkcji w środkowym punkcie każdego prostokąta jest używana do określenia wysokości tego prostokąta.\n\n\n\nZakładamy, że chcemy obliczyć całkę funkcji \\(f(x)\\) w przedziale \\([a, b]\\).\nDzielimy przedział \\([a, b]\\) na \\(n\\) równych podprzedziałów o długości \\(\\Delta x\\), gdzie: \\[\\Delta x = \\frac{b - a}{n}\\]\nWartość funkcji w punkcie środkowym \\(x_i^*\\) każdego podprzedziału jest używana do obliczenia wysokości prostokąta. Gdzie \\(x_i^* = a + \\left(i - \\frac{1}{2}\\right) \\Delta x\\) dla \\(i = 1, 2, \\dots, n\\).\nPole każdego prostokąta jest dane przez \\(f(x_i^*) \\Delta x\\).\nCałkowite przybliżone pole pod krzywą to suma pól wszystkich prostokątów: \\[A \\approx \\sum_{i=1}^{n} f(x_i^*) \\Delta x\\]\n\n\n\n\n\\[\\int_a^b f(x) \\, dx \\approx \\sum_{i=1}^{n} f\\left(a + \\left(i - \\frac{1}{2}\\right) \\Delta x\\right) \\Delta x\\]\nUproszczone przybliżenie wartości całki funkcji \\(f(x)\\) na przedziale \\([a, b]\\), zakładając że bierzemy punkt w lewym górnym rogu prostokątu a nie w środku, gdzie dzielimy przedział na \\(n\\) równych części o szerokości \\(\\Delta x\\): \\(\\Delta x = \\frac{b - a}{n}\\)\nPrzybliżenie regułą prostokątów jest: \\[\\int_a^b f(x) dx \\approx \\sum_{i=0}^{n-1} f(a + i\\Delta x) \\Delta x\\]\nW tym przypadku przyjmujemy wartość funkcji na lewym krańcu każdego podprzedziału (czyli lewych prostokątów) i mnożymy przez szerokość \\(e\\Delta x\\) dla każdego prostokąta.\nMetoda prostokątów jest stosunkowo prosta w implementacji i może być użyteczna w przypadkach, gdy funkcja jest stosunkowo gładka lub gdy dysponujemy dużą liczbą punktów do całkowania. Jednakże może nie być tak dokładna jak bardziej zaawansowane metody, takie jak metoda trapezów czy metoda Simpsona, zwłaszcza dla funkcji o skomplikowanym kształcie.\n\n\n\n\nMetoda trapezów to pierwsza z metod Newtona-Cotesa. Formuły Newtona-Cotesa są najpopularniejszymi schematami całkowania numerycznego. Opierają się one na strategii zastąpienia skomplikowanej funkcji lub danych tabelarycznych funkcją aproksymującą, która jest łatwa do całkowania:\n\\[I = \\int_a^bf(x)dx \\approxeq \\int_a^bf_n(x)dx\\]\ngdzie \\(f_n(x)\\) jest wielomianem przyjmującym postać:\n\\[f_n(x) = a_0 + a_1x + ... + a_{n-1}x^{n-1}+a_nx^n\\]\na \\(n\\) jest rzędem wielomianu.\n\nMetoda trapezów to najprostsza zamknięta formuła Newtona-Cotesa, w której funkcja jest przybliżana linią prostą (wielomianem pierwszego stopnia) na każdym podprzedziale.\n\\[I \\approxeq h\\frac{f(x_0) + f(x_1)}{2} + h\\frac{f(x_1) + f(x_2)}{2} + h\\frac{f(x_{n-1}) + f(x_n)}{2}\\]\nCzyli uogólniając: \\[I \\approxeq \\frac{h}{2} [f(x_0) + 2\\sum_{i=1}^{n-1}f(x_i) + f(x_n)]\\]\n\n\n\n\n\n\n\nKod użyty do wygenerowania tego rysunku\n\n\n\n\n\n# Definiujemy funkcję\ndef f(x):\n    return np.sin(x) + (1/3)*np.sin(3*x)\n\n# Zakres całkowania od 0 do pi\na, b = 0, 1*np.pi\n\n# Liczba trapezów\nn = 5\n\n# Definiujemy szerokość trapezu\ndx = (b - a) / n\n\n# Punkty x do obliczeń i wizualizacji\nx = np.linspace(a, b, n+1)\ny = f(x)\n\n# Kolory z palety Material Design (ładnie wyglądają)\nfill_color = '#BBDEFB'  # light blue\nedge_color = '#1A237E'  # dark blue\nline_color = '#1976D2'  # blue\n\n# Rysujemy funkcję\nx_dense = np.linspace(a, b, 400)\nplt.plot(x_dense, f(x_dense), color=line_color, label='f(x)')\n\n# Rysujemy trapezy oraz ich obrysy\nfor i in range(n):\n    plt.fill_between([x[i], x[i+1]], [y[i], y[i+1]], color=fill_color, edgecolor=edge_color)\n    plt.plot([x[i], x[i]], [0, y[i]], color=edge_color)  # obrysy wertykalne\n    \n    # Dodajemy podpisy dla kolejnych kroków\n    mid_point = (x[i] + x[i+1]) / 2\n    plt.text(mid_point, 0.2, f'h{i+1}', ha='center', fontsize=10)\nplt.plot([x[-1], x[-1]], [0, y[-1]], color=edge_color)  # ostatni obrys wertykalny\n\nplt.text(a + 0.2, -0.4, f'h = {dx:.4f}', fontsize=12)\n\nplt.legend()\nplt.grid(True)\nplt.ylim([-0.5, 2])\nplt.show()\n\n\n\nPseudokod dla metody trapezów:\nFunction TrapezoidalRuleDiscrete(y, n):\n   h = (b - a) / (n - 1)\n   integral = 0.5 * (y[0] + y[n-1])\n\n   For i from 1 to n-2:\n      integral = integral + y[i]\n\n   integral = integral * h\n   Return integral\n\n\n\n\n\n\nEksperyment 1\n\n\n\nPrzeprowadź eksperyment i spróbuj obliczyć całki dla różnych funkcji numerycznych metodą trapezów z różną długością kroku. Funkcje możesz wygenerować przy pomocy następującego kodu:\nstart = -np.pi\nend = np.pi \nstep = 0.000001\nsamples = int((end - start) / step)\n\nx = np.linspace(start, end, samples)\nf = np.cos(x) + x**2\nPrzeprowadź analizę błędu całkowania.\nCo dzieje się z błędem wraz ze zmianą długości kroku.\nW jaki sposób się zmienia?\nPorównaj to z wartością całki obliczoną analitycznie.\nPorównaj czas wykonywania całkowania dla sygnałów o różnej długości i dla różnych typów danych.\n\n\n\n\n\nDrugą z omawianych metod całkowania numerycznego jest metoda Simpsona. Polega ona na użyciu wielomianu drugiego stopnia do przybliżenia funkcji w danym przedziale.\n\\[I = \\int_a^bf(x)dx \\approxeq \\int_a^bf_s(x)dx\\]\nPole powierzhni pod wykresem funkcji \\(f_s\\) reprezentującej przybliżenie funkcji \\(\\int_a^b(fx)dx\\) jest dane wzorem\n\\[I \\approxeq \\frac{h}{3} [f_s(x_0) + 4\\sum_{i = 1,3,5...}^{n-1}{f_s(x_i)} + 2\\sum_{j = 2,4,6...}^{n-2}f_s(x_j) + f_s(x_n)\\]\nWzór ten można wyprowadzić z przybliżenia Lagrange’s wielomianu stopnia drugiego (wykład).\nBłąd w metodzie Simpsona 1/3 względem\n\n\n\n\n\n\nOgraniczenia metody Simpsona 1/3\n\n\n\nMetoda Simpsona 1/3 wymaga aby ilość przedziałów była parzysta. W sytuacji kiedy liczba przedziałów jest nieparzysta na pierwszych lub ostatnich trzech z nich możemy przeprowadzić całkowanie metodą Simpsona 3/8.\n\n\n\n\n\n\n\n\n\nKod użyty do wygenerowania tego rysunku\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the function\ndef f(x):\n    return np.sin(x) + (1/3)*np.sin(3*x)\n\n# Range for integration\na, b = 0, 2*np.pi\n\n# Number of intervals (must be even for Simpson's 1/3 rule)\nn = 10\nassert n % 2 == 0, \"Number of intervals must be even for Simpson's 1/3 rule\"\n\n# Width of an interval\ndx = (b - a) / n\n\n# Points x for calculation and visualization\nx = np.linspace(a, b, n+1)\ny = f(x)\n\n# Compute the approximation using Simpson's 1/3 rule\nintegral_approx = dx/3 * (y[0] + y[-1] + 4*np.sum(y[1:-1:2]) + 2*np.sum(y[2:-2:2]))\n\n# Colors from Material Design palette\nfill_color = '#BBDEFB'\nedge_color = '#1A237E'\nline_color = '#1976D2'\npoint_color = '#D32F2F'  # red color for points\n\n# Plot the function\nx_dense = np.linspace(a, b, 400)\nplt.plot(x_dense, f(x_dense), color=line_color, label='f(x)')\n\n# Draw parabolic sections and mark the points\nfor i in range(0, n, 2):\n    xx = np.linspace(x[i], x[i+2], 100)\n    yy = (\n        f(x[i])*(xx - x[i+1])*(xx - x[i+2])/((x[i] - x[i+1])*(x[i] - x[i+2]))\n        + f(x[i+1])*(xx - x[i])*(xx - x[i+2])/((x[i+1] - x[i])*(x[i+1] - x[i+2]))\n        + f(x[i+2])*(xx - x[i])*(xx - x[i+1])/((x[i+2] - x[i])*(x[i+2] - x[i+1]))\n    )\n    plt.fill_between(xx, yy, color=fill_color, edgecolor=edge_color)\n    \n    # Add steps annotations\n    plt.text((x[i] + x[i+2]) / 2, 1.4, f'step {i//2+1}', ha='center', fontsize=10)\n    \n    # Marking points: start, middle, and end\n    plt.scatter([x[i], x[i+1], x[i+2]], [y[i], y[i+1], y[i+2]], color=point_color, zorder=5)\n    \n    # Adjusted labels to avoid overlap\n    offset = 0.15\n    plt.text(x[i], y[i] - offset if y[i] &gt; 0 else y[i] + offset, f'Start', ha='center', fontsize=8, va='center')\n    plt.text(x[i+1], y[i+1] - offset, f'Mid', ha='center', fontsize=8, va='center')\n    plt.text(x[i+2], y[i+2] + offset if y[i+2] &gt; 0 else y[i+2] - offset, f'End', ha='center', fontsize=8, va='center')\nplt.text(a + 0.2, -0.3, f'h = {dx:.4f}', fontsize=12)\n\nplt.legend()\nplt.grid(True)\nplt.ylim([-1.5, 2])\nplt.show()\n\n\n\n\n\n\n\n\n\nEksperyment 2\n\n\n\nPrzeprowadź analogiczny eksperyment do eksperymentu 1 ale z wykorzystaniem metody Simpsona. Możesz skorzystać z funkcji dostępnej w pakiecie scipy o nazwie scipy.integrate.simpson\n\n\n\n\n\nW przypadku metody Simpsona 3/8 jej sposób działania jest podobny do metody Simpsona 1/3, jednak zamiast wielomianu stopnia drugiego, wykorzystamy wielomian stopnia trzeciego.\n\\[I = \\int_a^bf(x)dx \\approxeq \\int_a^bf_3(x)dx\\]\na to po odpowiednich przekształceniach wynikających z przybliżenia Lagrange’a wielomianu prowadzi do wzoru:\n\\[I \\approxeq \\frac{3h}{8}[f(x_0) + 3f(x_1) + 3f(x_2) + f(x_3)]\\]\nRegułę Simpsona 3/8 można stosować w połączeniu z metodą Simpsona 1/3 gdy mamy do czynienia z nieparzystą liczbą przedziałów.\n\n\n\nSuma kumulacyjna, inaczej nazywana sumą skumulowaną lub kumulatą, to suma wartości danego zestawu danych w kolejnych punktach, zamiast pojedynczych wartości. Daje to ciąg liczb, w którym każda kolejna wartość to suma wszystkich poprzednich wartości w zestawie plus bieżąca wartość.\n\\[y[i] = \\sum_{k=1}^{i}k[i]\\] \\[x = [x_1, x_2, x_3, x_4...x_n]\\]\n\\[y = [x_1, x_1 + x_2, x_1+x_2+x_3...]\\]\nPrzykład:\nZałóżmy, że mamy następujący zestaw danych:\n\\[A = \\{ 1, 2, 3, 4 \\}\\]\nSuma kumulacyjna tego zestawu będzie wyglądała następująco:\n\\[\\{ 1, 1+2, 1+2+3, 1+2+3+4 \\} = \\{ 1, 3, 6, 10 \\}\\]\nOstateczny ciąg sumy kumulacyjnej to {1, 3, 6, 10}.\nW wielu zastosowaniach, takich jak analiza finansowa, statystyka czy obróbka sygnałów, suma kumulacyjna jest używana do obliczenia sumy wartości w określonym zakresie lub do analizy wzrostu wartości w czasie."
  },
  {
    "objectID": "labs/lab3.html#przykłady-praktyczne",
    "href": "labs/lab3.html#przykłady-praktyczne",
    "title": "Laboratorium 3",
    "section": "",
    "text": "Obszar pod zespołem QRS (często nazywany obszarem QRS) w elektrokardiogramie (EKG) może dostarczyć cennych informacji diagnostycznych na temat aktywności elektrycznej serca i stanu mięśnia sercowego.\nQRS Area Is a Strong Determinant of Outcome in Cardiac Resynchronization Therapy\n\n\n\n\n\n\n\nKod użyty do wygenerowania tego przykładu\n\n\n\n\n\nimport neurokit2 as nk\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate a synthetic ECG signal (5 seconds)\necg_signal = nk.ecg_simulate(duration=5, sampling_rate=1000, heart_rate=70)\n\n# Detect R-peaks\n_, rpeaks = nk.ecg_peaks(ecg_signal, sampling_rate=1000)\n\n# Delineate the ECG signal to extract waves\n_, waves_peak = nk.ecg_delineate(ecg_signal, rpeaks, sampling_rate=1000, method=\"peak\")\n\n# Plot the ECG signal\nplt.figure(figsize=(15, 5))\nplt.plot(ecg_signal, label='ECG Signal')\n\nqrs_areas = []\n\n# Get a colormap for varying QRS colors\ncolor_map = plt.cm.get_cmap('viridis', len(waves_peak['ECG_Q_Peaks']))\n\n# Highlight the QRS complex using the Q-peaks and S-peaks as boundaries\nfor idx, (q_peak, s_peak) in enumerate(zip(waves_peak['ECG_Q_Peaks'], waves_peak['ECG_S_Peaks'])):\n    if not np.isnan(q_peak) and not np.isnan(s_peak):\n        \n        # Determine the local baseline as the mean value before Q and after S\n        local_baseline = np.mean([ecg_signal[int(q_peak) - 5:int(q_peak)], ecg_signal[int(s_peak):int(s_peak) + 5]])\n        \n        # Calculate the QRS area related to the local baseline using the trapezoidal rule\n        qrs_area = np.trapz(ecg_signal[int(q_peak):int(s_peak)] - local_baseline)\n        qrs_areas.append(qrs_area)\n        \n        # Highlight the QRS complex on the plot with different colors\n        plt.fill_between(range(int(q_peak), int(s_peak)), ecg_signal[int(q_peak):int(s_peak)], local_baseline, color=color_map(idx), alpha=0.7, label=f'QRS Area {idx + 1} = {qrs_area:.2f}')\n\n# Display the legend and title\nhandles, labels = plt.gca().get_legend_handles_labels()\nby_label = dict(zip(labels, handles))\nplt.legend(by_label.values(), by_label.keys(), loc=\"upper left\")\n\nplt.title(\"ECG Signal with Highlighted QRS Area\")\nplt.show()\n\n# Print the QRS areas\nfor idx, area in enumerate(qrs_areas, 1):\n    print(f\"QRS complex {idx}: Area = {area:.2f}\")"
  },
  {
    "objectID": "labs/lab3.html#zadania",
    "href": "labs/lab3.html#zadania",
    "title": "Laboratorium 3",
    "section": "",
    "text": "Zaimplementuj funkcję (za pomocą pętli for, bez użycia gotowych funkcji) implementującą metodę trapezów, metodę Simpsona 1/3 i metodę Simpsona 3/8. Porównaj działanie do funkcji dostępnych w bibliotece SciPy (zarówno pod kątem czasu obliczeń jak i uzyskanych wyników). Porównaj dokładność wyznaczonych sum z wartością oczekiwaną, dla wybranych, znanych całek oznaczonych.\ndef our_integrate(y, dx, method=”trapezoidal”): \n   #methods: trapezoidal, simpson_13, simpson_38 pass\n\n\n\nZaimplementuj własny generator do sumy kumulacyjnej (za pomocą pętli for) i korzystając z niej zaimplementuj rekurencyjnie całkowanie z Zadania 1. Dokonaj wizualizacji przykładowych funkcji i ich całek. Jakie zalety ma implementacja rekurencyjna całkowania? Jakie wady? Porównaj szybkość działania implementacji rekurencyjnej całkowania metodą trapezów/Simpsona z wbudowaną funkcją do całkowania kwadraturą Gaussa z biblioteki SciPy.\ndef our_integrate_recur(y, dx, mode=\"trapezoidal\"): \n#trapezoidal, simpson_13, simpson_38\npass # should use yield\n\n\n\nZaimplementuj własną funkcję do całkowania funkcji dwóch zmiennych metodą trapezów. Porównaj uzyskane wyniki z metodą opartą o kwadratury Gaussa dla dwóch zmiennych pod względem dokładności i szybkości wykonywania. W jakich przypadkach zaimplementowana metoda może być bardziej użyteczna od metod opartych o kwadratury Gaussa?\ndef our_integrate_2d(z, x_step, y_step): pass"
  }
]